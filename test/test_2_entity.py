"""
ì—”í‹°í‹° ë§¤í•‘ API í…ŒìŠ¤íŠ¸ ì½”ë“œ
API ë‚´ë¶€ í•¨ìˆ˜ë“¤ì„ ì§ì ‘ ì‚¬ìš©í•˜ì—¬ 6ë‹¨ê³„ë³„ë¡œ í›„ë³´êµ°ê³¼ ì ìˆ˜ë¥¼ í™•ì¸
"""

import sys
import os
import logging
import numpy as np
from typing import Dict, Any, List

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ì˜ src ë””ë ‰í† ë¦¬ë¥¼ Python ê²½ë¡œì— ì¶”ê°€
project_root = os.path.dirname(os.path.dirname(__file__))
src_path = os.path.join(project_root, 'src')
sys.path.insert(0, src_path)

from omop_mapper.entity_mapping_api import (
    EntityMappingAPI, 
    EntityInput, 
    DomainID
)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)


def test_entity_mapping_6_steps(entity_name: str, domain_id: str, 
                               golden_concept_id: str, golden_concept_name: str) -> None:
    """
    ì—”í‹°í‹° ë§¤í•‘ì„ 6ë‹¨ê³„ë³„ë¡œ ìƒì„¸ í…ŒìŠ¤íŠ¸ (API í•¨ìˆ˜ ì§ì ‘ ì‚¬ìš©)
    
    Args:
        entity_name: í…ŒìŠ¤íŠ¸í•  ì—”í‹°í‹° ì´ë¦„
        domain_id: ë„ë©”ì¸ ID
        golden_concept_id: ê³¨ë“ ì…‹ ì»¨ì…‰ ID
        golden_concept_name: ê³¨ë“ ì…‹ ì»¨ì…‰ ì´ë¦„
    """
    print(f"\n{'='*80}")
    print(f"ğŸ” ì—”í‹°í‹°: {entity_name}")
    print(f"ğŸ¯ ê³¨ë“ ì…‹: {golden_concept_id} - {golden_concept_name}")
    print(f"{'='*80}")
    
    # API ì´ˆê¸°í™”
    api = EntityMappingAPI()
    
    # ì—”í‹°í‹° ì…ë ¥ ìƒì„±
    entity_input = EntityInput(
        entity_name=entity_name,
        domain_id=DomainID(domain_id),
        confidence=1.0
    )
    
    # ì‚¬ì „ ë§¤í•‘ ì •ë³´ ì¤€ë¹„
    entities_to_map = []
    entities_to_map.append({
        "entity_name": entity_input.entity_name,
        "domain_id": entity_input.domain_id or None,
        "vocabulary_id": entity_input.vocabulary_id or None
    })
    
    if not entities_to_map:
        print("âŒ ì—”í‹°í‹° ë§¤í•‘ ì¤€ë¹„ ì‹¤íŒ¨")
        return
    
    entity_info = entities_to_map[0]
    
    # ===== 1ë‹¨ê³„: Elasticsearch ê²€ìƒ‰ =====
    print(f"\nğŸ” 1ë‹¨ê³„: Elasticsearch ê²€ìƒ‰")
    print(f"{'='*60}")
    
    candidates = api._search_similar_concepts(entity_input, entity_info, top_k=5)
    
    if not candidates:
        print("âŒ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
        return
    
    print(f"ì´ {len(candidates)}ê°œ í›„ë³´ ë°œê²¬:")
    for i, candidate in enumerate(candidates, 1):
        source = candidate['_source']
        score = candidate['_score']
        
        print(f"  {i}. Elasticsearch ì ìˆ˜: {score:.3f}")
        print(f"     ì»¨ì…‰ ID: {source.get('concept_id', 'N/A')}")
        print(f"     ì»¨ì…‰ëª…: {source.get('concept_name', 'N/A')}")
        print(f"     ë„ë©”ì¸: {source.get('domain_id', 'N/A')}")
        print(f"     ì–´íœ˜ì²´ê³„: {source.get('vocabulary_id', 'N/A')}")
        print(f"     í‘œì¤€ì—¬ë¶€: {source.get('standard_concept', 'N/A')}")
        print()
    
    # ===== 2ë‹¨ê³„: Standard/Non-standard ë¶„ë¥˜ =====
    print(f"ğŸ”„ 2ë‹¨ê³„: Standard/Non-standard ë¶„ë¥˜")
    print(f"{'='*60}")
    
    standard_candidates = []
    non_standard_candidates = []
    
    for i, candidate in enumerate(candidates, 1):
        source = candidate['_source']
        
        if source.get('standard_concept') == 'S':
            standard_candidates.append(candidate)
            print(f"  {i}. âœ… Standard: {source.get('concept_name', 'N/A')}")
        else:
            non_standard_candidates.append(candidate)
            print(f"  {i}. âš ï¸ Non-standard: {source.get('concept_name', 'N/A')}")
    
    print(f"\n  ğŸ“Š ë¶„ë¥˜ ê²°ê³¼: Standard {len(standard_candidates)}ê°œ, Non-standard {len(non_standard_candidates)}ê°œ")
    
    # ===== 3ë‹¨ê³„: Non-standardì¸ ê²½ìš° â†’ Maps to ê´€ê³„ë¡œ Standard í›„ë³´ ì¡°íšŒ =====
    print(f"\nğŸ”— 3ë‹¨ê³„: Non-standard â†’ Maps to ê´€ê³„ë¡œ Standard í›„ë³´ ì¡°íšŒ")
    print(f"{'='*60}")
    
    # Non-standard í›„ë³´ë“¤ì€ Standard í›„ë³´ ì¡°íšŒ
    non_standard_to_standard_mappings = []
    
    for i, candidate in enumerate(non_standard_candidates, 1):
        source = candidate['_source']
        concept_id = str(source.get('concept_id', ''))
        print(f"  Non-standard {i}: {source.get('concept_name', 'N/A')} (ID: {concept_id})")
        
        standard_candidates_from_non = api._get_standard_candidates(concept_id, entity_info["domain_id"])
        
        if standard_candidates_from_non:
            print(f"    â†’ Maps to ê´€ê³„ë¡œ {len(standard_candidates_from_non)}ê°œ Standard í›„ë³´ ë°œê²¬")
            for j, std_candidate in enumerate(standard_candidates_from_non[:3], 1):  # ìƒìœ„ 3ê°œë§Œ ì¶œë ¥
                print(f"      {j}. {std_candidate.get('concept_name', 'N/A')} (ID: {std_candidate.get('concept_id', 'N/A')})")
            
            # ëª¨ë“  Standard í›„ë³´ë“¤ì„ ì„ì‹œ ì €ì¥ (ë‚˜ì¤‘ì— ìœ ì‚¬ë„ ì¬ê³„ì‚°)
            non_standard_to_standard_mappings.append({
                'non_standard_source': source,
                'non_standard_candidate': candidate,
                'standard_candidates': standard_candidates_from_non
            })
        else:
            print(f"    â†’ Maps to ê´€ê³„ ì—†ìŒ")
        
        print()
    
    # ===== 4ë‹¨ê³„: ëª¨ë“  í›„ë³´êµ°ì— ëŒ€í•´ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê¸°ë°˜ Re-ranking =====
    print(f"ğŸ¯ 4ë‹¨ê³„: ëª¨ë“  í›„ë³´êµ°ì— ëŒ€í•´ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê¸°ë°˜ Re-ranking")
    print(f"{'='*60}")
    
    all_standard_candidates = []
    
    # 1. Standard í›„ë³´ë“¤ì— ëŒ€í•´ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ì¬ê³„ì‚° (APIì™€ ë™ì¼í•œ ë°©ì‹)
    print("  ğŸ“Š Standard í›„ë³´ë“¤ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ì¬ê³„ì‚°:")
    for i, candidate in enumerate(standard_candidates, 1):
        source = candidate['_source']
        original_score = candidate['_score']
        
        # APIì˜ _calculate_hybrid_score ë©”ì„œë“œ ì‚¬ìš©í•˜ì—¬ ì¼ê´€ëœ ì ìˆ˜ ê³„ì‚°
        hybrid_score, text_sim, semantic_sim = api._calculate_hybrid_score(
            entity_name, 
            source.get('concept_name', ''),
            original_score,  # Elasticsearch ì ìˆ˜ ì „ë‹¬ (í•˜ì§€ë§Œ APIì—ì„œëŠ” ë¬´ì‹œë¨)
            source
        )
        
        print(f"    {i}. {source.get('concept_name', 'N/A')}")
        print(f"       í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜: {hybrid_score:.3f} (í…ìŠ¤íŠ¸: {text_sim:.3f}, ì˜ë¯¸: {semantic_sim:.3f})")
        
        all_standard_candidates.append({
            'concept': source,
            'final_score': hybrid_score,  # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ì‚¬ìš©
            'is_original_standard': True,
            'original_candidate': candidate,
            'elasticsearch_score': original_score,
            'hybrid_score': hybrid_score,
            'text_similarity': text_sim,
            'semantic_similarity': semantic_sim
        })
        print()
    
    # 2. Non-standard â†’ Standard í›„ë³´ë“¤ì— ëŒ€í•´ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ì¬ê³„ì‚°
    print("  ğŸ“Š Non-standard â†’ Standard í›„ë³´ë“¤ í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ì¬ê³„ì‚°:")
    for i, mapping in enumerate(non_standard_to_standard_mappings, 1):
        non_standard_source = mapping['non_standard_source']
        non_standard_candidate = mapping['non_standard_candidate']
        standard_candidates_list = mapping['standard_candidates']
        
        print(f"    Non-standard {i}: {non_standard_source.get('concept_name', 'N/A')}")
        
        for j, std_candidate in enumerate(standard_candidates_list, 1):
            # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê³„ì‚° (Non-standard â†’ Standardì˜ ê²½ìš° Elasticsearch ì ìˆ˜ëŠ” 0ìœ¼ë¡œ ì„¤ì •)
            hybrid_score, text_sim, semantic_sim = api._calculate_hybrid_score(
                entity_name, 
                std_candidate.get('concept_name', ''),
                0.0,  # Non-standard â†’ Standardì˜ ê²½ìš° Elasticsearch ì ìˆ˜ ì—†ìŒ
                std_candidate
            )
            
            print(f"      Standard {j}: {std_candidate.get('concept_name', 'N/A')}")
            print(f"        í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜: {hybrid_score:.3f} (í…ìŠ¤íŠ¸: {text_sim:.3f}, ì˜ë¯¸: {semantic_sim:.3f})")
            
            all_standard_candidates.append({
                'concept': std_candidate,
                'final_score': hybrid_score,  # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ì‚¬ìš©
                'is_original_standard': False,
                'original_non_standard': non_standard_source,
                'original_candidate': non_standard_candidate,
                'hybrid_score': hybrid_score,
                'text_similarity': text_sim,
                'semantic_similarity': semantic_sim
            })
        
        print()
    
    # ===== 5ë‹¨ê³„: ì ìˆ˜ ì •ê·œí™” (0.0~1.0) â†’ ìµœì¢… ë§¤í•‘ ê²°ê³¼ =====
    print(f"ğŸ“Š 5ë‹¨ê³„: ì ìˆ˜ ì •ê·œí™” (0.0~1.0) â†’ ìµœì¢… ë§¤í•‘ ê²°ê³¼")
    print(f"{'='*60}")
    
    if not all_standard_candidates:
        print("âŒ ì²˜ë¦¬ëœ í›„ë³´ ì—†ìŒ")
        return
    
    # ì¤‘ë³µ ì œê±° (ë™ì¼í•œ concept_idì™€ concept_nameì¸ ê²½ìš° ìµœê³  ì ìˆ˜ë§Œ ìœ ì§€)
    unique_candidates = {}
    for candidate in all_standard_candidates:
        concept = candidate['concept']
        concept_key = (concept.get('concept_id', ''), concept.get('concept_name', ''))
        
        # ë™ì¼í•œ ì»¨ì…‰ì´ ì´ë¯¸ ìˆëŠ” ê²½ìš° ë” ë†’ì€ ì ìˆ˜ë§Œ ìœ ì§€
        if concept_key not in unique_candidates or candidate['final_score'] > unique_candidates[concept_key]['final_score']:
            unique_candidates[concept_key] = candidate
    
    # ì¤‘ë³µ ì œê±°ëœ í›„ë³´ë“¤ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    deduplicated_candidates = list(unique_candidates.values())
    
    print(f"ì¤‘ë³µ ì œê±° ì „: {len(all_standard_candidates)}ê°œ â†’ ì¤‘ë³µ ì œê±° í›„: {len(deduplicated_candidates)}ê°œ")
    
    # ì ìˆ˜ë³„ ì •ë ¬ (í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê¸°ì¤€)
    sorted_candidates = sorted(deduplicated_candidates, key=lambda x: x['final_score'], reverse=True)
    
    print("ìµœì¢… í›„ë³´ ìˆœìœ„ (í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ ê¸°ì¤€):")
    for i, candidate in enumerate(sorted_candidates, 1):
        concept = candidate['concept']
        final_score = candidate['final_score']  # í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜
        is_standard = candidate['is_original_standard']
        mapping_type = "ì§ì ‘ Standard" if is_standard else "Non-standard â†’ Standard"
        
        # ì ìˆ˜ ì •ê·œí™” (í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜ëŠ” ì´ë¯¸ 0~1 ì‚¬ì´)
        normalized_score = api._normalize_score(final_score)
        confidence = api._determine_confidence(normalized_score)
        
        print(f"  {i}. í•˜ì´ë¸Œë¦¬ë“œ ì ìˆ˜: {final_score:.3f} â†’ ì •ê·œí™”: {normalized_score:.3f} ({confidence})")
        
        # ì„¸ë¶€ ì ìˆ˜ ì •ë³´
        if 'hybrid_score' in candidate:
            text_sim = candidate.get('text_similarity', 0.0)
            semantic_sim = candidate.get('semantic_similarity', 0.0)
            print(f"     â”” í…ìŠ¤íŠ¸: {text_sim:.3f} | ì˜ë¯¸: {semantic_sim:.3f}")
        
        print(f"     ì»¨ì…‰ ID: {concept.get('concept_id', 'N/A')}")
        print(f"     ì»¨ì…‰ëª…: {concept.get('concept_name', 'N/A')}")
        print(f"     ë„ë©”ì¸: {concept.get('domain_id', 'N/A')}")
        print(f"     ì–´íœ˜ì²´ê³„: {concept.get('vocabulary_id', 'N/A')}")
        print(f"     ë§¤í•‘ ë°©ë²•: {mapping_type}")
        
        print()
    
    # ===== 6ë‹¨ê³„: APIì˜ map_entity í•¨ìˆ˜ë¡œ ìµœì¢… ë§¤í•‘ ê²°ê³¼ í™•ì¸ =====
    print(f"ğŸ¯ 6ë‹¨ê³„: APIì˜ map_entity í•¨ìˆ˜ë¡œ ìµœì¢… ë§¤í•‘ ê²°ê³¼ í™•ì¸")
    print(f"{'='*60}")
    
    # APIì˜ map_entity í•¨ìˆ˜ í˜¸ì¶œ
    mapping_result = api.map_entity(entity_input)
    
    if mapping_result:
        print(f"âœ… API ë§¤í•‘ ì„±ê³µ!")
        print(f"   ë§¤í•‘ëœ ì»¨ì…‰ ID: {mapping_result.mapped_concept_id}")
        print(f"   ë§¤í•‘ëœ ì»¨ì…‰ëª…: {mapping_result.mapped_concept_name}")
        print(f"   ë§¤í•‘ ì ìˆ˜: {mapping_result.mapping_score:.3f}")
        print(f"   ë§¤í•‘ ì‹ ë¢°ë„: {mapping_result.mapping_confidence}")
        print(f"   ë§¤í•‘ ë°©ë²•: {mapping_result.mapping_method}")
        
        # ê³¨ë“ ì…‹ê³¼ ë¹„êµ
        print(f"\nğŸ¯ ê³¨ë“ ì…‹ ë¹„êµ:")
        if mapping_result.mapped_concept_id == golden_concept_id:
            print(f"  âœ… ì„±ê³µ! ê³¨ë“ ì…‹ê³¼ ì •í™•íˆ ì¼ì¹˜")
        else:
            print(f"  âŒ ë¶ˆì¼ì¹˜")
        
        print(f"  ì˜ˆìƒ: {golden_concept_id} - {golden_concept_name}")
        print(f"  ì‹¤ì œ: {mapping_result.mapped_concept_id} - {mapping_result.mapped_concept_name}")
    else:
        print("âŒ API ë§¤í•‘ ì‹¤íŒ¨")
    
    print(f"\n{'='*80}")


def main():
    """ë©”ì¸ í…ŒìŠ¤íŠ¸ í•¨ìˆ˜"""
    print("ğŸš€ ì—”í‹°í‹° ë§¤í•‘ API í…ŒìŠ¤íŠ¸ ì‹œì‘")
    
    # API ìƒíƒœ í™•ì¸
    api = EntityMappingAPI()
    health_check = api.health_check()
    print(f"ğŸ“Š API ìƒíƒœ: {health_check}")
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: Adrenal Cushing's syndrome
    print("\n" + "="*80)
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 1: Adrenal Cushing's syndrome")
    print("="*80)
    test_entity_mapping_6_steps(
        entity_name="Adrenal Cushing's syndrome",
        domain_id="condition",
        golden_concept_id="4030206",
        golden_concept_name="Adrenal Cushing's syndrome"
    )
    
    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: Acute Coronary Syndromes (ACS)
    print("\n" + "="*80)
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 2: Acute Coronary Syndromes (ACS)")
    print("="*80)
    test_entity_mapping_6_steps(
        entity_name="Acute Coronary Syndromes (ACS)",
        domain_id="condition",
        golden_concept_id="4215140",
        golden_concept_name="Acute coronary syndrome"
    )

    # í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: ST-segment elevation myocardial infarction (STEMI)
    print("\n" + "="*80)
    print("ğŸ“‹ í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ 3: ST-segment elevation myocardial infarction (STEMI)")
    print("="*80)
    test_entity_mapping_6_steps(
        entity_name="ST-segment elevation myocardial infarction (STEMI)",
        domain_id="condition",
        golden_concept_id="4296653",
        golden_concept_name="Acute ST segment elevation myocardial infarction"
    )
    
    print("\nğŸ‰ ëª¨ë“  í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")


if __name__ == "__main__":
    main()