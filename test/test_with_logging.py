import pandas as pd
import logging
import os
from datetime import datetime
from pathlib import Path
import sys
import openpyxl
from openpyxl.styles import Font, Alignment, PatternFill
from openpyxl.utils.dataframe import dataframe_to_rows
from tqdm import tqdm
import time

# ìƒëŒ€ ê²½ë¡œë¡œ src ë””ë ‰í† ë¦¬ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent / 'src'))

from MapOMOP.entity_mapping_api import EntityMappingAPI, EntityInput, DomainID
from MapOMOP.elasticsearch_client import ElasticsearchClient

class EntityMappingTester:
    def __init__(self, log_dir: str = "test_logs", scoring_mode: str = "llm"):
        """í…ŒìŠ¤í„° ì´ˆê¸°í™”
        
        Args:
            log_dir: ë¡œê·¸ ë””ë ‰í† ë¦¬
            scoring_mode: Stage 3 ì ìˆ˜ ê³„ì‚° ë°©ì‹
                - 'llm': LLM without score (ë””í´íŠ¸)
                - 'llm_with_score': LLM with semantic score in prompt
                - 'semantic': Semantic similarity only
        """
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        self.scoring_mode = scoring_mode
        
        self.setup_logging()
        
        self.es_client = ElasticsearchClient()
        self.es_client.concept_index = "concept-small"
        self.es_client.concept_synonym_index = "concept-synonym"
        
        self.api = EntityMappingAPI(
            es_client=self.es_client,
            scoring_mode=scoring_mode
        )
        
        self.logger.info(f"âœ… Scoring Mode: {scoring_mode}")
        
        self.domain_mapping = {
            'Condition': DomainID.CONDITION,
            'Procedure': DomainID.PROCEDURE,
            'Drug': DomainID.DRUG,
            'Observation': DomainID.OBSERVATION,
            'Measurement': DomainID.MEASUREMENT,
            'Period': DomainID.PERIOD,
            'Provider': DomainID.PROVIDER,
            'Device': DomainID.DEVICE,
        }
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        log_file = self.log_dir / f"entity_mapping_test_{timestamp}.log"
        
        self.logger = logging.getLogger('entity_mapping_test')
        self.logger.setLevel(logging.INFO)
        
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
        api_logger = logging.getLogger('MapOMOP.entity_mapping_api')
        api_logger.setLevel(logging.INFO)
        api_logger.addHandler(file_handler)
        
        stage1_logger = logging.getLogger('MapOMOP.mapping_stages.stage1_candidate_retrieval')
        stage1_logger.setLevel(logging.INFO)
        stage1_logger.addHandler(file_handler)
        
        stage2_logger = logging.getLogger('MapOMOP.mapping_stages.stage2_standard_collection')
        stage2_logger.setLevel(logging.INFO)
        stage2_logger.addHandler(file_handler)
        
        stage3_logger = logging.getLogger('MapOMOP.mapping_stages.stage3_hybrid_scoring')
        stage3_logger.setLevel(logging.INFO)
        stage3_logger.addHandler(file_handler)
        
        self.logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file}")
    
    def load_test_data_from_list(self, entity_list: list) -> pd.DataFrame:
        """ë¦¬ìŠ¤íŠ¸ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±
        
        Args:
            entity_list: ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸. ë‹¤ìŒ í˜•ì‹ ì§€ì›:
                - ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸: ['entity1', 'entity2', ...]
                - (entity, domain) íŠœí”Œ ë¦¬ìŠ¤íŠ¸: [('entity1', 'Condition'), ('entity2', 'Drug'), ...]
                - domainì´ Noneì´ë©´ ëª¨ë“  ë„ë©”ì¸ ê²€ìƒ‰
        """
        self.logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: {len(entity_list)}ê°œ ì—”í‹°í‹°")
        
        test_data = []
        for i, item in enumerate(entity_list):
            # (entity, domain) íŠœí”Œì¸ ê²½ìš°
            if isinstance(item, tuple) and len(item) == 2:
                entity_name, domain = item
                test_data.append({
                    'entity_plain_name': entity_name,
                    'entity_domain': domain,
                    'sheet': 'manual'
                })
                domain_str = domain if domain else 'All'
                self.logger.info(f"  {i+1}. {entity_name} [{domain_str}]")
            # ë¬¸ìì—´ì¸ ê²½ìš°
            else:
                test_data.append({
                    'entity_plain_name': item,
                    'entity_domain': None,
                    'sheet': 'manual'
                })
                self.logger.info(f"  {i+1}. {item} [All]")
        
        df = pd.DataFrame(test_data)
        self.logger.info(f"ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(df)}ê°œ ì—”í‹°í‹°")
        
        # ë„ë©”ì¸ ë¶„í¬ ì¶œë ¥
        if 'entity_domain' in df.columns:
            domain_dist = df['entity_domain'].fillna('All').value_counts()
            self.logger.info("\në„ë©”ì¸ ë¶„í¬:")
            for domain, count in domain_dist.items():
                self.logger.info(f"  {domain}: {count}ê°œ")
        
        return df
    
    def create_entity_input(self, row) -> EntityInput:
        """DataFrame í–‰ì—ì„œ EntityInput ìƒì„±"""
        entity_name = str(row['entity_plain_name']).strip()
        
        # ë„ë©”ì¸ì€ ê¸°ë³¸ì ìœ¼ë¡œ None (ëª¨ë“  ë„ë©”ì¸ ê²€ìƒ‰)
        # ì‚¬ìš©ìê°€ entity_domainì„ ì§€ì •í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©
        domain_id = None
        if 'entity_domain' in row and pd.notna(row['entity_domain']):
            domain_str = str(row['entity_domain']).strip()
            if domain_str and domain_str in self.domain_mapping:
                domain_id = self.domain_mapping[domain_str]
        
        return EntityInput(
            entity_name=entity_name,
            domain_id=domain_id,
            vocabulary_id=None
        )
    
    def test_single_entity(self, entity_input: EntityInput, test_index: int, sheet: str) -> dict:
        """ë‹¨ì¼ ì—”í‹°í‹° í…ŒìŠ¤íŠ¸ (ë„ë©”ì¸ë³„ ê²°ê³¼)"""
        input_domain = entity_input.domain_id.value if entity_input.domain_id else 'All'
        
        self.logger.info("=" * 100)
        self.logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ #{test_index} [{input_domain}]: {entity_input.entity_name}")
        self.logger.info("=" * 100)
        
        try:
            # ë§¤í•‘ ìˆ˜í–‰ (ë„ë©”ì¸ë³„ ê²°ê³¼ ë°˜í™˜)
            results = self.api.map_entity(entity_input)
            
            # ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´ ë¡œê¹… (ë§ˆì§€ë§‰ ë„ë©”ì¸)
            stage1_candidates = []
            stage2_candidates = []
            stage3_candidates = []
            
            if hasattr(self.api, '_last_stage1_candidates') and self.api._last_stage1_candidates:
                stage1_candidates = self.api._last_stage1_candidates
            
            if hasattr(self.api, '_last_stage2_candidates') and self.api._last_stage2_candidates:
                stage2_candidates = self.api._last_stage2_candidates
                self.logger.info("ğŸ“Š Stage 2 í›„ë³´êµ° ìƒì„¸ ì •ë³´:")
                for i, candidate in enumerate(stage2_candidates, 1):
                    search_type = candidate.get('search_type', 'unknown')
                    is_std = "âœ“" if candidate['is_original_standard'] else "â†’"
                    self.logger.info(f"   {i}. [{search_type}] {is_std} {candidate['concept_name']} (ID: {candidate['concept_id']})")
                    self.logger.info(f"      - Domain: {candidate.get('domain_id', 'N/A')}, Vocabulary: {candidate['vocabulary_id']}")
            
            if hasattr(self.api, '_last_rerank_candidates') and self.api._last_rerank_candidates:
                stage3_candidates = self.api._last_rerank_candidates
                # LLM ëª¨ë“œì¸ ê²½ìš° Stage 3 ê²°ê³¼ ìƒì„¸ ë¡œê¹…
                if self.scoring_mode in ['llm', 'llm_with_score'] and stage3_candidates:
                    header = "ğŸ“Š Stage 3 LLM í‰ê°€ ê²°ê³¼"
                    if self.scoring_mode == 'llm_with_score':
                        header += " (SapBERT ì˜ë¯¸ìœ ì‚¬ë„ í¬í•¨)"
                    self.logger.info(f"\n{header}:")
                    for i, candidate in enumerate(stage3_candidates[:10], 1):
                        llm_score = candidate.get('llm_score', candidate.get('final_score', 0))
                        llm_rank = candidate.get('llm_rank', i)
                        llm_reasoning = candidate.get('llm_reasoning', 'N/A')
                        semantic_sim = candidate.get('semantic_similarity')
                        
                        self.logger.info(f"   {i}. {candidate['concept_name']} (ID: {candidate['concept_id']})")
                        if semantic_sim is not None:
                            self.logger.info(f"      - LLM ì ìˆ˜: {llm_score}, ìˆœìœ„: {llm_rank}, ì˜ë¯¸ìœ ì‚¬ë„: {semantic_sim:.4f}")
                        else:
                            self.logger.info(f"      - LLM ì ìˆ˜: {llm_score}, ìˆœìœ„: {llm_rank}")
                        if llm_reasoning and llm_reasoning != 'N/A':
                            reasoning_short = llm_reasoning[:80] + '...' if len(llm_reasoning) > 80 else llm_reasoning
                            self.logger.info(f"      - ì´ìœ : {reasoning_short}")
            
            # ë„ë©”ì¸ë³„ ê²°ê³¼ ì •ë¦¬
            domain_results = []
            if results:
                self.logger.info("\n" + "=" * 100)
                self.logger.info("ğŸ“Š ë„ë©”ì¸ë³„ ë§¤í•‘ ê²°ê³¼ ìš”ì•½")
                self.logger.info("=" * 100)
                
                for idx, result in enumerate(results, 1):
                    domain_info = {
                        'domain_id': result.domain_id,
                        'mapped_concept_id': result.mapped_concept_id,
                        'mapped_concept_name': result.mapped_concept_name,
                        'mapping_score': result.mapping_score,
                        'mapping_confidence': result.mapping_confidence,
                        'mapping_method': result.mapping_method,
                        'vocabulary_id': result.vocabulary_id
                    }
                    domain_results.append(domain_info)
                    
                    self.logger.info(f"\n{idx}. [{result.domain_id}] ë§¤í•‘ ì„±ê³µ!")
                    self.logger.info(f"   ê°œë…: {result.mapped_concept_name} (ID: {result.mapped_concept_id})")
                    self.logger.info(f"   ì ìˆ˜: {result.mapping_score:.4f} | ì‹ ë¢°ë„: {result.mapping_confidence}")
                    self.logger.info(f"   ë°©ë²•: {result.mapping_method} | Vocabulary: {result.vocabulary_id}")
            
            # ê²°ê³¼ ì •ë¦¬ (ìµœê³  ì ìˆ˜ ë„ë©”ì¸ ì„ íƒ)
            best_result = max(results, key=lambda x: x.mapping_score) if results else None
            
            # ë„ë©”ì¸ë³„ Stage ê²½ë¡œ ì •ë³´ ì¶”ì¶œ
            domain_stage_paths = {}
            best_search_domain = None
            if hasattr(self.api, '_all_domain_stage_results') and self.api._all_domain_stage_results:
                domain_stage_paths = self.api._all_domain_stage_results
                
                # Best resultì˜ ê²€ìƒ‰ ë„ë©”ì¸ ì°¾ê¸°
                if best_result:
                    for search_domain, stage_info in domain_stage_paths.items():
                        if stage_info.get('result_domain') == best_result.domain_id:
                            best_search_domain = search_domain
                            break
            
            test_result = {
                'test_index': test_index,
                'sheet': sheet,
                'entity_name': entity_input.entity_name,
                'input_domain': input_domain,
                'success': results is not None and len(results) > 0,
                'domain_count': len(results) if results else 0,
                'domain_results': domain_results,
                'domain_stage_paths': domain_stage_paths,
                'best_search_domain': best_search_domain,
                'best_result_domain': best_result.domain_id if best_result else None,
                'best_concept_id': best_result.mapped_concept_id if best_result else None,
                'best_concept_name': best_result.mapped_concept_name if best_result else None,
                'best_score': best_result.mapping_score if best_result else 0.0,
                'best_confidence': best_result.mapping_confidence if best_result else None,
                'stage1_candidates': stage1_candidates,
                'stage2_candidates': stage2_candidates,
                'stage3_candidates': stage3_candidates
            }
            
            if not results:
                self.logger.info(f"âŒ ëª¨ë“  ë„ë©”ì¸ì—ì„œ ë§¤í•‘ ì‹¤íŒ¨")
            else:
                self.logger.info(f"\n" + "=" * 100)
                self.logger.info(f"ğŸ“Š ìµœì¢… ìš”ì•½: {len(results)}ê°œ ë„ë©”ì¸ì—ì„œ ë§¤í•‘ ì„±ê³µ")
                self.logger.info("=" * 100)
                self.logger.info(f"ğŸ† ìµœê³  ì ìˆ˜: [{best_result.domain_id}] {best_result.mapped_concept_name} ({best_result.mapping_score:.4f})")
                
                # ë„ë©”ì¸ë³„ Stage ê²½ë¡œ ì¶œë ¥
                if hasattr(self.api, '_all_domain_stage_results') and self.api._all_domain_stage_results:
                    self.logger.info(f"\nğŸ“ˆ ë„ë©”ì¸ë³„ Stage ê²½ë¡œ:")
                    for domain_name, stage_info in self.api._all_domain_stage_results.items():
                        self.logger.info(f"  [{domain_name}] Stage1: {stage_info.get('stage1_count', 0)}ê°œ â†’ "
                                       f"Stage2: {stage_info.get('stage2_count', 0)}ê°œ â†’ "
                                       f"Stage3: {stage_info.get('stage3_count', 0)}ê°œ")
                self.logger.info("=" * 100)
                
            return test_result
            
        except Exception as e:
            self.logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
            return {
                'test_index': test_index,
                'sheet': sheet,
                'entity_name': entity_input.entity_name,
                'input_domain': input_domain,
                'success': False,
                'domain_count': 0,
                'domain_results': [],
                'best_search_domain': None,
                'best_result_domain': None,
                'best_concept_id': None,
                'best_concept_name': None,
                'best_score': 0.0,
                'best_confidence': None,
                'error': str(e),
                'stage1_candidates': [],
                'stage2_candidates': [],
                'stage3_candidates': []
            }
    
    def run_test_with_entities(self, entity_list: list, max_entities: int = None):
        """ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        
        Args:
            entity_list: ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸ (ë¬¸ìì—´ ë˜ëŠ” (entity, domain) íŠœí”Œ)
            max_entities: í…ŒìŠ¤íŠ¸í•  ìµœëŒ€ ì—”í‹°í‹° ìˆ˜
        """
        self.logger.info("=" * 100)
        self.logger.info("ğŸš€ Entity Mapping API í…ŒìŠ¤íŠ¸ ì‹œì‘")
        self.logger.info("=" * 100)
        self.logger.info(f"í…ŒìŠ¤íŠ¸ ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸: {len(entity_list)}ê°œ")
        self.logger.info(f"Scoring Mode: {self.scoring_mode}")
        
        start_time = time.time()
        
        # ë°ì´í„° ìƒì„±
        test_data = self.load_test_data_from_list(entity_list)
        
        if max_entities:
            test_data = test_data.head(max_entities)
            self.logger.info(f"í…ŒìŠ¤íŠ¸ ì œí•œ: ìµœëŒ€ {max_entities}ê°œ ì—”í‹°í‹°")
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        test_results = []
        successful_tests = 0
        
        # tqdmìœ¼ë¡œ ì§„í–‰ ìƒí™© í‘œì‹œ
        for idx, row in tqdm(test_data.iterrows(), total=len(test_data), desc="ì—”í‹°í‹° ë§¤í•‘ í…ŒìŠ¤íŠ¸"):
            try:
                entity_input = self.create_entity_input(row)
                result = self.test_single_entity(entity_input, idx + 1, row['sheet'])
                test_results.append(result)
                
                if result['success']:
                    successful_tests += 1
                    
            except Exception as e:
                self.logger.error(f"í…ŒìŠ¤íŠ¸ #{idx + 1} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì‹œê°„
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        # ê²°ê³¼ ìš”ì•½
        total_tests = len(test_results)
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        self.logger.info("\n" + "=" * 100)
        self.logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        self.logger.info("=" * 100)
        self.logger.info(f"ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
        self.logger.info(f"ë§¤í•‘ ì„±ê³µ: {successful_tests}ê°œ ({success_rate:.2f}%)")
        self.logger.info(f"ë§¤í•‘ ì‹¤íŒ¨: {total_tests - successful_tests}ê°œ")
        self.logger.info(f"ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ ({elapsed_time/60:.2f}ë¶„)")
        if total_tests > 0:
            self.logger.info(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {elapsed_time/total_tests:.3f}ì´ˆ/ì—”í‹°í‹°")
        
        # ì—”í‹°í‹°ë³„ ìš”ì•½
        self.logger.info("\nğŸ“‹ ì—”í‹°í‹°ë³„ ê²°ê³¼:")
        for i, result in enumerate(test_results, 1):
            status = "âœ… ì„±ê³µ" if result['success'] else "âŒ ì‹¤íŒ¨"
            input_domain = result.get('input_domain', 'All')
            self.logger.info(f"  {i}. [{input_domain}] {result['entity_name']}: {status}")
            if result['success']:
                search_domain = result.get('best_search_domain', 'N/A')
                result_domain = result.get('best_result_domain', 'N/A')
                if search_domain == result_domain:
                    domain_info = f"[{result_domain}]"
                else:
                    domain_info = f"[{search_domain} â†’ {result_domain}]"
                self.logger.info(f"     -> {domain_info} {result.get('best_concept_name', 'N/A')} (ì ìˆ˜: {result.get('best_score', 0.0):.4f})")
        
        # ê²°ê³¼ë¥¼ CSVì™€ XLSXë¡œ ì €ì¥
        self.save_results_to_csv(test_results)
        self.save_results_to_xlsx(test_results)
        
        return test_results
    
    def save_results_to_csv(self, test_results: list):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥ (ë„ë©”ì¸ë³„ ê²°ê³¼ í¬í•¨)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_file = self.log_dir / f"test_results_{self.scoring_mode}_{timestamp}.csv"
        
        # CSVìš© ë°ì´í„° ì •ë¦¬ (ë„ë©”ì¸ë³„ ê²°ê³¼ í‰íƒ„í™”)
        csv_results = []
        for result in test_results:
            # ê¸°ë³¸ ì •ë³´
            base_info = {
                'test_index': result['test_index'],
                'entity_name': result['entity_name'],
                'input_domain': result.get('input_domain', 'All'),
                'success': result['success'],
                'domain_count': result.get('domain_count', 0),
                'best_search_domain': result.get('best_search_domain', 'N/A'),
                'best_result_domain': result.get('best_result_domain', 'N/A'),
                'best_concept_id': result.get('best_concept_id', 'N/A'),
                'best_concept_name': result.get('best_concept_name', 'N/A'),
                'best_score': result.get('best_score', 0.0),
                'best_confidence': result.get('best_confidence', 'N/A')
            }
            csv_results.append(base_info)
        
        df_results = pd.DataFrame(csv_results)
        df_results.to_csv(csv_file, index=False, encoding='utf-8')
        
        self.logger.info(f"ğŸ“„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ CSV ì €ì¥: {csv_file}")
    
    def save_results_to_xlsx(self, test_results: list):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ XLSX íŒŒì¼ë¡œ ì €ì¥ (stage1, stage3 í›„ë³´êµ°ì„ ì—´ë¡œ ë¶„ë¦¬)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        xlsx_file = self.log_dir / f"test_results_detailed_{self.scoring_mode}_{timestamp}.xlsx"
        
        # ì—‘ì…€ ì›Œí¬ë¶ ìƒì„±
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "Detailed Results"
        
        # í†µí•© ìƒì„¸ ì‹œíŠ¸ ìƒì„±
        self._create_integrated_detail_sheet(ws, test_results)
        
        # íŒŒì¼ ì €ì¥
        wb.save(xlsx_file)
        self.logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ XLSX ì €ì¥: {xlsx_file}")
    
    def _create_integrated_detail_sheet(self, ws, test_results):
        """í†µí•© ìƒì„¸ ì‹œíŠ¸ ìƒì„± (ëª¨ë“  ì—”í‹°í‹°ë¥¼ í•˜ë‚˜ì˜ ì‹œíŠ¸ì—, ë„ë©”ì¸ë³„ ê²°ê³¼ í¬í•¨)"""
        
        # í—¤ë” ì„¤ì •
        headers = [
            "Test Index", "Entity Name", "Input Domain", "Success", "Domain Count",
            "Best Search Domain", "Best Result Domain", "Best Concept ID", "Best Concept Name", 
            "Best Score", "Best Confidence",
            "All Domains", "Domain Stage Paths", "Stage1 Candidates", "Stage2 Candidates", "Stage3 Candidates"
        ]
        
        # í—¤ë” ìŠ¤íƒ€ì¼
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        header_alignment = Alignment(horizontal="center", vertical="center")
        
        # í—¤ë” ì‘ì„±
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col, value=header)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = header_alignment
        
        # ë°ì´í„° ì‘ì„±
        for row, result in enumerate(test_results, 2):
            ws.cell(row=row, column=1, value=result['test_index'])
            ws.cell(row=row, column=2, value=result['entity_name'])
            ws.cell(row=row, column=3, value=result.get('input_domain', 'All'))
            ws.cell(row=row, column=4, value="ì„±ê³µ" if result['success'] else "ì‹¤íŒ¨")
            ws.cell(row=row, column=5, value=result.get('domain_count', 0))
            ws.cell(row=row, column=6, value=result.get('best_search_domain', 'N/A'))
            ws.cell(row=row, column=7, value=result.get('best_result_domain', 'N/A'))
            ws.cell(row=row, column=8, value=result.get('best_concept_id', 'N/A'))
            ws.cell(row=row, column=9, value=result.get('best_concept_name', 'N/A'))
            ws.cell(row=row, column=10, value=result.get('best_score', 0.0))
            ws.cell(row=row, column=11, value=result.get('best_confidence', 'N/A'))
            
            # ëª¨ë“  ë„ë©”ì¸ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            domain_results_text = self._format_domain_results(result.get('domain_results', []))
            ws.cell(row=row, column=12, value=domain_results_text)
            
            # ë„ë©”ì¸ë³„ Stage ê²½ë¡œ ì •ë³´
            stage_paths_text = self._format_stage_paths(result.get('domain_stage_paths', {}))
            ws.cell(row=row, column=13, value=stage_paths_text)
            
            # Stage1 í›„ë³´êµ° ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            stage1_text = self._format_candidates_for_cell(result.get('stage1_candidates', []), 'stage1')
            ws.cell(row=row, column=14, value=stage1_text)
            
            # Stage2 í›„ë³´êµ° ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            stage2_text = self._format_candidates_for_cell(result.get('stage2_candidates', []), 'stage2')
            ws.cell(row=row, column=15, value=stage2_text)
            
            # Stage3 í›„ë³´êµ° ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            stage3_text = self._format_candidates_for_cell(result.get('stage3_candidates', []), 'stage3')
            ws.cell(row=row, column=16, value=stage3_text)
            
            # ì…€ ìŠ¤íƒ€ì¼ ì„¤ì • (í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ í—ˆìš©)
            for col in range(12, 17):  # All Domains, Stage Paths, Stage1, Stage2, Stage3 ì—´
                cell = ws.cell(row=row, column=col)
                cell.alignment = Alignment(wrap_text=True, vertical='top')
        
        # ì—´ ë„ˆë¹„ ì„¤ì •
        column_widths = {
            'A': 10,  # Test Index
            'B': 35,  # Entity Name
            'C': 15,  # Input Domain
            'D': 10,  # Success
            'E': 12,  # Domain Count
            'F': 15,  # Best Search Domain
            'G': 15,  # Best Result Domain
            'H': 15,  # Best Concept ID
            'I': 45,  # Best Concept Name
            'J': 12,  # Best Score
            'K': 15,  # Best Confidence
            'L': 50,  # All Domains
            'M': 45,  # Domain Stage Paths
            'N': 70,  # Stage1 Candidates
            'O': 70,  # Stage2 Candidates
            'P': 85   # Stage3 Candidates
        }
        
        for col_letter, width in column_widths.items():
            ws.column_dimensions[col_letter].width = width
        
        # í–‰ ë†’ì´ ìë™ ì¡°ì • (í›„ë³´êµ° ì •ë³´ê°€ ë§ì€ ê²½ìš°)
        for row_num in range(2, len(test_results) + 2):
            ws.row_dimensions[row_num].height = 150  # ì¶©ë¶„í•œ ë†’ì´ ì„¤ì •
    
    def _format_domain_results(self, domain_results):
        """ë„ë©”ì¸ë³„ ê²°ê³¼ë¥¼ ì—‘ì…€ ì…€ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if not domain_results:
            return "ë„ë©”ì¸ ê²°ê³¼ ì—†ìŒ"
        
        lines = []
        for i, domain in enumerate(domain_results, 1):
            line = f"{i}. [{domain.get('domain_id', 'N/A')}] {domain.get('mapped_concept_name', 'N/A')}\n"
            line += f"   ID: {domain.get('mapped_concept_id', 'N/A')}, "
            line += f"Score: {domain.get('mapping_score', 0):.4f}, "
            line += f"Conf: {domain.get('mapping_confidence', 'N/A')}\n"
            line += f"   Vocab: {domain.get('vocabulary_id', 'N/A')}"
            lines.append(line)
        
        return "\n\n".join(lines)
    
    def _format_stage_paths(self, stage_paths):
        """ë„ë©”ì¸ë³„ Stage ê²½ë¡œë¥¼ ì—‘ì…€ ì…€ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if not stage_paths:
            return "ê²½ë¡œ ì •ë³´ ì—†ìŒ"
        
        lines = []
        for domain_name, stage_info in sorted(stage_paths.items()):
            search_domain = stage_info.get('search_domain', domain_name)
            result_domain = stage_info.get('result_domain', 'N/A')
            
            # ê²€ìƒ‰ ë„ë©”ì¸ê³¼ ê²°ê³¼ ë„ë©”ì¸ì´ ë‹¤ë¥¸ ê²½ìš° í‘œì‹œ
            if search_domain != result_domain:
                line = f"[{search_domain} â†’ {result_domain}]\n"
            else:
                line = f"[{search_domain}]\n"
            
            line += f"  Stage1: {stage_info.get('stage1_count', 0)}ê°œ\n"
            line += f"  Stage2: {stage_info.get('stage2_count', 0)}ê°œ\n"
            line += f"  Stage3: {stage_info.get('stage3_count', 0)}ê°œ"
            lines.append(line)
        
        return "\n\n".join(lines)
    
    def _format_candidates_for_cell(self, candidates, stage_type):
        """í›„ë³´êµ° ì •ë³´ë¥¼ ì—‘ì…€ ì…€ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if not candidates:
            return "í›„ë³´ ì—†ìŒ"
        
        lines = []
        max_candidates = 15 if stage_type == 'stage1' else (15 if stage_type == 'stage2' else 10)  # Stage1, Stage2ëŠ” 15ê°œ, Stage3ëŠ” 10ê°œ í‘œì‹œ
        
        for i, candidate in enumerate(candidates[:max_candidates], 1):
            if stage_type == 'stage1':
                search_type = candidate.get('search_type', 'unknown')
                line = f"{i}. [{search_type}] {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                line += f"   ESì ìˆ˜: {candidate.get('elasticsearch_score', 0):.4f}, "
                line += f"Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Domain: {candidate.get('domain_id', 'N/A')}"
            elif stage_type == 'stage2':
                search_type = candidate.get('search_type', 'unknown')
                is_std = "âœ“" if candidate.get('is_original_standard', True) else "â†’"
                line = f"{i}. [{search_type}] {is_std} {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                line += f"   Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Domain: {candidate.get('domain_id', 'N/A')}"
                if not candidate.get('is_original_standard', True):
                    original_non_std = candidate.get('original_non_standard', {})
                    if original_non_std:
                        line += f"\n   ì›ë³¸ Non-std: {original_non_std.get('concept_name', 'N/A')} (ID: {original_non_std.get('concept_id', 'N/A')})"
            else:  # stage3
                search_type = candidate.get('search_type', 'unknown')
                line = f"{i}. [{search_type}] {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                
                # LLM ëª¨ë“œì¸ ê²½ìš° LLM ì ìˆ˜/ìˆœìœ„/ì´ìœ  í‘œì‹œ
                llm_score = candidate.get('llm_score')
                llm_rank = candidate.get('llm_rank')
                llm_reasoning = candidate.get('llm_reasoning')
                semantic_sim = candidate.get('semantic_similarity')
                
                if llm_score is not None:
                    if semantic_sim is not None:
                        line += f"   LLMì ìˆ˜: {llm_score}, ìˆœìœ„: {llm_rank}, ì˜ë¯¸ìœ ì‚¬ë„: {semantic_sim:.4f}\n"
                    else:
                        line += f"   LLMì ìˆ˜: {llm_score}, ìˆœìœ„: {llm_rank}\n"
                    if llm_reasoning:
                        reasoning_short = llm_reasoning[:60] + '...' if len(llm_reasoning) > 60 else llm_reasoning
                        line += f"   ì´ìœ : {reasoning_short}\n"
                else:
                    # Hybrid ëª¨ë“œì¸ ê²½ìš°
                    line += f"   í…ìŠ¤íŠ¸: {candidate.get('text_similarity', 0):.4f}, "
                    line += f"ì˜ë¯¸ì : {candidate.get('semantic_similarity', 0):.4f}, "
                    line += f"ìµœì¢…: {candidate.get('final_score', 0):.4f}\n"
                
                line += f"   Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Domain: {candidate.get('domain_id', 'N/A')}"
            
            lines.append(line)
        
        return "\n\n".join(lines)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ============================================================
    # ì„¤ì • ì˜µì…˜
    # ============================================================
    # scoring_mode ì„ íƒ: 'llm' (ë””í´íŠ¸), 'llm_with_score', 'semantic'
    SCORING_MODE = "llm"
    
    # í…ŒìŠ¤í„° ì´ˆê¸°í™”
    tester = EntityMappingTester(
        log_dir="test_logs",
        scoring_mode=SCORING_MODE
    )
    
    # ============================================================
    # í…ŒìŠ¤íŠ¸í•  ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸
    # í˜•ì‹: ë¬¸ìì—´ ë˜ëŠ” (entity, domain) íŠœí”Œ
    # domain: 'Condition', 'Procedure', 'Drug', 'Observation', 
    #         'Measurement', 'Device' ë˜ëŠ” None (ëª¨ë“  ë„ë©”ì¸)
    # ============================================================
    test_entities = [
        # (entity, domain) íŠœí”Œ í˜•ì‹ - íŠ¹ì • ë„ë©”ì¸ ì§€ì •
        ('decompression', 'Procedure'),
        ('procedure', 'Procedure'),
        ('acute coronary syndrome', 'Condition'),
        ('flexible bronchoscopic removal of trachea or bronchial foreign body', 'Procedure')
        # ('mass removal', 'Procedure'),
        # ('congenital ring syndrome', 'Condition'),
        # ('monophasic synovial sarcoma', 'Observation'),
        # ('anaplastic astrocytoma', 'Observation'),
        # ('sacroiliac joint block', 'Procedure'),
        # ('endometrial polypectomy', 'Procedure'),
        # ('mandibular nerve block', 'Procedure'),
    ]
    
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    results = tester.run_test_with_entities(test_entities)
    
    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ë¡œê·¸ëŠ” {tester.log_dir} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    print(f"   - Scoring Mode: {SCORING_MODE}")

if __name__ == "__main__":
    main()