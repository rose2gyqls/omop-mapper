#!/usr/bin/env python3
"""
Elasticsearch ì¸ë±ìŠ¤ ë‚´ìš© ì¡°íšŒ ë° ë¡œê·¸ ì €ì¥ ìŠ¤í¬ë¦½íŠ¸

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Elasticsearchì˜ ëª¨ë“  ì¸ë±ìŠ¤ë¥¼ ì¡°íšŒí•˜ê³ ,
ê° ì¸ë±ìŠ¤ì˜ ë©”íƒ€ë°ì´í„°ì™€ ìƒ˜í”Œ ë¬¸ì„œë“¤ì„ ë¡œê·¸ íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
"""

import os
import json
import logging
from datetime import datetime
from typing import Dict, List, Any, Optional
from elasticsearch import Elasticsearch
from elasticsearch.exceptions import ConnectionError, RequestError


class ElasticsearchIndexInspector:
    """Elasticsearch ì¸ë±ìŠ¤ ê²€ì‚¬ê¸°"""
    
    def __init__(
        self,
        host: str = None,
        port: int = None,
        username: str = None,
        password: str = None,
        scheme: str = "http"
    ):
        """
        Elasticsearch ì¸ë±ìŠ¤ ê²€ì‚¬ê¸° ì´ˆê¸°í™”
        
        Args:
            host: ES ì„œë²„ í˜¸ìŠ¤íŠ¸ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” 3.35.110.161)
            port: ES ì„œë²„ í¬íŠ¸ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” 9200)
            username: ì‚¬ìš©ìëª… (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” elastic)
            password: ë¹„ë°€ë²ˆí˜¸ (ê¸°ë³¸ê°’: í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” snomed)
            scheme: ì—°ê²° ìŠ¤í‚¤ë§ˆ (ê¸°ë³¸ê°’: http)
        """
        # í™˜ê²½ë³€ìˆ˜ ë˜ëŠ” ê¸°ë³¸ê°’ ì„¤ì •
        self.host = host or os.getenv("ES_SERVER_HOST", "3.35.110.161")
        self.port = port or int(os.getenv("ES_SERVER_PORT", "9200"))
        self.username = username or os.getenv("ES_SERVER_USERNAME", "elastic")
        self.password = password or os.getenv("ES_SERVER_PASSWORD", "snomed")
        self.scheme = scheme
        
        # ë¡œê·¸ ì„¤ì •
        self.setup_logging()
        
        # Elasticsearch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        self.es = self._create_elasticsearch_client()
        
        # ì—°ê²° í…ŒìŠ¤íŠ¸
        if not self._test_connection():
            raise ConnectionError("Elasticsearch ì„œë²„ì— ì—°ê²°í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            
        self.logger.info(f"Elasticsearch ì—°ê²° ì„±ê³µ: {self.host}:{self.port}")
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        log_filename = f"elasticsearch_index_inspection_{timestamp}.log"
        
        # ë¡œê±° ì„¤ì •
        self.logger = logging.getLogger('es_inspector')
        self.logger.setLevel(logging.INFO)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        file_handler = logging.FileHandler(log_filename, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # í¬ë§·í„°
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # í•¸ë“¤ëŸ¬ ì¶”ê°€
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
        self.log_filename = log_filename
        self.logger.info(f"ë¡œê·¸ íŒŒì¼ ìƒì„±: {log_filename}")
    
    def _create_elasticsearch_client(self) -> Elasticsearch:
        """Elasticsearch í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
        try:
            # ES 8.x ë°©ì‹ìœ¼ë¡œ ë¨¼ì € ì‹œë„
            es = Elasticsearch(
                f"{self.scheme}://{self.host}:{self.port}",
                basic_auth=(self.username, self.password),
                request_timeout=60,
                retry_on_timeout=True,
                max_retries=3
            )
            return es
        except Exception as e:
            self.logger.warning(f"ES 8.x ë°©ì‹ ì—°ê²° ì‹¤íŒ¨, ëŒ€ì²´ ë°©ì‹ ì‹œë„: {e}")
            
            try:
                # ES 7.x ë°©ì‹ìœ¼ë¡œ ëŒ€ì²´ ì‹œë„
                es = Elasticsearch(
                    hosts=[{"host": self.host, "port": self.port, "scheme": self.scheme}],
                    http_auth=(self.username, self.password),
                    request_timeout=60,
                    retry_on_timeout=True,
                    max_retries=3
                )
                return es
            except Exception as e2:
                self.logger.error(f"ES 7.x ë°©ì‹ë„ ì‹¤íŒ¨: {e2}")
                raise ConnectionError(f"Elasticsearch í´ë¼ì´ì–¸íŠ¸ ìƒì„± ì‹¤íŒ¨: {e2}")
    
    def _test_connection(self) -> bool:
        """ì—°ê²° í…ŒìŠ¤íŠ¸"""
        try:
            return self.es.ping()
        except Exception as e:
            self.logger.error(f"ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {e}")
            return False
    
    def get_cluster_info(self) -> Dict[str, Any]:
        """í´ëŸ¬ìŠ¤í„° ì •ë³´ ì¡°íšŒ"""
        try:
            info = self.es.info()
            self.logger.info("=== Elasticsearch í´ëŸ¬ìŠ¤í„° ì •ë³´ ===")
            self.logger.info(f"í´ëŸ¬ìŠ¤í„°ëª…: {info.get('cluster_name', 'Unknown')}")
            self.logger.info(f"ë²„ì „: {info.get('version', {}).get('number', 'Unknown')}")
            self.logger.info(f"íƒœê·¸ë¼ì¸: {info.get('tagline', 'Unknown')}")
            return info
        except Exception as e:
            self.logger.error(f"í´ëŸ¬ìŠ¤í„° ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_all_indices(self) -> List[str]:
        """ëª¨ë“  ì¸ë±ìŠ¤ ëª©ë¡ ì¡°íšŒ"""
        try:
            indices = list(self.es.indices.get(index="*").keys())
            indices.sort()
            
            self.logger.info(f"=== ì „ì²´ ì¸ë±ìŠ¤ ëª©ë¡ (ì´ {len(indices)}ê°œ) ===")
            for i, index in enumerate(indices, 1):
                self.logger.info(f"{i:2d}. {index}")
            
            return indices
        except Exception as e:
            self.logger.error(f"ì¸ë±ìŠ¤ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_index_stats(self, index_name: str) -> Dict[str, Any]:
        """ì¸ë±ìŠ¤ í†µê³„ ì •ë³´ ì¡°íšŒ"""
        try:
            stats = self.es.indices.stats(index=index_name)
            index_stats = stats['indices'][index_name]
            
            # ì£¼ìš” í†µê³„ ì •ë³´ ì¶”ì¶œ
            total_docs = index_stats['total']['docs']['count']
            total_size = index_stats['total']['store']['size_in_bytes']
            primary_size = index_stats['primaries']['store']['size_in_bytes']
            
            return {
                'total_documents': total_docs,
                'total_size_bytes': total_size,
                'total_size_mb': round(total_size / (1024 * 1024), 2),
                'primary_size_bytes': primary_size,
                'primary_size_mb': round(primary_size / (1024 * 1024), 2),
                'shards': index_stats['total']['docs']
            }
        except Exception as e:
            self.logger.warning(f"ì¸ë±ìŠ¤ {index_name} í†µê³„ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_index_mapping(self, index_name: str) -> Dict[str, Any]:
        """ì¸ë±ìŠ¤ ë§¤í•‘ ì •ë³´ ì¡°íšŒ"""
        try:
            mapping = self.es.indices.get_mapping(index=index_name)
            return mapping[index_name]['mappings']
        except Exception as e:
            self.logger.warning(f"ì¸ë±ìŠ¤ {index_name} ë§¤í•‘ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return {}
    
    def get_sample_documents(self, index_name: str, size: int = 5) -> List[Dict[str, Any]]:
        """ì¸ë±ìŠ¤ì˜ ìƒ˜í”Œ ë¬¸ì„œë“¤ ì¡°íšŒ"""
        try:
            response = self.es.search(
                index=index_name,
                body={
                    "query": {"match_all": {}},
                    "size": size
                }
            )
            
            documents = []
            for hit in response['hits']['hits']:
                documents.append({
                    'id': hit['_id'],
                    'source': hit['_source']
                })
            
            return documents
        except Exception as e:
            self.logger.warning(f"ì¸ë±ìŠ¤ {index_name} ìƒ˜í”Œ ë¬¸ì„œ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def inspect_index(self, index_name: str):
        """ê°œë³„ ì¸ë±ìŠ¤ ìƒì„¸ ì¡°ì‚¬"""
        self.logger.info(f"\n{'='*60}")
        self.logger.info(f"ì¸ë±ìŠ¤ ìƒì„¸ ì¡°ì‚¬: {index_name}")
        self.logger.info(f"{'='*60}")
        
        # 1. í†µê³„ ì •ë³´
        stats = self.get_index_stats(index_name)
        if stats:
            self.logger.info(f"ğŸ“Š í†µê³„ ì •ë³´:")
            self.logger.info(f"  - ì´ ë¬¸ì„œ ìˆ˜: {stats.get('total_documents', 'Unknown'):,}")
            self.logger.info(f"  - ì´ í¬ê¸°: {stats.get('total_size_mb', 'Unknown')} MB")
            self.logger.info(f"  - í”„ë¼ì´ë¨¸ë¦¬ í¬ê¸°: {stats.get('primary_size_mb', 'Unknown')} MB")
        
        # 2. ë§¤í•‘ ì •ë³´
        mapping = self.get_index_mapping(index_name)
        if mapping:
            self.logger.info(f"ğŸ—ºï¸  ë§¤í•‘ ì •ë³´:")
            properties = mapping.get('properties', {})
            if properties:
                self.logger.info(f"  - í•„ë“œ ìˆ˜: {len(properties)}")
                self.logger.info(f"  - í•„ë“œ ëª©ë¡:")
                for field_name, field_info in properties.items():
                    field_type = field_info.get('type', 'unknown')
                    self.logger.info(f"    * {field_name}: {field_type}")
            else:
                self.logger.info("  - ë§¤í•‘ ì •ë³´ ì—†ìŒ")
        
        # 3. ìƒ˜í”Œ ë¬¸ì„œë“¤
        sample_docs = self.get_sample_documents(index_name, size=3)
        if sample_docs:
            self.logger.info(f"ğŸ“„ ìƒ˜í”Œ ë¬¸ì„œ ({len(sample_docs)}ê°œ):")
            for i, doc in enumerate(sample_docs, 1):
                self.logger.info(f"  --- ë¬¸ì„œ {i} (ID: {doc['id']}) ---")
                # JSONì„ ì˜ˆì˜ê²Œ ì¶œë ¥
                doc_json = json.dumps(doc['source'], ensure_ascii=False, indent=4)
                for line in doc_json.split('\n'):
                    self.logger.info(f"  {line}")
        else:
            self.logger.info("ğŸ“„ ìƒ˜í”Œ ë¬¸ì„œ: ì—†ìŒ ë˜ëŠ” ì¡°íšŒ ì‹¤íŒ¨")
        
        self.logger.info(f"{'='*60}\n")
    
    def inspect_all_indices(self):
        """ëª¨ë“  ì¸ë±ìŠ¤ ì¡°ì‚¬"""
        self.logger.info("ğŸ” Elasticsearch ì¸ë±ìŠ¤ ì „ì²´ ì¡°ì‚¬ ì‹œì‘")
        self.logger.info(f"ì¡°ì‚¬ ì‹œì‘ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        
        # í´ëŸ¬ìŠ¤í„° ì •ë³´
        cluster_info = self.get_cluster_info()
        
        # ì¸ë±ìŠ¤ ëª©ë¡
        indices = self.get_all_indices()
        
        if not indices:
            self.logger.warning("ì¡°ì‚¬í•  ì¸ë±ìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        # ê° ì¸ë±ìŠ¤ ìƒì„¸ ì¡°ì‚¬
        for i, index_name in enumerate(indices, 1):
            self.logger.info(f"\nì§„í–‰ ìƒí™©: {i}/{len(indices)} - {index_name}")
            try:
                self.inspect_index(index_name)
            except Exception as e:
                self.logger.error(f"ì¸ë±ìŠ¤ {index_name} ì¡°ì‚¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
                continue
        
        self.logger.info("ğŸ‰ ëª¨ë“  ì¸ë±ìŠ¤ ì¡°ì‚¬ ì™„ë£Œ!")
        self.logger.info(f"ì¡°ì‚¬ ì™„ë£Œ ì‹œê°„: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        self.logger.info(f"ë¡œê·¸ íŒŒì¼: {self.log_filename}")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # ì¸ë±ìŠ¤ ê²€ì‚¬ê¸° ìƒì„±
        inspector = ElasticsearchIndexInspector()
        
        # ëª¨ë“  ì¸ë±ìŠ¤ ì¡°ì‚¬ ì‹¤í–‰
        inspector.inspect_all_indices()
        
        print(f"\nâœ… ì¸ë±ìŠ¤ ì¡°ì‚¬ê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        print(f"ğŸ“„ ë¡œê·¸ íŒŒì¼: {inspector.log_filename}")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return 1
    
    return 0


if __name__ == "__main__":
    exit(main())
