"""
ë§¤í•‘ ì‹¤íŒ¨ ë°ì´í„° ì¬ì‹œë„ í…ŒìŠ¤íŠ¸ ìŠ¤í¬ë¦½íŠ¸

ë°ì´í„°: data/fail-retry.xlsx
ë„ë©”ì¸: Entityë³„ Domain ì»¬ëŸ¼ì— ë”°ë¼ ì§€ì •
Stage 1: Lexical + Semantic + Combined
Stage 3: LLM (ì ìˆ˜ ë¯¸í¬í•¨) + Non-std ì •ë³´ í¬í•¨ í”„ë¡¬í”„íŠ¸
"""
import pandas as pd
import logging
import os
from datetime import datetime
from pathlib import Path
import sys
import openpyxl
from openpyxl.styles import Font, Alignment, PatternFill
from tqdm import tqdm
import time
import json

# ìƒëŒ€ ê²½ë¡œë¡œ src ë””ë ‰í† ë¦¬ ì¶”ê°€
sys.path.append(str(Path(__file__).parent.parent / 'src'))

from MapOMOP.entity_mapping_api import EntityMappingAPI, EntityInput, DomainID
from MapOMOP.elasticsearch_client import ElasticsearchClient


class FailRetryMappingTester:
    """ë§¤í•‘ ì‹¤íŒ¨ ë°ì´í„° ì¬ì‹œë„ í…ŒìŠ¤íŠ¸ í´ë˜ìŠ¤"""
    
    # Domain ë¬¸ìì—´ -> DomainID ë§¤í•‘
    DOMAIN_MAP = {
        'Condition': DomainID.CONDITION,
        'Procedure': DomainID.PROCEDURE,
        'Drug': DomainID.DRUG,
        'Measurement': DomainID.MEASUREMENT,
        'Observation': DomainID.OBSERVATION,
        'Device': DomainID.DEVICE,
    }
    
    def __init__(self, log_dir: str = "test_logs_fail_retry"):
        """í…ŒìŠ¤í„° ì´ˆê¸°í™”"""
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        self.setup_logging()
        
        self.es_client = ElasticsearchClient()
        self.es_client.concept_index = "concept-small"
        self.es_client.concept_synonym_index = "concept-synonym"
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        log_file = self.log_dir / f"fail_retry_mapping_test_{timestamp}.log"
        
        self.logger = logging.getLogger('fail_retry_mapping_test')
        self.logger.setLevel(logging.INFO)
        
        # ê¸°ì¡´ í•¸ë“¤ëŸ¬ ì œê±°
        self.logger.handlers.clear()
        
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        formatter = logging.Formatter(
            '%(asctime)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
        self.logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file}")
    
    def load_excel_data(self, excel_path: str) -> pd.DataFrame:
        """
        ì—‘ì…€ íŒŒì¼ì—ì„œ ë°ì´í„° ë¡œë”©
        
        Args:
            excel_path: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        """
        self.logger.info(f"ë°ì´í„° ë¡œë”© ì‹œì‘: {excel_path}")
        
        df = pd.read_excel(excel_path)
        self.logger.info(f"ì „ì²´ ë°ì´í„° í¬ê¸°: {len(df):,}ê°œ")
        self.logger.info(f"ì»¬ëŸ¼: {df.columns.tolist()}")
        
        # Entity Name ì—´ í™•ì¸
        if 'Entity Name' not in df.columns:
            raise ValueError("'Entity Name' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        # Domain ì—´ í™•ì¸
        if 'Domain' not in df.columns:
            raise ValueError("'Domain' ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.")
        
        # ë¹ˆ ê°’ ì œì™¸
        df_clean = df[df['Entity Name'].notna()].copy()
        df_clean = df_clean.reset_index(drop=True)
        
        self.logger.info(f"ìœ íš¨í•œ ì—”í‹°í‹° ìˆ˜: {len(df_clean):,}ê°œ")
        
        # ë„ë©”ì¸ë³„ ë¶„í¬
        domain_counts = df_clean['Domain'].value_counts()
        self.logger.info("ë„ë©”ì¸ë³„ ë¶„í¬:")
        for domain, count in domain_counts.items():
            self.logger.info(f"  - {domain}: {count:,}ê°œ")
        
        return df_clean
    
    def get_domain_id(self, domain_str: str) -> DomainID:
        """Domain ë¬¸ìì—´ì„ DomainIDë¡œ ë³€í™˜"""
        if pd.isna(domain_str) or domain_str is None:
            return None
        
        domain_str = str(domain_str).strip()
        return self.DOMAIN_MAP.get(domain_str, None)
    
    def create_entity_input(self, entity_name: str, domain_str: str) -> EntityInput:
        """ì—”í‹°í‹°ëª…ê³¼ ë„ë©”ì¸ìœ¼ë¡œë¶€í„° EntityInput ìƒì„±"""
        domain_id = self.get_domain_id(domain_str)
        return EntityInput(
            entity_name=entity_name.strip(),
            domain_id=domain_id,
            vocabulary_id=None
        )
    
    def test_single_entity(
        self, 
        api: EntityMappingAPI,
        entity_input: EntityInput,
        ground_truth_id: str = None,
        ground_truth_name: str = None
    ) -> dict:
        """ë‹¨ì¼ ì—”í‹°í‹° í…ŒìŠ¤íŠ¸"""
        # ì´ˆê¸°í™”
        results = None
        error_msg = None
        
        # ë§¤í•‘ ìˆ˜í–‰
        try:
            results = api.map_entity(entity_input)
        except Exception as e:
            error_msg = str(e)
        
        # ë§¤í•‘ ì„±ê³µ/ì‹¤íŒ¨ì™€ ê´€ê³„ì—†ì´ í•­ìƒ stage candidates ìˆ˜ì§‘
        # APIì—ì„œ ë§¤í•‘ ì‹œì‘ ì‹œ ì´ˆê¸°í™”ë˜ë¯€ë¡œ, í˜„ì¬ ë§¤í•‘ì˜ candidatesë§Œ í¬í•¨ë¨
        stage1_candidates = getattr(api, '_last_stage1_candidates', []) or []
        stage2_candidates = getattr(api, '_last_stage2_candidates', []) or []
        stage3_candidates = getattr(api, '_last_rerank_candidates', []) or []
        
        # LLMì´ 1ìœ„ë¡œ ì„ íƒí•œ ê²ƒ í™•ì¸
        llm_top_pick = None
        if stage3_candidates:
            llm_top = stage3_candidates[0]
            llm_top_pick = {
                'concept_id': llm_top.get('concept_id'),
                'concept_name': llm_top.get('concept_name'),
                'llm_score': llm_top.get('llm_score'),
                'llm_rank': llm_top.get('llm_rank')
            }
        
        # ìµœê³  ì ìˆ˜ ê²°ê³¼ ì„ íƒ
        best_result = None
        if results and len(results) > 0:
            best_result = max(results, key=lambda x: x.mapping_score)
        
        # Validationìœ¼ë¡œ ì¸í•´ ê²°ê³¼ê°€ ë³€ê²½ë˜ì—ˆëŠ”ì§€ í™•ì¸
        validation_changed = False
        if best_result and llm_top_pick:
            if str(best_result.mapped_concept_id) != str(llm_top_pick.get('concept_id')):
                validation_changed = True
        
        # ì‹¤íŒ¨ ì›ì¸ íŒë‹¨
        if not best_result and not error_msg:
            if not stage1_candidates:
                error_msg = "Stage 1: No candidates found"
            elif not stage2_candidates:
                error_msg = "Stage 2: No standard candidates found"
            elif not stage3_candidates:
                error_msg = "Stage 3: Scoring failed"
            else:
                error_msg = "Validation: All candidates failed"
        
        # Ground Truthì™€ ë¹„êµ
        gt_matched = None
        if best_result and ground_truth_id:
            try:
                gt_matched = str(best_result.mapped_concept_id) == str(int(float(ground_truth_id)))
            except:
                gt_matched = False
        
        return {
            'entity_name': entity_input.entity_name,
            'input_domain': entity_input.domain_id.value if entity_input.domain_id else 'All',
            'ground_truth_id': ground_truth_id,
            'ground_truth_name': ground_truth_name,
            'success': best_result is not None,
            'gt_matched': gt_matched,
            'best_concept_id': best_result.mapped_concept_id if best_result else None,
            'best_concept_name': best_result.mapped_concept_name if best_result else None,
            'best_score': best_result.mapping_score if best_result else 0.0,
            'best_confidence': best_result.mapping_confidence if best_result else None,
            'mapping_method': best_result.mapping_method if best_result else None,
            'vocabulary_id': best_result.vocabulary_id if best_result else None,
            'llm_top_pick': llm_top_pick,
            'validation_changed': validation_changed,
            'error': error_msg,
            'stage1_candidates': stage1_candidates,
            'stage2_candidates': stage2_candidates,
            'stage3_candidates': stage3_candidates
        }
    
    def run_mapping_test(self, excel_path: str) -> dict:
        """ë§¤í•‘ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.logger.info("\n" + "=" * 100)
        self.logger.info("ğŸ”„ ë§¤í•‘ ì‹¤íŒ¨ ë°ì´í„° ì¬ì‹œë„ í…ŒìŠ¤íŠ¸ ì‹œì‘")
        self.logger.info("=" * 100)
        self.logger.info("í…ŒìŠ¤íŠ¸ ì¡°ê±´:")
        self.logger.info("  - Domain: ê° ì—”í‹°í‹°ë³„ ì§€ì •ëœ ë„ë©”ì¸")
        self.logger.info("  - Stage 1: Lexical + Semantic + Combined (use_lexical: True)")
        self.logger.info("  - Stage 3: LLM (ì ìˆ˜ ë¯¸í¬í•¨, include_stage1_scores: False)")
        self.logger.info("  - Non-std ì •ë³´ í¬í•¨ í”„ë¡¬í”„íŠ¸ (include_non_std_info: True)")
        self.logger.info("=" * 100)
        
        # ë°ì´í„° ë¡œë”©
        test_data = self.load_excel_data(excel_path)
        
        start_time = time.time()
        
        # API ì´ˆê¸°í™”
        api = EntityMappingAPI(
            es_client=self.es_client,
            scoring_mode='llm',
            include_stage1_scores=False,
            use_lexical=True,
            include_non_std_info=True
        )
        
        # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
        test_results = []
        successful_mappings = 0
        gt_matched_count = 0
        
        for idx, row in tqdm(test_data.iterrows(), total=len(test_data), desc="ë§¤í•‘ í…ŒìŠ¤íŠ¸"):
            try:
                entity_name = str(row['Entity Name']).strip()
                domain_str = str(row['Domain']).strip() if pd.notna(row['Domain']) else None
                ground_truth_id = row.get('Ground Truth ID', None)
                ground_truth_name = row.get('concept_name', None)
                
                entity_input = self.create_entity_input(entity_name, domain_str)
                
                result = self.test_single_entity(
                    api, entity_input, 
                    ground_truth_id=ground_truth_id,
                    ground_truth_name=ground_truth_name
                )
                test_results.append(result)
                
                if result['success']:
                    successful_mappings += 1
                    if result['gt_matched']:
                        gt_matched_count += 1
                    
            except Exception as e:
                self.logger.error(f"í…ŒìŠ¤íŠ¸ #{idx + 1} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì‹œê°„
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        # ê²°ê³¼ ìš”ì•½
        total_tests = len(test_results)
        success_rate = (successful_mappings / total_tests * 100) if total_tests > 0 else 0
        gt_match_rate = (gt_matched_count / total_tests * 100) if total_tests > 0 else 0
        
        summary = {
            'test_name': 'fail_retry_mapping',
            'description': 'Stage1 (Lexical + Semantic + Combined) + Stage3 LLM (ì ìˆ˜ ë¯¸í¬í•¨, Non-std ì •ë³´ í¬í•¨)',
            'use_lexical': True,
            'scoring_mode': 'llm',
            'include_stage1_scores': False,
            'include_non_std_info': True,
            'total_tests': total_tests,
            'successful_mappings': successful_mappings,
            'success_rate': success_rate,
            'gt_matched_count': gt_matched_count,
            'gt_match_rate': gt_match_rate,
            'elapsed_time': elapsed_time,
            'avg_time_per_entity': elapsed_time / total_tests if total_tests > 0 else 0,
            'results': test_results
        }
        
        self.logger.info(f"\nğŸ“Š ê²°ê³¼ ìš”ì•½:")
        self.logger.info(f"   ì´ í…ŒìŠ¤íŠ¸: {total_tests:,}ê°œ")
        self.logger.info(f"   ë§¤í•‘ ì„±ê³µ: {successful_mappings:,}ê°œ ({success_rate:.2f}%)")
        self.logger.info(f"   GT ì¼ì¹˜: {gt_matched_count:,}ê°œ ({gt_match_rate:.2f}%)")
        self.logger.info(f"   ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ ({elapsed_time/60:.2f}ë¶„)")
        
        # ê²°ê³¼ ì €ì¥
        self.save_results(summary)
        
        return summary
    
    def save_results(self, summary: dict):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # 1. ìš”ì•½ CSV ì €ì¥
        summary_data = [{
            'test_name': summary['test_name'],
            'description': summary['description'],
            'use_lexical': summary['use_lexical'],
            'scoring_mode': summary['scoring_mode'],
            'include_stage1_scores': summary['include_stage1_scores'],
            'include_non_std_info': summary['include_non_std_info'],
            'total_tests': summary['total_tests'],
            'successful_mappings': summary['successful_mappings'],
            'success_rate': summary['success_rate'],
            'gt_matched_count': summary['gt_matched_count'],
            'gt_match_rate': summary['gt_match_rate'],
            'elapsed_time': summary['elapsed_time'],
            'avg_time_per_entity': summary['avg_time_per_entity']
        }]
        
        summary_df = pd.DataFrame(summary_data)
        summary_csv = self.log_dir / f"fail_retry_mapping_summary_{timestamp}.csv"
        summary_df.to_csv(summary_csv, index=False, encoding='utf-8')
        self.logger.info(f"ğŸ“„ ìš”ì•½ CSV ì €ì¥: {summary_csv}")
        
        # 2. ìƒì„¸ ê²°ê³¼ XLSX ì €ì¥
        xlsx_file = self.log_dir / f"fail_retry_mapping_detailed_{timestamp}.xlsx"
        
        wb = openpyxl.Workbook()
        
        # ìš”ì•½ ì‹œíŠ¸
        ws_summary = wb.active
        ws_summary.title = "Summary"
        self._create_summary_sheet(ws_summary, summary)
        
        # ìƒì„¸ ê²°ê³¼ ì‹œíŠ¸
        ws_detail = wb.create_sheet(title="Details")
        self._create_detail_sheet(ws_detail, summary)
        
        wb.save(xlsx_file)
        self.logger.info(f"ğŸ“Š ìƒì„¸ XLSX ì €ì¥: {xlsx_file}")
        
        # 3. JSONìœ¼ë¡œ ì „ì²´ ê²°ê³¼ ì €ì¥
        json_file = self.log_dir / f"fail_retry_mapping_results_{timestamp}.json"
        json_data = {
            'timestamp': timestamp,
            'summary': {k: v for k, v in summary.items() if k != 'results'}
        }
        with open(json_file, 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        self.logger.info(f"ğŸ“ JSON ì €ì¥: {json_file}")
    
    def _create_summary_sheet(self, ws, summary):
        """ìš”ì•½ ì‹œíŠ¸ ìƒì„±"""
        headers = [
            "í•­ëª©", "ê°’"
        ]
        
        # í—¤ë” ìŠ¤íƒ€ì¼
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col, value=header)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = Alignment(horizontal="center")
        
        # ë°ì´í„° ì‘ì„±
        summary_items = [
            ("í…ŒìŠ¤íŠ¸ëª…", summary['test_name']),
            ("ì„¤ëª…", summary['description']),
            ("use_lexical", str(summary['use_lexical'])),
            ("scoring_mode", summary['scoring_mode']),
            ("include_stage1_scores", str(summary['include_stage1_scores'])),
            ("include_non_std_info", str(summary['include_non_std_info'])),
            ("ì´ í…ŒìŠ¤íŠ¸", summary['total_tests']),
            ("ë§¤í•‘ ì„±ê³µ", summary['successful_mappings']),
            ("ì„±ê³µë¥  (%)", round(summary['success_rate'], 2)),
            ("GT ì¼ì¹˜ ìˆ˜", summary['gt_matched_count']),
            ("GT ì¼ì¹˜ìœ¨ (%)", round(summary['gt_match_rate'], 2)),
            ("ì†Œìš”ì‹œê°„ (ì´ˆ)", round(summary['elapsed_time'], 2)),
            ("í‰ê· ì‹œê°„ (ì´ˆ/ì—”í‹°í‹°)", round(summary['avg_time_per_entity'], 4))
        ]
        
        for row, (key, value) in enumerate(summary_items, 2):
            ws.cell(row=row, column=1, value=key)
            ws.cell(row=row, column=2, value=value)
        
        # ì—´ ë„ˆë¹„ ì„¤ì •
        ws.column_dimensions['A'].width = 25
        ws.column_dimensions['B'].width = 80
    
    def _create_detail_sheet(self, ws, summary):
        """ìƒì„¸ ê²°ê³¼ ì‹œíŠ¸ ìƒì„±"""
        headers = [
            "Entity Name", "Domain", "Ground Truth ID", "GT Name", "Success", "GT Matched",
            "Best Concept ID", "Best Concept Name", "Vocabulary ID",
            "Score", "Confidence", "Mapping Method",
            "Validation Changed", "LLM Top Pick", "Error",
            "Stage1 Candidates", "Stage2 Candidates", "Stage3 Candidates"
        ]
        
        # í—¤ë” ìŠ¤íƒ€ì¼
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col, value=header)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = Alignment(horizontal="center", vertical="center")
        
        # ë°ì´í„° ì‘ì„±
        for row, result in enumerate(summary['results'], 2):
            ws.cell(row=row, column=1, value=result.get('entity_name', 'N/A'))
            ws.cell(row=row, column=2, value=result.get('input_domain', 'N/A'))
            ws.cell(row=row, column=3, value=result.get('ground_truth_id', 'N/A'))
            ws.cell(row=row, column=4, value=result.get('ground_truth_name', 'N/A'))
            
            # ì„±ê³µ ì—¬ë¶€ ì»¬ëŸ¬ë§
            success_cell = ws.cell(row=row, column=5, value="ì„±ê³µ" if result.get('success') else "ì‹¤íŒ¨")
            if result.get('success'):
                success_cell.fill = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
            else:
                success_cell.fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
            
            # GT ì¼ì¹˜ ì—¬ë¶€ ì»¬ëŸ¬ë§
            gt_matched = result.get('gt_matched')
            if gt_matched is not None:
                gt_cell = ws.cell(row=row, column=6, value="ì¼ì¹˜" if gt_matched else "ë¶ˆì¼ì¹˜")
                if gt_matched:
                    gt_cell.fill = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
                else:
                    gt_cell.fill = PatternFill(start_color="FFEB9C", end_color="FFEB9C", fill_type="solid")
            else:
                ws.cell(row=row, column=6, value="N/A")
            
            ws.cell(row=row, column=7, value=result.get('best_concept_id', 'N/A'))
            ws.cell(row=row, column=8, value=result.get('best_concept_name', 'N/A'))
            ws.cell(row=row, column=9, value=result.get('vocabulary_id', 'N/A'))
            ws.cell(row=row, column=10, value=result.get('best_score', 0.0))
            ws.cell(row=row, column=11, value=result.get('best_confidence', 'N/A'))
            ws.cell(row=row, column=12, value=result.get('mapping_method', 'N/A'))
            
            # Validation changed ì—¬ë¶€ ì»¬ëŸ¬ë§
            validation_changed = result.get('validation_changed', False)
            val_cell = ws.cell(row=row, column=13, value="ë³€ê²½ë¨" if validation_changed else "ìœ ì§€")
            if validation_changed:
                val_cell.fill = PatternFill(start_color="FFEB9C", end_color="FFEB9C", fill_type="solid")
            
            # LLM Top Pick ì •ë³´
            llm_top = result.get('llm_top_pick')
            if llm_top:
                llm_top_text = f"ID: {llm_top.get('concept_id', 'N/A')}\nì´ë¦„: {llm_top.get('concept_name', 'N/A')}\nLLMì ìˆ˜: {llm_top.get('llm_score', 'N/A')}"
            else:
                llm_top_text = "N/A"
            ws.cell(row=row, column=14, value=llm_top_text)
            ws.cell(row=row, column=14).alignment = Alignment(wrap_text=True, vertical='top')
            
            # Error ì •ë³´
            error_text = result.get('error', '')
            ws.cell(row=row, column=15, value=error_text if error_text else "")
            
            # Stageë³„ í›„ë³´êµ° ì¶”ê°€
            stage1_text = self._format_candidates_for_cell(result.get('stage1_candidates', []), 'stage1')
            ws.cell(row=row, column=16, value=stage1_text)
            
            stage2_text = self._format_candidates_for_cell(result.get('stage2_candidates', []), 'stage2')
            ws.cell(row=row, column=17, value=stage2_text)
            
            stage3_text = self._format_candidates_for_cell(result.get('stage3_candidates', []), 'stage3', 'llm')
            ws.cell(row=row, column=18, value=stage3_text)
            
            # Stage ì»¬ëŸ¼ ìŠ¤íƒ€ì¼ ì„¤ì •
            for col in range(16, 19):
                cell = ws.cell(row=row, column=col)
                cell.alignment = Alignment(wrap_text=True, vertical='top')
        
        # ì—´ ë„ˆë¹„ ì„¤ì •
        column_widths = [45, 15, 18, 40, 10, 12, 18, 50, 15, 10, 12, 20, 12, 40, 30, 70, 70, 85]
        for i, width in enumerate(column_widths, 1):
            ws.column_dimensions[openpyxl.utils.get_column_letter(i)].width = width
        
        # í–‰ ë†’ì´ ì„¤ì • (Stage í›„ë³´êµ° í‘œì‹œë¥¼ ìœ„í•´)
        for row_num in range(2, len(summary['results']) + 2):
            ws.row_dimensions[row_num].height = 150
    
    def _format_candidates_for_cell(self, candidates, stage_type, scoring_mode='llm'):
        """í›„ë³´êµ° í¬ë§·íŒ… (ì—‘ì…€ ì…€ìš©)"""
        if not candidates:
            return "í›„ë³´ ì—†ìŒ"
        
        lines = []
        max_candidates = 15 if stage_type in ['stage1', 'stage2'] else 10
        
        for i, candidate in enumerate(candidates[:max_candidates], 1):
            if stage_type == 'stage1':
                # Stage 1: Elasticsearch ê²°ê³¼
                search_type = candidate.get('search_type', 'unknown')
                line = f"{i}. [{search_type}] {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                line += f"   ESì ìˆ˜: {candidate.get('elasticsearch_score', 0):.4f}, "
                line += f"Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Domain: {candidate.get('domain_id', 'N/A')}"
            
            elif stage_type == 'stage2':
                # Stage 2: Standard ë³€í™˜ ê²°ê³¼
                search_type = candidate.get('search_type', 'unknown')
                is_std = "âœ“" if candidate.get('is_original_standard', True) else "â†’"
                line = f"{i}. [{search_type}] {is_std} {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                line += f"   Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Domain: {candidate.get('domain_id', 'N/A')}"
                if not candidate.get('is_original_standard', True):
                    original_non_std = candidate.get('original_non_standard', {})
                    if original_non_std:
                        line += f"\n   ì›ë³¸ Non-std: {original_non_std.get('concept_name', 'N/A')} (ID: {original_non_std.get('concept_id', 'N/A')})"
            
            else:  # stage3
                # Stage 3: LLM ë˜ëŠ” Semantic Only ê²°ê³¼
                search_type = candidate.get('search_type', 'unknown')
                line = f"{i}. [{search_type}] {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                
                # LLM ëª¨ë“œì¸ ê²½ìš°
                llm_score = candidate.get('llm_score')
                llm_rank = candidate.get('llm_rank')
                llm_reasoning = candidate.get('llm_reasoning')
                semantic_similarity = candidate.get('semantic_similarity')
                
                if llm_score is not None:
                    line += f"   LLMì ìˆ˜: {llm_score}, ìˆœìœ„: {llm_rank}"
                    if semantic_similarity is not None:
                        line += f" | ì˜ë¯¸ìœ ì‚¬ë„: {semantic_similarity:.4f}"
                    line += "\n"
                    if llm_reasoning:
                        reasoning_short = llm_reasoning[:60] + '...' if len(llm_reasoning) > 60 else llm_reasoning
                        line += f"   ì´ìœ : {reasoning_short}\n"
                else:
                    # Semantic Only ë˜ëŠ” Hybrid ëª¨ë“œì¸ ê²½ìš°
                    text_sim = candidate.get('text_similarity', 0)
                    sem_sim = candidate.get('semantic_similarity', 0)
                    final_score = candidate.get('final_score', 0)
                    line += f"   í…ìŠ¤íŠ¸: {text_sim:.4f}, ì˜ë¯¸ì : {sem_sim:.4f}, ìµœì¢…: {final_score:.4f}\n"
                
                line += f"   Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Domain: {candidate.get('domain_id', 'N/A')}"
            
            lines.append(line)
        
        return "\n\n".join(lines)


def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    # ============================================================
    # ì„¤ì •
    # ============================================================
    EXCEL_PATH = "/home/work/skku/hyo/omop-mapper/data/fail-retry.xlsx"
    
    # ============================================================
    # í…ŒìŠ¤íŠ¸ ì‹¤í–‰
    # ============================================================
    tester = FailRetryMappingTester()
    
    results = tester.run_mapping_test(
        excel_path=EXCEL_PATH
    )
    
    print(f"\nâœ… ë§¤í•‘ ì‹¤íŒ¨ ë°ì´í„° ì¬ì‹œë„ í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print(f"   ê²°ê³¼ëŠ” {tester.log_dir} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")


if __name__ == "__main__":
    main()
