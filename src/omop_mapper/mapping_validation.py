import json
import logging
import os
from typing import Any, Dict, List, Optional

from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

logger = logging.getLogger(__name__)

# OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
try:
    from openai import OpenAI
    HAS_OPENAI = True
except ImportError:
    HAS_OPENAI = False
    logger.warning("openaiê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê²€ì¦ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")


class MappingValidator:
    def __init__(
        self,
        es_client=None,
        openai_api_key: Optional[str] = None,
        openai_model: str = "gpt-4o-mini"
    ):
        self.es_client = es_client
        
        # OpenAI API ì´ˆê¸°í™”
        self.openai_client = None
        self.openai_model = openai_model
        
        if not HAS_OPENAI:
            logger.error("âš ï¸ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê²€ì¦ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        try:
            api_key = openai_api_key or os.getenv('OPENAI_API_KEY')
            if api_key:
                self.openai_client = OpenAI(api_key=api_key)
                logger.info(f"âœ… MappingValidator ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {openai_model})")
            else:
                logger.error("âš ï¸ OPENAI_API_KEYê°€ .env íŒŒì¼ì— ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ê²€ì¦ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        except Exception as e:
            logger.error(f"âš ï¸ OpenAI API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}. ê²€ì¦ ê¸°ëŠ¥ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    
    def validate_mapping(
        self,
        entity_name: str,
        concept_id: str,
        concept_name: str,
        synonyms: Optional[List[str]] = None
    ) -> bool:
        """
        ë§¤í•‘ ê²°ê³¼ ê²€ì¦ (True/False)
        
        Args:
            entity_name: ì…ë ¥ ì—”í‹°í‹° ì´ë¦„
            concept_id: ë§¤í•‘ëœ concept ID
            concept_name: ë§¤í•‘ëœ concept ì´ë¦„
            synonyms: ë™ì˜ì–´ ë¦¬ìŠ¤íŠ¸ (Noneì´ë©´ Elasticsearchì—ì„œ ì¡°íšŒ)
            
        Returns:
            bool: Trueë©´ ë§¤í•‘ì´ ì˜¬ë°”ë¦„, Falseë©´ ë§¤í•‘ì´ ì˜ëª»ë¨
        """
        if not self.openai_client:
            logger.error("âš ï¸ OpenAI API í´ë¼ì´ì–¸íŠ¸ê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
            return False
        
        # ë™ì˜ì–´ê°€ ì œê³µë˜ì§€ ì•Šìœ¼ë©´ Elasticsearchì—ì„œ ì¡°íšŒ
        if synonyms is None:
            synonyms = self._fetch_synonyms(concept_id)
        
        # LLMì„ í†µí•œ ê²€ì¦ ìˆ˜í–‰
        try:
            result = self._validate_with_llm(entity_name, concept_id, concept_name, synonyms)
            return result
        except Exception as e:
            logger.error(f"âš ï¸ ê²€ì¦ ì‹¤íŒ¨: {e}")
            return False
    
    def _fetch_synonyms(self, concept_id: str) -> List[str]:
        """
        Elasticsearchì—ì„œ ë™ì˜ì–´ ì¡°íšŒ
        
        Args:
            concept_id: concept ID
            
        Returns:
            List[str]: ë™ì˜ì–´ ë¦¬ìŠ¤íŠ¸
        """
        if not self.es_client:
            logger.warning("âš ï¸ Elasticsearch í´ë¼ì´ì–¸íŠ¸ê°€ ì—†ì–´ ë™ì˜ì–´ë¥¼ ì¡°íšŒí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return []
        
        try:
            synonyms = self.es_client.search_synonyms(str(concept_id))
            logger.debug(f"ë™ì˜ì–´ ì¡°íšŒ ì™„ë£Œ: concept_id={concept_id}, ë™ì˜ì–´ ìˆ˜={len(synonyms)}")
            return synonyms
        except Exception as e:
            logger.error(f"âš ï¸ ë™ì˜ì–´ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def _validate_with_llm(
        self,
        entity_name: str,
        concept_id: str,
        concept_name: str,
        synonyms: List[str]
    ) -> bool:
        """
        OpenAI LLMì„ ì‚¬ìš©í•˜ì—¬ ë§¤í•‘ ê²€ì¦
        
        Args:
            entity_name: ì…ë ¥ ì—”í‹°í‹° ì´ë¦„
            concept_id: ë§¤í•‘ëœ concept ID
            concept_name: ë§¤í•‘ëœ concept ì´ë¦„
            synonyms: ë™ì˜ì–´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            bool: Trueë©´ ë§¤í•‘ì´ ì˜¬ë°”ë¦„, Falseë©´ ë§¤í•‘ì´ ì˜ëª»ë¨
        """
        # í”„ë¡¬í”„íŠ¸ ìƒì„±
        prompt = self._create_validation_prompt(entity_name, concept_id, concept_name, synonyms)
        
        try:
            # OpenAI API í˜¸ì¶œ
            response = self.openai_client.chat.completions.create(
                model=self.openai_model,
                messages=[
                    {
                        "role": "system",
                        "content": "ë‹¹ì‹ ì€ ì˜ë£Œ ìš©ì–´ ë§¤í•‘ ê²€ì¦ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì£¼ì–´ì§„ ì…ë ¥ ì—”í‹°í‹°ì™€ ë§¤í•‘ëœ OMOP CDM conceptì˜ ì¼ì¹˜ ì—¬ë¶€ë¥¼ ê²€ì¦í•´ì•¼ í•©ë‹ˆë‹¤."
                    },
                    {
                        "role": "user",
                        "content": prompt
                    }
                ],
                temperature=0.1,
                max_tokens=256,
                response_format={"type": "json_object"}
            )
            
            # ì‘ë‹µ íŒŒì‹±
            response_text = response.choices[0].message.content
            result = self._parse_validation_response(response_text)
            return result
            
        except Exception as e:
            logger.error(f"OpenAI API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
            return False
    
    def _create_validation_prompt(
        self,
        entity_name: str,
        concept_id: str,
        concept_name: str,
        synonyms: List[str]
    ) -> str:
        """
        ê²€ì¦ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ ìƒì„±
        
        Args:
            entity_name: ì…ë ¥ ì—”í‹°í‹° ì´ë¦„
            concept_id: ë§¤í•‘ëœ concept ID
            concept_name: ë§¤í•‘ëœ concept ì´ë¦„
            synonyms: ë™ì˜ì–´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            str: í”„ë¡¬í”„íŠ¸ ë¬¸ìì—´
        """
        # ë™ì˜ì–´ ì²˜ë¦¬ (ì„¸ë¯¸ì½œë¡ ì´ë‚˜ ìŠ¬ë˜ì‹œë¡œ êµ¬ë¶„ëœ ê²½ìš° ê°œë³„ ë™ì˜ì–´ë¡œ ë¶„ë¦¬)
        all_synonyms = []
        for syn in synonyms:
            # ì„¸ë¯¸ì½œë¡ ìœ¼ë¡œ ë¶„ë¦¬
            parts = syn.split(';')
            for part in parts:
                # ìŠ¬ë˜ì‹œë¡œ ë¶„ë¦¬
                sub_parts = part.split('/')
                for sub_part in sub_parts:
                    cleaned = sub_part.strip()
                    if cleaned and cleaned not in all_synonyms:
                        all_synonyms.append(cleaned)
        
        # ë™ì˜ì–´ê°€ ìˆìœ¼ë©´ ë™ì˜ì–´ë¥¼ íŒíŠ¸ë¡œ ì‚¬ìš©, ì—†ìœ¼ë©´ concept_nameë§Œ ì‚¬ìš©
        if all_synonyms:
            synonyms_text = "\n".join([f"- {syn}" for syn in all_synonyms[:50]])  # ìµœëŒ€ 50ê°œ
            prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤í•‘ì´ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦í•´ì£¼ì„¸ìš”.

**ì…ë ¥ ì—”í‹°í‹°**: {entity_name}

**ë§¤í•‘ëœ Concept**:
- Concept ID: {concept_id}
- Concept Name: {concept_name}

**Conceptì˜ ë™ì˜ì–´ë“¤** (íŒíŠ¸):
{synonyms_text}

**ì§€ì‹œì‚¬í•­**:
1. ì…ë ¥ ì—”í‹°í‹°({entity_name})ê°€ ë§¤í•‘ëœ concept({concept_name})ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ì¼ì¹˜í•˜ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”.
2. ë™ì˜ì–´ë“¤ì„ ì°¸ê³ í•˜ì—¬ ì…ë ¥ ì—”í‹°í‹°ê°€ í•´ë‹¹ conceptìœ¼ë¡œ ë§¤í•‘ë˜ëŠ” ê²ƒì´ ì ì ˆí•œì§€ íŒë‹¨í•˜ì„¸ìš”.
3. ë™ì˜ì–´ ì¤‘ í•˜ë‚˜ë¼ë„ ì…ë ¥ ì—”í‹°í‹°ì™€ ì¼ì¹˜í•˜ê±°ë‚˜ ë§¤ìš° ìœ ì‚¬í•˜ë©´ Trueë¡œ íŒë‹¨í•˜ì„¸ìš”.
4. ì…ë ¥ ì—”í‹°í‹°ê°€ conceptì˜ í•˜ìœ„ ê°œë…ì´ê±°ë‚˜ ì™„ì „íˆ ë‹¤ë¥¸ ê°œë…ì´ë©´ Falseë¡œ íŒë‹¨í•˜ì„¸ìš”.

**ì¶œë ¥ í˜•ì‹** (JSON):
{{
  "is_valid": true ë˜ëŠ” false,
  "reasoning": "íŒë‹¨ ì´ìœ  (í•œêµ­ì–´ë¡œ ê°„ë‹¨íˆ)"
}}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""
        else:
            # ë™ì˜ì–´ê°€ ì—†ëŠ” ê²½ìš° concept_nameê³¼ entity_nameë§Œ ë¹„êµ
            prompt = f"""ë‹¤ìŒ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤í•‘ì´ ì˜¬ë°”ë¥¸ì§€ ê²€ì¦í•´ì£¼ì„¸ìš”.

**ì…ë ¥ ì—”í‹°í‹°**: {entity_name}

**ë§¤í•‘ëœ Concept**:
- Concept ID: {concept_id}
- Concept Name: {concept_name}

**ì§€ì‹œì‚¬í•­**:
1. ì…ë ¥ ì—”í‹°í‹°({entity_name})ê°€ ë§¤í•‘ëœ concept({concept_name})ê³¼ ì˜ë¯¸ì ìœ¼ë¡œ ì¼ì¹˜í•˜ëŠ”ì§€ í‰ê°€í•˜ì„¸ìš”.
2. ì…ë ¥ ì—”í‹°í‹°ì™€ concept nameì´ ì˜ë¯¸ì ìœ¼ë¡œ ì¼ì¹˜í•˜ê±°ë‚˜ ë§¤ìš° ìœ ì‚¬í•˜ë©´ Trueë¡œ íŒë‹¨í•˜ì„¸ìš”.
3. ì…ë ¥ ì—”í‹°í‹°ê°€ conceptì˜ í•˜ìœ„ ê°œë…ì´ê±°ë‚˜ ì™„ì „íˆ ë‹¤ë¥¸ ê°œë…ì´ë©´ Falseë¡œ íŒë‹¨í•˜ì„¸ìš”.

**ì¶œë ¥ í˜•ì‹** (JSON):
{{
  "is_valid": true ë˜ëŠ” false,
  "reasoning": "íŒë‹¨ ì´ìœ  (í•œêµ­ì–´ë¡œ ê°„ë‹¨íˆ)"
}}

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•´ì£¼ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª…ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.
"""
        
        return prompt
    
    def _parse_validation_response(self, response_text: str) -> bool:
        """
        LLM ì‘ë‹µ íŒŒì‹±
        
        Args:
            response_text: LLM ì‘ë‹µ í…ìŠ¤íŠ¸
            
        Returns:
            bool: ê²€ì¦ ê²°ê³¼ (True/False)
        """
        try:
            # JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
            text = response_text.strip()
            if '```json' in text:
                text = text.split('```json')[1].split('```')[0].strip()
            elif '```' in text:
                text = text.split('```')[1].split('```')[0].strip()
            
            # JSON íŒŒì‹±
            parsed = json.loads(text)
            
            # is_valid í•„ë“œ ì¶”ì¶œ
            is_valid = parsed.get('is_valid', False)
            reasoning = parsed.get('reasoning', '')
            
            logger.debug(f"ê²€ì¦ ê²°ê³¼: is_valid={is_valid}, reasoning={reasoning}")
            
            return bool(is_valid)
            
        except Exception as e:
            logger.error(f"ê²€ì¦ ì‘ë‹µ íŒŒì‹± ì‹¤íŒ¨: {e}")
            logger.debug(f"ì‘ë‹µ í…ìŠ¤íŠ¸: {response_text[:500]}")
            return False
    
    def validate_candidates_sequentially(
        self,
        entity_name: str,
        candidates: List[Dict[str, Any]],
        max_candidates: int = 10
    ) -> Optional[Dict[str, Any]]:
        """
        í›„ë³´êµ°ë“¤ì„ ìˆœì°¨ì ìœ¼ë¡œ ê²€ì¦í•˜ì—¬ ì²« ë²ˆì§¸ True ê²°ê³¼ ë°˜í™˜
        
        Args:
            entity_name: ì…ë ¥ ì—”í‹°í‹° ì´ë¦„
            candidates: ê²€ì¦í•  í›„ë³´êµ° ë¦¬ìŠ¤íŠ¸ (rank ìˆœì„œëŒ€ë¡œ ì •ë ¬ë˜ì–´ ìˆì–´ì•¼ í•¨)
            max_candidates: ìµœëŒ€ ê²€ì¦í•  í›„ë³´êµ° ìˆ˜
            
        Returns:
            Optional[Dict[str, Any]]: ê²€ì¦ í†µê³¼í•œ ì²« ë²ˆì§¸ í›„ë³´ ë˜ëŠ” None
        """
        if not candidates:
            logger.warning("âš ï¸ ê²€ì¦í•  í›„ë³´ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return None
        
        # ìƒìœ„ í›„ë³´ë“¤ë§Œ ê²€ì¦ (ì„±ëŠ¥ìƒ ì´ìœ )
        top_candidates = candidates[:max_candidates]
        
        logger.info(f"ğŸ” ìˆœì°¨ ê²€ì¦ ì‹œì‘: {len(top_candidates)}ê°œ í›„ë³´ ê²€ì¦")
        
        for idx, candidate in enumerate(top_candidates, 1):
            concept = candidate.get('concept', {})
            concept_id = str(concept.get('concept_id', ''))
            concept_name = concept.get('concept_name', '')
            
            if not concept_id or not concept_name:
                logger.warning(f"âš ï¸ í›„ë³´ {idx}: concept_id ë˜ëŠ” concept_nameì´ ì—†ìŠµë‹ˆë‹¤.")
                continue
            
            logger.info(f"  [{idx}/{len(top_candidates)}] ê²€ì¦ ì¤‘: {concept_name} (ID: {concept_id})")
            
            # ê²€ì¦ ìˆ˜í–‰
            is_valid = self.validate_mapping(
                entity_name=entity_name,
                concept_id=concept_id,
                concept_name=concept_name,
                synonyms=None  # Elasticsearchì—ì„œ ì¡°íšŒ
            )
            
            if is_valid:
                logger.info(f"  âœ… ê²€ì¦ í†µê³¼: {concept_name} (ID: {concept_id})")
                return candidate
            else:
                logger.info(f"  âŒ ê²€ì¦ ì‹¤íŒ¨: {concept_name} (ID: {concept_id})")
        
        logger.warning(f"âš ï¸ ëª¨ë“  í›„ë³´({len(top_candidates)}ê°œ) ê²€ì¦ ì‹¤íŒ¨")
        return None

