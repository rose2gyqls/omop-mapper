"""
Stage 2: Non-standard to Standard ë³€í™˜ ë° ì¤‘ë³µ ì œê±°
- Standard ê°œë…ì€ ì§ì ‘ ì¶”ê°€
- Non-standard ê°œë…ì€ "Maps to" ê´€ê³„ë¥¼ í†µí•´ Standard ê°œë…ìœ¼ë¡œ ë³€í™˜
- ë™ì¼í•œ concept_idì™€ concept_nameì¸ ê²½ìš° ì¤‘ë³µ ì œê±°
"""
from typing import List, Dict, Any
import logging

logger = logging.getLogger(__name__)


class Stage2StandardCollection:
    """Stage 2: Standard í›„ë³´ ìˆ˜ì§‘ ë° ì¤‘ë³µ ì œê±°"""
    
    def __init__(self, es_client):
        """
        Args:
            es_client: Elasticsearch í´ë¼ì´ì–¸íŠ¸
        """
        self.es_client = es_client
    
    def collect_standard_candidates(
        self, 
        stage1_candidates: List[Dict[str, Any]], 
        domain_id: str
    ) -> List[Dict[str, Any]]:
        """
        Stage 1 í›„ë³´ë“¤ì„ Standard ê°œë…ìœ¼ë¡œ ë³€í™˜í•˜ê³  ì¤‘ë³µ ì œê±°
        
        **ì²˜ë¦¬ ë¡œì§**:
        1. Standard ê°œë… (S/C): ê·¸ëŒ€ë¡œ ì¶”ê°€
        2. Non-standard ê°œë…: concept-relationship ì¸ë±ìŠ¤ì—ì„œ "Maps to" ê´€ê³„ë¡œ Standard ê°œë… ì¡°íšŒ
        3. ì¤‘ë³µ ì œê±°: ë™ì¼í•œ concept_idì™€ concept_nameì¸ ê²½ìš° Elasticsearch ì ìˆ˜ê°€ ë†’ì€ ê²ƒë§Œ ìœ ì§€
        
        Args:
            stage1_candidates: Stage 1ì—ì„œ ê²€ìƒ‰ëœ í›„ë³´ë“¤ (ìµœëŒ€ 9ê°œ)
            domain_id: ë„ë©”ì¸ ID (ë””ë²„ê¹…ìš©)
            
        Returns:
            List[Dict]: ì¤‘ë³µ ì œê±°ëœ Standard í›„ë³´ë“¤
        """
        logger.info("=" * 80)
        logger.info("Stage 2: Non-standard â†’ Standard ë³€í™˜ ë° ì¤‘ë³µ ì œê±°")
        logger.info("=" * 80)
        
        all_standard_candidates = []
        standard_count = 0
        non_standard_count = 0
        
        # ê° í›„ë³´ ì²˜ë¦¬
        for candidate in stage1_candidates:
            source = candidate['_source']
            search_type = candidate.get('_search_type', 'unknown')
            
            if source.get('standard_concept') in ['S', 'C']:
                # Standard ê°œë…: ì§ì ‘ ì¶”ê°€
                standard_count += 1
                all_standard_candidates.append({
                    'concept': source,
                    'is_original_standard': True,
                    'original_candidate': candidate,
                    'elasticsearch_score': candidate['_score'],
                    'search_type': search_type
                })
                logger.info(f"  âœ… Standard: {source.get('concept_name', 'N/A')} "
                          f"(ID: {source.get('concept_id', 'N/A')}) "
                          f"[{search_type}]")
            else:
                # Non-standard ê°œë…: Standard ê°œë…ìœ¼ë¡œ ë³€í™˜
                non_standard_count += 1
                concept_id = str(source.get('concept_id', ''))
                logger.info(f"  âš ï¸ Non-standard: {source.get('concept_name', 'N/A')} "
                          f"(ID: {concept_id}) [{search_type}]")
                
                # "Maps to" ê´€ê³„ë¥¼ í†µí•´ Standard ê°œë… ì¡°íšŒ
                standard_candidates_from_non = self._get_standard_candidates(concept_id, domain_id)
                
                for std_candidate in standard_candidates_from_non:
                    all_standard_candidates.append({
                        'concept': std_candidate,
                        'is_original_standard': False,
                        'original_non_standard': source,
                        'original_candidate': candidate,
                        'elasticsearch_score': 0.0,  # Non-standard â†’ StandardëŠ” ES ì ìˆ˜ ì—†ìŒ
                        'search_type': search_type
                    })
                    logger.info(f"     â†’ Standard ë§¤í•‘: {std_candidate.get('concept_name', 'N/A')} "
                              f"(ID: {std_candidate.get('concept_id', 'N/A')})")
        
        logger.info(f"\nðŸ“Š ë¶„ë¥˜ ê²°ê³¼:")
        logger.info(f"  - Standard: {standard_count}ê°œ")
        logger.info(f"  - Non-standard: {non_standard_count}ê°œ")
        logger.info(f"  - ì´ ìˆ˜ì§‘ëœ Standard í›„ë³´: {len(all_standard_candidates)}ê°œ")
        
        # ì¤‘ë³µ ì œê±°
        deduplicated_candidates = self._deduplicate_candidates(all_standard_candidates)
        
        logger.info(f"\nðŸ“Š ì¤‘ë³µ ì œê±° ì™„ë£Œ: {len(all_standard_candidates)}ê°œ â†’ {len(deduplicated_candidates)}ê°œ")
        logger.info("=" * 80)
        
        return deduplicated_candidates
    
    def _get_standard_candidates(self, non_standard_concept_id: str, domain_id: str) -> List[Dict[str, Any]]:
        """
        Non-standard ê°œë…ì˜ Standard í›„ë³´ë“¤ ì¡°íšŒ
        
        Args:
            non_standard_concept_id: Non-standard ê°œë… ID
            domain_id: ë„ë©”ì¸ ID
            
        Returns:
            List[Dict]: Standard ê°œë… í›„ë³´ë“¤
        """
        try:
            # "Maps to" ê´€ê³„ ì¡°íšŒ
            standard_concept_ids = self._get_maps_to_relationships(non_standard_concept_id)
            
            # Standard ê°œë… ê²€ìƒ‰
            standard_candidates = self._search_concepts_in_all_indices(standard_concept_ids, domain_id)
            
            logger.debug(f"Non-standard {non_standard_concept_id}ì— ëŒ€í•œ "
                        f"{len(standard_candidates)}ê°œ Standard í›„ë³´ ì¡°íšŒ ì™„ë£Œ")
            return standard_candidates
            
        except Exception as e:
            logger.error(f"Standard í›„ë³´ ì¡°íšŒ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def _get_maps_to_relationships(self, concept_id_1: str) -> List[str]:
        """
        concept-relationship ì¸ë±ìŠ¤ì—ì„œ "Maps to" ê´€ê³„ ì¡°íšŒ
        
        Args:
            concept_id_1: ì†ŒìŠ¤ ê°œë… ID
            
        Returns:
            List[str]: "Maps to"ë¡œ ì—°ê²°ëœ concept_id_2 ë¦¬ìŠ¤íŠ¸
        """
        try:
            relationship_query = {
                "query": {
                    "bool": {
                        "must": [
                            {"term": {"concept_id_1": concept_id_1}},
                            {"match": {"relationship_id": "Maps to"}}
                        ]
                    }
                },
                "size": 10
            }
            
            relationship_response = self.es_client.es_client.search(
                index="concept-relationship",
                body=relationship_query
            )
            
            standard_concept_ids = []
            for hit in relationship_response['hits']['hits']:
                concept_id_2 = hit['_source'].get('concept_id_2')
                if concept_id_2:
                    standard_concept_ids.append(str(concept_id_2))
            
            if standard_concept_ids:
                logger.debug(f"concept-relationship ì¸ë±ìŠ¤ì—ì„œ {concept_id_1}ì— ëŒ€í•œ "
                           f"{len(standard_concept_ids)}ê°œ Maps to ê´€ê³„ ë°œê²¬: {standard_concept_ids}")
            
            return standard_concept_ids
            
        except Exception as e:
            logger.warning(f"concept-relationship ì¸ë±ìŠ¤ Maps to ê´€ê³„ ì¡°íšŒ ì‹¤íŒ¨: {str(e)}")
            return []
    
    def _search_concepts_in_all_indices(self, concept_ids: List[str], domain_id: str) -> List[Dict[str, Any]]:
        """
        concept ì¸ë±ìŠ¤ì—ì„œ concept_idë“¤ ê²€ìƒ‰
        
        Args:
            concept_ids: ê²€ìƒ‰í•  concept_id ë¦¬ìŠ¤íŠ¸
            domain_id: ê²€ìƒ‰í•  ë„ë©”ì¸ ID
            
        Returns:
            List[Dict]: ì°¾ì€ ê°œë…ë“¤
        """
        if not concept_ids:
            return []
        
        all_candidates = []
        
        try:
            concepts_query = {
                "query": {
                    "bool": {
                        "must": [
                            {"terms": {"concept_id": concept_ids}},
                            {"terms": {"standard_concept": ["S", "C"]}}
                        ]
                    }
                },
                "size": len(concept_ids)
            }
            
            # Elasticsearch í´ë¼ì´ì–¸íŠ¸ì— ì„¤ì •ëœ ì¸ë±ìŠ¤ ì‚¬ìš©
            concepts_response = self.es_client.es_client.search(
                index="concept-small",
                body=concepts_query
            )
            
            for hit in concepts_response['hits']['hits']:
                all_candidates.append(hit['_source'])
            
            if concepts_response['hits']['total']['value'] > 0:
                logger.debug(f"{concepts_response['hits']['total']['value']}ê°œ Standard ê°œë… ë°œê²¬")
            
        except Exception as e:
            logger.warning(f"ê°œë… ê²€ìƒ‰ ì‹¤íŒ¨: {str(e)}")
        
        return all_candidates
    
    def _deduplicate_candidates(self, candidates: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """
        ì¤‘ë³µ í›„ë³´ ì œê±° (ë™ì¼í•œ concept_idì™€ concept_nameì¸ ê²½ìš°)
        
        Args:
            candidates: í›„ë³´ ë¦¬ìŠ¤íŠ¸
            
        Returns:
            List[Dict]: ì¤‘ë³µ ì œê±°ëœ í›„ë³´ ë¦¬ìŠ¤íŠ¸
        """
        unique_candidates = {}
        
        for candidate in candidates:
            concept = candidate['concept']
            concept_key = (concept.get('concept_id', ''), concept.get('concept_name', ''))
            
            # ë™ì¼í•œ ê°œë…ì´ ì´ë¯¸ ìžˆëŠ” ê²½ìš°, ë” ë†’ì€ Elasticsearch ì ìˆ˜ë§Œ ìœ ì§€
            if concept_key not in unique_candidates:
                unique_candidates[concept_key] = candidate
            else:
                existing_score = unique_candidates[concept_key]['elasticsearch_score']
                new_score = candidate['elasticsearch_score']
                
                # ë” ë†’ì€ ì ìˆ˜ë¡œ êµì²´
                if new_score > existing_score:
                    unique_candidates[concept_key] = candidate
        
        return list(unique_candidates.values())

