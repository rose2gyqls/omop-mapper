"""
Stage 1: Elasticsearchì—ì„œ ê° ë„ë©”ì¸ë³„ í›„ë³´êµ° 15ê°œ ì¶”ì¶œ
- Lexical Analysis: í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ top 5ê°œ
- Semantic Analysis: ì˜ë¯¸ì  ê²€ìƒ‰ìœ¼ë¡œ top 5ê°œ
- Combined Score: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ top 5ê°œ
"""
from typing import List, Dict, Any, Optional
import logging
import numpy as np

logger = logging.getLogger(__name__)


class Stage1CandidateRetrieval:
    """Stage 1: í›„ë³´êµ° ì¶”ì¶œ (Lexical 3 + Semantic 3 + Combined 3)"""
    
    def __init__(self, es_client, has_sapbert: bool = True):
        """
        Args:
            es_client: Elasticsearch í´ë¼ì´ì–¸íŠ¸
            has_sapbert: SapBERT ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
        """
        self.es_client = es_client
        self.has_sapbert = has_sapbert
        # Threshold ì„¤ì •
        self.lexical_threshold = 5.0
        self.semantic_threshold = 0.8
        self.combined_threshold = 5.0
    
    def retrieve_candidates(
        self, 
        entity_name: str, 
        domain_id: str,
        entity_embedding: Optional[np.ndarray] = None,
        es_index: str = "concept-small"
    ) -> List[Dict[str, Any]]:
        """
        ê° ë„ë©”ì¸ë³„ë¡œ ë‹¤ì–‘í•œ ê²€ìƒ‰ ì „ëµì„ ì‚¬ìš©í•˜ì—¬ í›„ë³´êµ° ì¶”ì¶œ
        
        **ê²€ìƒ‰ ì „ëµ**:
        - Lexical: í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ (ìµœëŒ€ 3ê°œ)
        - Semantic: ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ (ìµœëŒ€ 3ê°œ, ì„ë² ë”©ì´ ìˆëŠ” ê²½ìš°)
        - Combined: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ìµœëŒ€ 3ê°œ, ì„ë² ë”©ì´ ìˆëŠ” ê²½ìš°)
        
        **Threshold í•„í„°ë§**:
        - Lexical: {self.lexical_threshold} ì´ìƒ
        - Semantic: {self.semantic_threshold} ì´ìƒ
        - Combined: {self.combined_threshold} ì´ìƒ
        
        Args:
            entity_name: ì—”í‹°í‹° ì´ë¦„
            domain_id: ê²€ìƒ‰í•  ë„ë©”ì¸ ID (í•´ë‹¹ ë„ë©”ì¸ë§Œ í•„í„°ë§)
            entity_embedding: ì—”í‹°í‹° ì„ë² ë”© ë²¡í„° (ì„ íƒì‚¬í•­)
            es_index: Elasticsearch ì¸ë±ìŠ¤ ì´ë¦„
            
        Returns:
            List[Dict]: Thresholdë¥¼ í†µê³¼í•œ í›„ë³´ ë¦¬ìŠ¤íŠ¸ (ê° í›„ë³´ëŠ” _search_type í•„ë“œ í¬í•¨)
        """
        logger.info("=" * 80)
        logger.info("Stage 1: í›„ë³´êµ° ì¶”ì¶œ (Lexical + Semantic + Combined)")
        logger.info(f"  ì—”í‹°í‹°: {entity_name}")
        logger.info(f"  ë„ë©”ì¸: {domain_id}")
        logger.info("=" * 80)
        
        all_candidates = []
        
        # ===== 1. Lexical Analysis: í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ =====
        logger.info("\nğŸ“ 1-1. Lexical Analysis (í…ìŠ¤íŠ¸ ê²€ìƒ‰, threshold: {:.2f})".format(self.lexical_threshold))
        lexical_results = self._perform_text_only_search(entity_name, domain_id, es_index, 3)
        lexical_results_filtered = [hit for hit in lexical_results if hit['_score'] >= self.lexical_threshold]
        logger.info(f"âœ… Lexical: {len(lexical_results)}ê°œ â†’ {len(lexical_results_filtered)}ê°œ (threshold í†µê³¼)")
        
        for hit in lexical_results_filtered:
            hit['_search_type'] = 'lexical'
            all_candidates.append(hit)
            source = hit['_source']
            logger.debug(f"  - {source.get('concept_name', 'N/A')} (ID: {source.get('concept_id', 'N/A')}) [ì ìˆ˜: {hit['_score']:.4f}]")
        
        # ===== 2. Semantic Analysis: ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ =====
        logger.info("\nğŸ§  1-2. Semantic Analysis (ë²¡í„° ê²€ìƒ‰, threshold: {:.2f})".format(self.semantic_threshold))
        semantic_results_filtered = []
        if entity_embedding is not None:
            semantic_results = self._perform_vector_search(entity_embedding, domain_id, es_index, 3)
            semantic_results_filtered = [hit for hit in semantic_results if hit['_score'] >= self.semantic_threshold]
            logger.info(f"âœ… Semantic: {len(semantic_results)}ê°œ â†’ {len(semantic_results_filtered)}ê°œ (threshold í†µê³¼)")
            
            for hit in semantic_results_filtered:
                hit['_search_type'] = 'semantic'
                all_candidates.append(hit)
                source = hit['_source']
                logger.debug(f"  - {source.get('concept_name', 'N/A')} (ID: {source.get('concept_id', 'N/A')}) [ì ìˆ˜: {hit['_score']:.4f}]")
        else:
            logger.warning("âš ï¸ ì„ë² ë”© ì—†ìŒ - Semantic ê²€ìƒ‰ ê±´ë„ˆëœ€")
        
        # ===== 3. Combined Score: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ =====
        logger.info("\nğŸ”„ 1-3. Combined Score (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰, threshold: {:.2f})".format(self.combined_threshold))
        combined_results_filtered = []
        if entity_embedding is not None:
            combined_results = self._perform_native_hybrid_search(
                entity_name, entity_embedding, domain_id, es_index, 3
            )
            combined_results_filtered = [hit for hit in combined_results if hit['_score'] >= self.combined_threshold]
        else:
            # ì„ë² ë”©ì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼ ì¬ì‚¬ìš©
            combined_results = lexical_results[:3]
            combined_results_filtered = [hit for hit in combined_results if hit['_score'] >= self.combined_threshold]
        
        logger.info(f"âœ… Combined: {len(combined_results if entity_embedding is not None else lexical_results[:3])}ê°œ â†’ {len(combined_results_filtered)}ê°œ (threshold í†µê³¼)")
        for hit in combined_results_filtered:
            hit['_search_type'] = 'combined'
            all_candidates.append(hit)
            source = hit['_source']
            logger.debug(f"  - {source.get('concept_name', 'N/A')} (ID: {source.get('concept_id', 'N/A')}) [ì ìˆ˜: {hit['_score']:.4f}]")
        
        # ìµœì¢… ìš”ì•½
        logger.info("\n" + "=" * 80)
        logger.info(f"ğŸ“Š Stage 1 ì™„ë£Œ: ì´ {len(all_candidates)}ê°œ í›„ë³´ ì¶”ì¶œ")
        logger.info(f"  - Lexical: {len(lexical_results_filtered)}ê°œ (threshold: {self.lexical_threshold:.2f})")
        logger.info(f"  - Semantic: {len(semantic_results_filtered)}ê°œ (threshold: {self.semantic_threshold:.2f})")
        logger.info(f"  - Combined: {len(combined_results_filtered)}ê°œ (threshold: {self.combined_threshold:.2f})")
        logger.info("=" * 80)
        
        return all_candidates

    def _perform_text_only_search(self, entity_name: str, domain_id: str, es_index: str, top_k: int) -> List[Dict[str, Any]]:
        """
        í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ ìˆ˜í–‰ (Lexical Search)
        
        **ê²€ìƒ‰ ì „ëµ**:
        - Exact match: concept_name.keywordë¡œ ì •í™•íˆ ì¼ì¹˜í•˜ëŠ” í•­ëª© (boost: 3.0)
        - Phrase match: concept_nameì— êµ¬ë¬¸ ì¼ì¹˜í•˜ëŠ” í•­ëª© (boost: 2.5)
        - Text match: concept_nameì— í…ìŠ¤íŠ¸ ì¼ì¹˜í•˜ëŠ” í•­ëª© (boost: 2.0)
        
        Args:
            entity_name: ê²€ìƒ‰í•  ì—”í‹°í‹° ì´ë¦„
            domain_id: ë„ë©”ì¸ í•„í„° (í•´ë‹¹ ë„ë©”ì¸ë§Œ ê²€ìƒ‰)
            es_index: Elasticsearch ì¸ë±ìŠ¤
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        # Measurement ë„ë©”ì¸ì˜ ê²½ìš° "Meas Value"ë„ í¬í•¨ (OMOP CDM íŠ¹ì„±)
        if domain_id == "Measurement":
            domain_filter = {
                "terms": {
                    "domain_id": ["Measurement", "Meas Value"]
                }
            }
        else:
            domain_filter = {
                "term": {
                    "domain_id": domain_id
                }
            }
        
        body = {
            "size": top_k,
            "query": {
                "bool": {
                    "must": [
                        {
                            "bool": {
                                "should": [
                                    {
                                        "term": {
                                            "concept_name.keyword": {
                                                "value": entity_name,
                                                "boost": 3.0
                                            }
                                        }
                                    },
                                    {
                                        "match_phrase": {
                                            "concept_name": {
                                                "query": entity_name,
                                                "boost": 2.5
                                            }
                                        }
                                    },
                                    {
                                        "match": {
                                            "concept_name": {
                                                "query": entity_name,
                                                "boost": 2.0
                                            }
                                        }
                                    }
                                ],
                                "minimum_should_match": 1
                            }
                        }
                    ],
                    "filter": [
                        domain_filter
                    ]
                }
            }
        }
        
        try:
            response = self.es_client.es_client.search(index=es_index, body=body)
            hits = response['hits']['hits'] if response['hits']['total']['value'] > 0 else []
            return hits
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _perform_vector_search(self, entity_embedding: np.ndarray, domain_id: str, es_index: str, top_k: int) -> List[Dict[str, Any]]:
        """
        ë²¡í„° ê¸°ë°˜ ê²€ìƒ‰ ìˆ˜í–‰ (Semantic Search)
        
        **ê²€ìƒ‰ ì „ëµ**:
        - Elasticsearch KNN (k-Nearest Neighbors) ê²€ìƒ‰ ì‚¬ìš©
        - concept_embedding í•„ë“œì™€ ì…ë ¥ ì„ë² ë”© ê°„ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        - ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ìœ¼ë¡œ ê°€ì¥ ìœ ì‚¬í•œ ê°œë… ê²€ìƒ‰
        
        Args:
            entity_embedding: ì—”í‹°í‹°ì˜ ì„ë² ë”© ë²¡í„° (SapBERT ë“±)
            domain_id: ë„ë©”ì¸ í•„í„° (í•´ë‹¹ ë„ë©”ì¸ë§Œ ê²€ìƒ‰)
            es_index: Elasticsearch ì¸ë±ìŠ¤
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        embedding_list = entity_embedding.tolist()
        
        # Measurement ë„ë©”ì¸ì˜ ê²½ìš° "Meas Value"ë„ í¬í•¨ (OMOP CDM íŠ¹ì„±)
        if domain_id == "Measurement":
            domain_filter = {
                "terms": {
                    "domain_id": ["Measurement", "Meas Value"]
                }
            }
        else:
            domain_filter = {
                "term": {
                    "domain_id": domain_id
                }
            }
        
        vector_query = {
            "knn": {
                "field": "concept_embedding",
                "query_vector": embedding_list,
                "k": top_k,
                "num_candidates": top_k * 3,
                "filter": domain_filter
            },
            "size": top_k,
            "_source": True
        }
        
        try:
            response = self.es_client.es_client.search(index=es_index, body=vector_query)
            hits = response['hits']['hits'] if response['hits']['total']['value'] > 0 else []
            return hits
        except Exception as e:
            logger.error(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _perform_native_hybrid_search(
        self, 
        entity_name: str, 
        entity_embedding: np.ndarray,
        domain_id: str,
        es_index: str, 
        top_k: int
    ) -> List[Dict[str, Any]]:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ìˆ˜í–‰ (í…ìŠ¤íŠ¸ + ë²¡í„° + ê¸¸ì´ ìœ ì‚¬ë„)
        
        **ê²€ìƒ‰ ì „ëµ**:
        - KNN ë²¡í„° ê²€ìƒ‰ (boost: 0.6)
        - í…ìŠ¤íŠ¸ ê²€ìƒ‰ (exact match boost: 3.0, match boost: 2.5)
        - ê¸¸ì´ ìœ ì‚¬ë„ ê°€ì¤‘ì¹˜ (ê°€ìš°ì‹œì•ˆ decay í•¨ìˆ˜ ì‚¬ìš©)
        
        **ê¸¸ì´ ìœ ì‚¬ë„**:
        - ì…ë ¥ ì—”í‹°í‹°ì™€ í›„ë³´ ê°œë…ì˜ ê¸€ì ìˆ˜ ì°¨ì´ë¥¼ ê³ ë ¤
        - ìœ ì‚¬í•œ ê¸¸ì´ì˜ ê°œë…ì— ë†’ì€ ê°€ì¤‘ì¹˜ ë¶€ì—¬
        
        Args:
            entity_name: ê²€ìƒ‰í•  ì—”í‹°í‹° ì´ë¦„
            entity_embedding: ì—”í‹°í‹° ì„ë² ë”© ë²¡í„°
            domain_id: ë„ë©”ì¸ í•„í„°
            es_index: Elasticsearch ì¸ë±ìŠ¤
            top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜
            
        Returns:
            List[Dict]: ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸
        """
        embedding_list = entity_embedding.tolist()
        entity_length = len(entity_name.strip())
        scale_len = max(8.0, entity_length * 0.8)
        
        # Measurement ë„ë©”ì¸ì˜ ê²½ìš° "Meas Value"ë„ í¬í•¨ (OMOP CDM íŠ¹ì„±)
        if domain_id == "Measurement":
            domain_filter = {
                "terms": {
                    "domain_id": ["Measurement", "Meas Value"]
                }
            }
        else:
            domain_filter = {
                "term": {
                    "domain_id": domain_id
                }
            }
        
        body = {
            "size": top_k,
            "knn": {
                "field": "concept_embedding",
                "query_vector": embedding_list,
                "k": top_k * 2,
                "num_candidates": top_k * 5,
                "boost": 0.6,
                "filter": domain_filter
            },
            "query": {
                "function_score": {
                    "query": {
                        "bool": {
                            "must": [
                                {
                                    "bool": {
                                        "should": [
                                            {
                                                "term": {
                                                    "concept_name.keyword": {
                                                        "value": entity_name,
                                                        "boost": 3.0
                                                    }
                                                }
                                            },
                                            {
                                                "match": {
                                                    "concept_name": {
                                                        "query": entity_name,
                                                        "boost": 2.5
                                                    }
                                                }
                                            }
                                        ],
                                        "minimum_should_match": 1
                                    }
                                }
                            ],
                            "filter": [
                                domain_filter
                            ]
                        }
                    },
                    "functions": [
                        {
                            "script_score": {
                                "script": {
                                    "params": {
                                        "origin_len": float(entity_length),
                                        "scale_len": float(scale_len)
                                    },
                                    "source": """
                                        double origin = params.origin_len;
                                        double scale = params.scale_len;
                                        double len = 0.0;
                                        
                                        if (!doc['concept_name.keyword'].isEmpty()) {
                                            len = doc['concept_name.keyword'].value.length();
                                        } else if (!doc['concept_name'].isEmpty()) {
                                            len = doc['concept_name'].value.length();
                                        }
                                        
                                        double x = (len - origin) / scale;
                                        double decay = Math.exp(-0.5 * x * x);
                                        
                                        return 1.0 + decay;
                                    """
                                }
                            }
                        }
                    ],
                    "score_mode": "multiply",
                    "boost_mode": "multiply",
                    "boost": 0.4
                }
            }
        }
        
        try:
            response = self.es_client.es_client.search(index=es_index, body=body)
            hits = response['hits']['hits'] if response['hits']['total']['value'] > 0 else []
            return hits
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
            return self._perform_text_only_search(entity_name, domain_id, es_index, top_k)

