"""
Stage 1: Elasticsearchì—ì„œ ê° ë„ë©”ì¸ë³„ í›„ë³´êµ° 15ê°œ ì¶”ì¶œ
- Lexical Analysis: í…ìŠ¤íŠ¸ ê¸°ë°˜ ê²€ìƒ‰ìœ¼ë¡œ top 5ê°œ
- Semantic Analysis: ì˜ë¯¸ì  ê²€ìƒ‰ìœ¼ë¡œ top 5ê°œ
- Combined Score: í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ top 5ê°œ
"""
from typing import List, Dict, Any, Optional
import logging
import numpy as np

logger = logging.getLogger(__name__)


class Stage1CandidateRetrieval:
    """Stage 1: í›„ë³´êµ° ì¶”ì¶œ (Lexical 5 + Semantic 5 + Combined 5)"""
    
    def __init__(self, es_client, has_sapbert: bool = True):
        """
        Args:
            es_client: Elasticsearch í´ë¼ì´ì–¸íŠ¸
            has_sapbert: SapBERT ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€
        """
        self.es_client = es_client
        self.has_sapbert = has_sapbert
    
    def retrieve_candidates(
        self, 
        entity_name: str, 
        domain_id: str,
        entity_embedding: Optional[np.ndarray] = None,
        es_index: str = "concept-small"
    ) -> List[Dict[str, Any]]:
        """
        ê° ë„ë©”ì¸ë³„ë¡œ lexical 5ê°œ, semantic 5ê°œ, combined 5ê°œ í›„ë³´ ì¶”ì¶œ (ì´ 15ê°œ)
        
        Args:
            entity_name: ì—”í‹°í‹° ì´ë¦„
            domain_id: ë„ë©”ì¸ ID (í•„í„°ë§ì— ì‚¬ìš©)
            entity_embedding: ì—”í‹°í‹° ì„ë² ë”© ë²¡í„° (ì„ íƒì‚¬í•­)
            es_index: Elasticsearch ì¸ë±ìŠ¤
            
        Returns:
            List[Dict]: 15ê°œì˜ í›„ë³´ ë¦¬ìŠ¤íŠ¸ (ê° í›„ë³´ëŠ” ê²€ìƒ‰ íƒ€ì… ì •ë³´ í¬í•¨)
        """
        logger.info("=" * 80)
        logger.info("Stage 1: ê° ë„ë©”ì¸ë³„ í›„ë³´êµ° 15ê°œ ì¶”ì¶œ")
        logger.info("  - Lexical Analysis: 5ê°œ")
        logger.info("  - Semantic Analysis: 5ê°œ")
        logger.info("  - Combined Score: 5ê°œ")
        logger.info("=" * 80)
        
        logger.info(f"ğŸ” ì—”í‹°í‹°: {entity_name}")
        logger.info(f"ğŸ” ë„ë©”ì¸: {domain_id}")
        
        all_candidates = []
        
        # 1. Lexical Analysis - í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ top 5ê°œ
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ“ 1-1. Lexical Analysis (í…ìŠ¤íŠ¸ ê²€ìƒ‰)")
        logger.info("=" * 60)
        lexical_results = self._perform_text_only_search(entity_name, domain_id, es_index, 5)
        logger.info(f"âœ… Lexical í›„ë³´: {len(lexical_results)}ê°œ")
        for i, hit in enumerate(lexical_results, 1):
            source = hit['_source']
            hit['_search_type'] = 'lexical'
            all_candidates.append(hit)
            logger.info(f"  {i}. {source.get('concept_name', 'N/A')} "
                      f"(ID: {source.get('concept_id', 'N/A')}) "
                      f"[Domain: {source.get('domain_id', 'N/A')}] "
                      f"- ì ìˆ˜: {hit['_score']:.4f}")
        
        # 2. Semantic Analysis - ë²¡í„° ê²€ìƒ‰ìœ¼ë¡œ top 5ê°œ
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ§  1-2. Semantic Analysis (ë²¡í„° ê²€ìƒ‰)")
        logger.info("=" * 60)
        if entity_embedding is not None:
            semantic_results = self._perform_vector_search(entity_embedding, domain_id, es_index, 5)
            logger.info(f"âœ… Semantic í›„ë³´: {len(semantic_results)}ê°œ")
            for i, hit in enumerate(semantic_results, 1):
                source = hit['_source']
                hit['_search_type'] = 'semantic'
                all_candidates.append(hit)
                logger.info(f"  {i}. {source.get('concept_name', 'N/A')} "
                          f"(ID: {source.get('concept_id', 'N/A')}) "
                          f"[Domain: {source.get('domain_id', 'N/A')}] "
                          f"- ì ìˆ˜: {hit['_score']:.4f}")
        else:
            logger.warning("âš ï¸ ì„ë² ë”© ì—†ìŒ - Semantic ê²€ìƒ‰ ê±´ë„ˆëœ€")
        
        # 3. Combined Score - í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ìœ¼ë¡œ top 5ê°œ
        logger.info("\n" + "=" * 60)
        logger.info("ğŸ”„ 1-3. Combined Score (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰)")
        logger.info("=" * 60)
        if entity_embedding is not None:
            combined_results = self._perform_native_hybrid_search(
                entity_name, entity_embedding, domain_id, es_index, 5
            )
        else:
            # ì„ë² ë”©ì´ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ê²€ìƒ‰ ê²°ê³¼ ì¬ì‚¬ìš©
            combined_results = lexical_results[:5]
        
        logger.info(f"âœ… Combined í›„ë³´: {len(combined_results)}ê°œ")
        for i, hit in enumerate(combined_results, 1):
            source = hit['_source']
            hit['_search_type'] = 'combined'
            all_candidates.append(hit)
            logger.info(f"  {i}. {source.get('concept_name', 'N/A')} "
                      f"(ID: {source.get('concept_id', 'N/A')}) "
                      f"[Domain: {source.get('domain_id', 'N/A')}] "
                      f"- ì ìˆ˜: {hit['_score']:.4f}")
        
        # ìµœì¢… ìš”ì•½
        logger.info("\n" + "=" * 80)
        logger.info(f"ğŸ“Š Stage 1 ì™„ë£Œ: ì´ {len(all_candidates)}ê°œ í›„ë³´ ì¶”ì¶œ")
        logger.info(f"  - Lexical: {len(lexical_results)}ê°œ")
        logger.info(f"  - Semantic: {len(semantic_results) if entity_embedding is not None else 0}ê°œ")
        logger.info(f"  - Combined: {len(combined_results)}ê°œ")
        logger.info("=" * 80)
        
        return all_candidates
    
    def _perform_text_only_search(self, entity_name: str, domain_id: str, es_index: str, top_k: int) -> List[Dict[str, Any]]:
        """í…ìŠ¤íŠ¸ ê²€ìƒ‰ ìˆ˜í–‰ (domain_id í•„í„° ì ìš©)"""
        # Measurement ë„ë©”ì¸ì˜ ê²½ìš° Meas Valueë„ í¬í•¨
        if domain_id == "Measurement":
            domain_filter = {
                "terms": {
                    "domain_id": ["Measurement", "Meas Value"]
                }
            }
        else:
            domain_filter = {
                "term": {
                    "domain_id": domain_id
                }
            }
        
        body = {
            "size": top_k,
            "query": {
                "bool": {
                    "must": [
                        {
                            "bool": {
                                "should": [
                                    {
                                        "term": {
                                            "concept_name.keyword": {
                                                "value": entity_name,
                                                "boost": 3.0
                                            }
                                        }
                                    },
                                    {
                                        "match_phrase": {
                                            "concept_name": {
                                                "query": entity_name,
                                                "boost": 2.5
                                            }
                                        }
                                    },
                                    {
                                        "match": {
                                            "concept_name": {
                                                "query": entity_name,
                                                "boost": 2.0
                                            }
                                        }
                                    }
                                ],
                                "minimum_should_match": 1
                            }
                        }
                    ],
                    "filter": [
                        domain_filter
                    ]
                }
            }
        }
        
        try:
            response = self.es_client.es_client.search(index=es_index, body=body)
            hits = response['hits']['hits'] if response['hits']['total']['value'] > 0 else []
            return hits
        except Exception as e:
            logger.error(f"í…ìŠ¤íŠ¸ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _perform_vector_search(self, entity_embedding: np.ndarray, domain_id: str, es_index: str, top_k: int) -> List[Dict[str, Any]]:
        """ë²¡í„° ê²€ìƒ‰ ìˆ˜í–‰ (domain_id í•„í„° ì ìš©)"""
        embedding_list = entity_embedding.tolist()
        
        # Measurement ë„ë©”ì¸ì˜ ê²½ìš° Meas Valueë„ í¬í•¨
        if domain_id == "Measurement":
            domain_filter = {
                "terms": {
                    "domain_id": ["Measurement", "Meas Value"]
                }
            }
        else:
            domain_filter = {
                "term": {
                    "domain_id": domain_id
                }
            }
        
        vector_query = {
            "knn": {
                "field": "concept_embedding",
                "query_vector": embedding_list,
                "k": top_k,
                "num_candidates": top_k * 3,
                "filter": domain_filter
            },
            "size": top_k,
            "_source": True
        }
        
        try:
            response = self.es_client.es_client.search(index=es_index, body=vector_query)
            hits = response['hits']['hits'] if response['hits']['total']['value'] > 0 else []
            return hits
        except Exception as e:
            logger.error(f"ë²¡í„° ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            return []
    
    def _perform_native_hybrid_search(
        self, 
        entity_name: str, 
        entity_embedding: np.ndarray,
        domain_id: str,
        es_index: str, 
        top_k: int
    ) -> List[Dict[str, Any]]:
        """ë„¤ì´í‹°ë¸Œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ (ë²¡í„° + í…ìŠ¤íŠ¸ + ê¸€ììˆ˜ ìœ ì‚¬ë„ + domain_id í•„í„°)"""
        embedding_list = entity_embedding.tolist()
        entity_length = len(entity_name.strip())
        scale_len = max(8.0, entity_length * 0.8)
        
        # Measurement ë„ë©”ì¸ì˜ ê²½ìš° Meas Valueë„ í¬í•¨
        if domain_id == "Measurement":
            domain_filter = {
                "terms": {
                    "domain_id": ["Measurement", "Meas Value"]
                }
            }
        else:
            domain_filter = {
                "term": {
                    "domain_id": domain_id
                }
            }
        
        body = {
            "size": top_k,
            "knn": {
                "field": "concept_embedding",
                "query_vector": embedding_list,
                "k": top_k * 2,
                "num_candidates": top_k * 5,
                "boost": 0.6,
                "filter": domain_filter
            },
            "query": {
                "function_score": {
                    "query": {
                        "bool": {
                            "must": [
                                {
                                    "bool": {
                                        "should": [
                                            {
                                                "term": {
                                                    "concept_name.keyword": {
                                                        "value": entity_name,
                                                        "boost": 3.0
                                                    }
                                                }
                                            },
                                            {
                                                "match": {
                                                    "concept_name": {
                                                        "query": entity_name,
                                                        "boost": 2.5
                                                    }
                                                }
                                            }
                                        ],
                                        "minimum_should_match": 1
                                    }
                                }
                            ],
                            "filter": [
                                domain_filter
                            ]
                        }
                    },
                    "functions": [
                        {
                            "script_score": {
                                "script": {
                                    "params": {
                                        "origin_len": float(entity_length),
                                        "scale_len": float(scale_len)
                                    },
                                    "source": """
                                        double origin = params.origin_len;
                                        double scale = params.scale_len;
                                        double len = 0.0;
                                        
                                        if (!doc['concept_name.keyword'].isEmpty()) {
                                            len = doc['concept_name.keyword'].value.length();
                                        } else if (!doc['concept_name'].isEmpty()) {
                                            len = doc['concept_name'].value.length();
                                        }
                                        
                                        double x = (len - origin) / scale;
                                        double decay = Math.exp(-0.5 * x * x);
                                        
                                        return 1.0 + decay;
                                    """
                                }
                            }
                        }
                    ],
                    "score_mode": "multiply",
                    "boost_mode": "multiply",
                    "boost": 0.4
                }
            }
        }
        
        try:
            response = self.es_client.es_client.search(index=es_index, body=body)
            hits = response['hits']['hits'] if response['hits']['total']['value'] > 0 else []
            return hits
        except Exception as e:
            logger.error(f"í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
            # ì‹¤íŒ¨ì‹œ í…ìŠ¤íŠ¸ ê²€ìƒ‰ìœ¼ë¡œ ëŒ€ì²´
            return self._perform_text_only_search(entity_name, domain_id, es_index, top_k)

