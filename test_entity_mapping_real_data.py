import pandas as pd
import logging
import os
from datetime import datetime
from pathlib import Path
import sys
import openpyxl
from openpyxl.styles import Font, Alignment, PatternFill
from tqdm import tqdm
import time

sys.path.append('/home/work/skku/hyo/omop-mapper/src')

from omop_mapper.entity_mapping_api import EntityMappingAPI, EntityInput, DomainID
from omop_mapper.elasticsearch_client import ElasticsearchClient

class RealDataEntityMappingTester:
    def __init__(self, log_dir: str = "test_logs_real_data"):
        """ì‹¤ì œ ë°ì´í„° í…ŒìŠ¤í„° ì´ˆê¸°í™”"""
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        self.setup_logging()
        
        self.es_client = ElasticsearchClient()
        self.es_client.concept_index = "concept-small"
        self.es_client.concept_synonym_index = "concept-synonym"
        
        self.api = EntityMappingAPI(es_client=self.es_client)
        
        self.domain_mapping = {
            'Condition': DomainID.CONDITION,
            'Procedure': DomainID.PROCEDURE,
            'Drug': DomainID.DRUG,
            'Observation': DomainID.OBSERVATION,
            'Measurement': DomainID.MEASUREMENT,
            'Period': DomainID.PERIOD,
            'Provider': DomainID.PROVIDER,
            'Device': DomainID.DEVICE,
        }
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        log_file = self.log_dir / f"entity_mapping_real_data_{timestamp}.log"
        
        self.logger = logging.getLogger('entity_mapping_real_data')
        self.logger.setLevel(logging.INFO)
        
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
        # API ë¡œê±°ë“¤ë„ íŒŒì¼ì— ê¸°ë¡
        api_logger = logging.getLogger('omop_mapper.entity_mapping_api')
        api_logger.setLevel(logging.INFO)
        api_logger.addHandler(file_handler)
        
        stage1_logger = logging.getLogger('omop_mapper.mapping_stages.stage1_candidate_retrieval')
        stage1_logger.setLevel(logging.INFO)
        stage1_logger.addHandler(file_handler)
        
        stage2_logger = logging.getLogger('omop_mapper.mapping_stages.stage2_standard_collection')
        stage2_logger.setLevel(logging.INFO)
        stage2_logger.addHandler(file_handler)
        
        stage3_logger = logging.getLogger('omop_mapper.mapping_stages.stage3_hybrid_scoring')
        stage3_logger.setLevel(logging.INFO)
        stage3_logger.addHandler(file_handler)
        
        self.logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file}")
    
    def load_and_sample_data(self, csv_path: str, sample_size: int = 10000, random_state: int = 42) -> pd.DataFrame:
        """CSV íŒŒì¼ì—ì„œ ëœë¤ ìƒ˜í”Œë§"""
        self.logger.info(f"ë°ì´í„° ë¡œë”© ì‹œì‘: {csv_path}")
        self.logger.info(f"ìƒ˜í”Œ í¬ê¸°: {sample_size}ê°œ")
        
        # ì²­í¬ ë‹¨ìœ„ë¡œ ì½ì–´ì„œ ìƒ˜í”Œë§ (ë©”ëª¨ë¦¬ íš¨ìœ¨)
        chunk_size = 100000
        chunks = []
        
        self.logger.info("ì²­í¬ ë‹¨ìœ„ë¡œ ë°ì´í„° ì½ëŠ” ì¤‘...")
        for chunk in tqdm(pd.read_csv(csv_path, chunksize=chunk_size), desc="ë°ì´í„° ë¡œë”©"):
            chunks.append(chunk)
        
        # ì „ì²´ ë°ì´í„° ë³‘í•©
        df = pd.concat(chunks, ignore_index=True)
        self.logger.info(f"ì „ì²´ ë°ì´í„° í¬ê¸°: {len(df):,}ê°œ")
        
        # ëœë¤ ìƒ˜í”Œë§
        df_sample = df.sample(n=min(sample_size, len(df)), random_state=random_state)
        df_sample = df_sample.reset_index(drop=True)
        
        self.logger.info(f"ìƒ˜í”Œë§ ì™„ë£Œ: {len(df_sample):,}ê°œ")
        self.logger.info(f"ì»¬ëŸ¼: {list(df_sample.columns)}")
        
        # ë„ë©”ì¸ ë¶„í¬ ì¶œë ¥
        if 'domain_id' in df_sample.columns:
            domain_dist = df_sample['domain_id'].value_counts()
            self.logger.info("\në„ë©”ì¸ ë¶„í¬:")
            for domain, count in domain_dist.items():
                self.logger.info(f"  {domain}: {count}ê°œ ({count/len(df_sample)*100:.1f}%)")
        
        return df_sample
    
    def create_entity_input(self, row) -> EntityInput:
        """DataFrame í–‰ì—ì„œ EntityInput ìƒì„±"""
        entity_name = str(row['entity_name']).strip()
        
        # ë„ë©”ì¸ ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ None (ëª¨ë“  ë„ë©”ì¸ ê²€ìƒ‰)
        domain_id = None
        if 'domain_id' in row and pd.notna(row['domain_id']):
            domain_str = str(row['domain_id']).strip()
            if domain_str and domain_str in self.domain_mapping:
                domain_id = self.domain_mapping[domain_str]
        
        return EntityInput(
            entity_name=entity_name,
            domain_id=domain_id,
            vocabulary_id=None
        )
    
    def test_single_entity(self, entity_input: EntityInput, test_index: int, ground_truth_concept_id: int) -> dict:
        """ë‹¨ì¼ ì—”í‹°í‹° í…ŒìŠ¤íŠ¸"""
        try:
            # ë§¤í•‘ ìˆ˜í–‰
            results = self.api.map_entity(entity_input)
            
            # ë‹¨ê³„ë³„ í›„ë³´êµ° ìˆ˜ì§‘
            stage1_candidates = []
            stage2_candidates = []
            stage3_candidates = []
            
            if hasattr(self.api, '_last_stage1_candidates') and self.api._last_stage1_candidates:
                stage1_candidates = self.api._last_stage1_candidates
            
            if hasattr(self.api, '_last_stage2_candidates') and self.api._last_stage2_candidates:
                stage2_candidates = self.api._last_stage2_candidates
            
            if hasattr(self.api, '_last_rerank_candidates') and self.api._last_rerank_candidates:
                stage3_candidates = self.api._last_rerank_candidates
            
            # ë„ë©”ì¸ë³„ ê²°ê³¼ ì •ë¦¬
            domain_results = []
            if results:
                for result in results:
                    domain_info = {
                        'domain_id': result.domain_id,
                        'mapped_concept_id': result.mapped_concept_id,
                        'mapped_concept_name': result.mapped_concept_name,
                        'mapping_score': result.mapping_score,
                        'mapping_confidence': result.mapping_confidence,
                        'mapping_method': result.mapping_method,
                        'vocabulary_id': result.vocabulary_id
                    }
                    domain_results.append(domain_info)
            
            # ìµœê³  ì ìˆ˜ ê²°ê³¼ ì„ íƒ
            best_result = max(results, key=lambda x: x.mapping_score) if results else None
            
            # ë„ë©”ì¸ë³„ Stage ê²½ë¡œ ì •ë³´
            domain_stage_paths = {}
            best_search_domain = None
            if hasattr(self.api, '_all_domain_stage_results') and self.api._all_domain_stage_results:
                domain_stage_paths = self.api._all_domain_stage_results
                
                if best_result:
                    for search_domain, stage_info in domain_stage_paths.items():
                        if stage_info.get('result_domain') == best_result.domain_id:
                            best_search_domain = search_domain
                            break
            
            # ë§¤í•‘ ì„±ê³µ ì—¬ë¶€ íŒë‹¨ (concept_id ì¼ì¹˜)
            mapping_correct = False
            if best_result and ground_truth_concept_id:
                mapping_correct = (best_result.mapped_concept_id == ground_truth_concept_id)
            
            test_result = {
                'test_index': test_index,
                'entity_name': entity_input.entity_name,
                'ground_truth_concept_id': ground_truth_concept_id,
                'success': results is not None and len(results) > 0,
                'mapping_correct': mapping_correct,
                'domain_count': len(results) if results else 0,
                'domain_results': domain_results,
                'domain_stage_paths': domain_stage_paths,
                'best_search_domain': best_search_domain,
                'best_result_domain': best_result.domain_id if best_result else None,
                'best_concept_id': best_result.mapped_concept_id if best_result else None,
                'best_concept_name': best_result.mapped_concept_name if best_result else None,
                'best_score': best_result.mapping_score if best_result else 0.0,
                'best_confidence': best_result.mapping_confidence if best_result else None,
                'stage1_candidates': stage1_candidates,
                'stage2_candidates': stage2_candidates,
                'stage3_candidates': stage3_candidates
            }
            
            return test_result
            
        except Exception as e:
            self.logger.error(f"í…ŒìŠ¤íŠ¸ #{test_index} ì˜¤ë¥˜: {str(e)}")
            return {
                'test_index': test_index,
                'entity_name': entity_input.entity_name,
                'ground_truth_concept_id': ground_truth_concept_id,
                'success': False,
                'mapping_correct': False,
                'domain_count': 0,
                'domain_results': [],
                'domain_stage_paths': {},
                'best_search_domain': None,
                'best_result_domain': None,
                'best_concept_id': None,
                'best_concept_name': None,
                'best_score': 0.0,
                'best_confidence': None,
                'error': str(e),
                'stage1_candidates': [],
                'stage2_candidates': [],
                'stage3_candidates': []
            }
    
    def run_test_with_real_data(self, csv_path: str, sample_size: int = 10000):
        """ì‹¤ì œ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.logger.info("=" * 100)
        self.logger.info("ğŸš€ ì‹¤ì œ ë°ì´í„° Entity Mapping í…ŒìŠ¤íŠ¸ ì‹œì‘")
        self.logger.info("=" * 100)
        
        start_time = time.time()
        
        # ë°ì´í„° ë¡œë”© ë° ìƒ˜í”Œë§
        test_data = self.load_and_sample_data(csv_path, sample_size)
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        test_results = []
        successful_mappings = 0
        correct_mappings = 0
        
        # tqdmìœ¼ë¡œ ì§„í–‰ ìƒí™© í‘œì‹œ
        for idx, row in tqdm(test_data.iterrows(), total=len(test_data), desc="ì—”í‹°í‹° ë§¤í•‘ í…ŒìŠ¤íŠ¸"):
            try:
                entity_input = self.create_entity_input(row)
                ground_truth = int(row['concept_id']) if pd.notna(row['concept_id']) else None
                
                result = self.test_single_entity(entity_input, idx + 1, ground_truth)
                test_results.append(result)
                
                if result['success']:
                    successful_mappings += 1
                    if result['mapping_correct']:
                        correct_mappings += 1
                        
            except Exception as e:
                self.logger.error(f"í…ŒìŠ¤íŠ¸ #{idx + 1} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # í…ŒìŠ¤íŠ¸ ì™„ë£Œ ì‹œê°„
        end_time = time.time()
        elapsed_time = end_time - start_time
        
        # ê²°ê³¼ ìš”ì•½
        total_tests = len(test_results)
        success_rate = (successful_mappings / total_tests * 100) if total_tests > 0 else 0
        accuracy = (correct_mappings / total_tests * 100) if total_tests > 0 else 0
        
        self.logger.info("\n" + "=" * 100)
        self.logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        self.logger.info("=" * 100)
        self.logger.info(f"ì´ í…ŒìŠ¤íŠ¸: {total_tests:,}ê°œ")
        self.logger.info(f"ë§¤í•‘ ì„±ê³µ: {successful_mappings:,}ê°œ ({success_rate:.2f}%)")
        self.logger.info(f"ì •ë‹µ ë§¤ì¹­: {correct_mappings:,}ê°œ ({accuracy:.2f}%)")
        self.logger.info(f"ë§¤í•‘ ì‹¤íŒ¨: {total_tests - successful_mappings:,}ê°œ")
        self.logger.info(f"ì†Œìš” ì‹œê°„: {elapsed_time:.2f}ì´ˆ ({elapsed_time/60:.2f}ë¶„)")
        self.logger.info(f"í‰ê·  ì²˜ë¦¬ ì‹œê°„: {elapsed_time/total_tests:.3f}ì´ˆ/ì—”í‹°í‹°")
        self.logger.info("=" * 100)
        
        # ê²°ê³¼ë¥¼ CSVì™€ XLSXë¡œ ì €ì¥
        self.save_results_to_csv(test_results)
        self.save_results_to_xlsx(test_results)
        
        return test_results
    
    def save_results_to_csv(self, test_results: list):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_file = self.log_dir / f"real_data_results_{timestamp}.csv"
        
        csv_results = []
        for result in test_results:
            base_info = {
                'test_index': result['test_index'],
                'entity_name': result['entity_name'],
                'ground_truth_concept_id': result['ground_truth_concept_id'],
                'success': result['success'],
                'mapping_correct': result['mapping_correct'],
                'domain_count': result.get('domain_count', 0),
                'best_search_domain': result.get('best_search_domain', 'N/A'),
                'best_result_domain': result.get('best_result_domain', 'N/A'),
                'best_concept_id': result.get('best_concept_id', 'N/A'),
                'best_concept_name': result.get('best_concept_name', 'N/A'),
                'best_score': result.get('best_score', 0.0),
                'best_confidence': result.get('best_confidence', 'N/A')
            }
            csv_results.append(base_info)
        
        df_results = pd.DataFrame(csv_results)
        df_results.to_csv(csv_file, index=False, encoding='utf-8')
        
        self.logger.info(f"ğŸ“„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ CSV ì €ì¥: {csv_file}")
    
    def save_results_to_xlsx(self, test_results: list):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ XLSX íŒŒì¼ë¡œ ì €ì¥ (stage í›„ë³´êµ° í¬í•¨)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        xlsx_file = self.log_dir / f"real_data_results_detailed_{timestamp}.xlsx"
        
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "Detailed Results"
        
        self._create_detailed_sheet(ws, test_results)
        
        wb.save(xlsx_file)
        self.logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ XLSX ì €ì¥: {xlsx_file}")
    
    def _create_detailed_sheet(self, ws, test_results):
        """ìƒì„¸ ì‹œíŠ¸ ìƒì„±"""
        
        # í—¤ë” ì„¤ì •
        headers = [
            "Test Index", "Entity Name", "Ground Truth Concept ID", 
            "Success", "Mapping Correct", "Domain Count",
            "Best Search Domain", "Best Result Domain", 
            "Best Concept ID", "Best Concept Name", 
            "Best Score", "Best Confidence",
            "All Domains", "Domain Stage Paths", 
            "Stage1 Candidates", "Stage2 Candidates", "Stage3 Candidates"
        ]
        
        # í—¤ë” ìŠ¤íƒ€ì¼
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        header_alignment = Alignment(horizontal="center", vertical="center")
        
        # í—¤ë” ì‘ì„±
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col, value=header)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = header_alignment
        
        # ë°ì´í„° ì‘ì„±
        for row, result in enumerate(test_results, 2):
            ws.cell(row=row, column=1, value=result['test_index'])
            ws.cell(row=row, column=2, value=result['entity_name'])
            ws.cell(row=row, column=3, value=result['ground_truth_concept_id'])
            ws.cell(row=row, column=4, value="ì„±ê³µ" if result['success'] else "ì‹¤íŒ¨")
            
            # ë§¤í•‘ ì •í™•ë„ í‘œì‹œ (ìƒ‰ìƒ ì ìš©)
            correct_cell = ws.cell(row=row, column=5, value="ì •ë‹µ" if result['mapping_correct'] else "ì˜¤ë‹µ")
            if result['mapping_correct']:
                correct_cell.fill = PatternFill(start_color="C6EFCE", end_color="C6EFCE", fill_type="solid")
                correct_cell.font = Font(color="006100")
            else:
                correct_cell.fill = PatternFill(start_color="FFC7CE", end_color="FFC7CE", fill_type="solid")
                correct_cell.font = Font(color="9C0006")
            
            ws.cell(row=row, column=6, value=result.get('domain_count', 0))
            ws.cell(row=row, column=7, value=result.get('best_search_domain', 'N/A'))
            ws.cell(row=row, column=8, value=result.get('best_result_domain', 'N/A'))
            ws.cell(row=row, column=9, value=result.get('best_concept_id', 'N/A'))
            ws.cell(row=row, column=10, value=result.get('best_concept_name', 'N/A'))
            ws.cell(row=row, column=11, value=result.get('best_score', 0.0))
            ws.cell(row=row, column=12, value=result.get('best_confidence', 'N/A'))
            
            # ë„ë©”ì¸ ê²°ê³¼
            domain_results_text = self._format_domain_results(result.get('domain_results', []))
            ws.cell(row=row, column=13, value=domain_results_text)
            
            # Stage ê²½ë¡œ
            stage_paths_text = self._format_stage_paths(result.get('domain_stage_paths', {}))
            ws.cell(row=row, column=14, value=stage_paths_text)
            
            # Stage í›„ë³´êµ°
            stage1_text = self._format_candidates_for_cell(result.get('stage1_candidates', []), 'stage1')
            ws.cell(row=row, column=15, value=stage1_text)
            
            stage2_text = self._format_candidates_for_cell(result.get('stage2_candidates', []), 'stage2')
            ws.cell(row=row, column=16, value=stage2_text)
            
            stage3_text = self._format_candidates_for_cell(result.get('stage3_candidates', []), 'stage3')
            ws.cell(row=row, column=17, value=stage3_text)
            
            # ì…€ ìŠ¤íƒ€ì¼ ì„¤ì •
            for col in range(13, 18):
                cell = ws.cell(row=row, column=col)
                cell.alignment = Alignment(wrap_text=True, vertical='top')
        
        # ì—´ ë„ˆë¹„ ì„¤ì •
        column_widths = {
            'A': 10,  # Test Index
            'B': 40,  # Entity Name
            'C': 20,  # Ground Truth Concept ID
            'D': 10,  # Success
            'E': 12,  # Mapping Correct
            'F': 12,  # Domain Count
            'G': 18,  # Best Search Domain
            'H': 18,  # Best Result Domain
            'I': 15,  # Best Concept ID
            'J': 45,  # Best Concept Name
            'K': 12,  # Best Score
            'L': 15,  # Best Confidence
            'M': 50,  # All Domains
            'N': 45,  # Domain Stage Paths
            'O': 70,  # Stage1 Candidates
            'P': 70,  # Stage2 Candidates
            'Q': 85   # Stage3 Candidates
        }
        
        for col_letter, width in column_widths.items():
            ws.column_dimensions[col_letter].width = width
        
        # í–‰ ë†’ì´ ì„¤ì •
        for row_num in range(2, len(test_results) + 2):
            ws.row_dimensions[row_num].height = 150
    
    def _format_domain_results(self, domain_results):
        """ë„ë©”ì¸ë³„ ê²°ê³¼ í¬ë§·íŒ…"""
        if not domain_results:
            return "ë„ë©”ì¸ ê²°ê³¼ ì—†ìŒ"
        
        lines = []
        for i, domain in enumerate(domain_results, 1):
            line = f"{i}. [{domain.get('domain_id', 'N/A')}] {domain.get('mapped_concept_name', 'N/A')}\n"
            line += f"   ID: {domain.get('mapped_concept_id', 'N/A')}, "
            line += f"Score: {domain.get('mapping_score', 0):.4f}, "
            line += f"Conf: {domain.get('mapping_confidence', 'N/A')}\n"
            line += f"   Vocab: {domain.get('vocabulary_id', 'N/A')}"
            lines.append(line)
        
        return "\n\n".join(lines)
    
    def _format_stage_paths(self, stage_paths):
        """Stage ê²½ë¡œ í¬ë§·íŒ…"""
        if not stage_paths:
            return "ê²½ë¡œ ì •ë³´ ì—†ìŒ"
        
        lines = []
        for domain_name, stage_info in sorted(stage_paths.items()):
            search_domain = stage_info.get('search_domain', domain_name)
            result_domain = stage_info.get('result_domain', 'N/A')
            
            if search_domain != result_domain:
                line = f"[{search_domain} â†’ {result_domain}]\n"
            else:
                line = f"[{search_domain}]\n"
            
            line += f"  Stage1: {stage_info.get('stage1_count', 0)}ê°œ\n"
            line += f"  Stage2: {stage_info.get('stage2_count', 0)}ê°œ\n"
            line += f"  Stage3: {stage_info.get('stage3_count', 0)}ê°œ"
            lines.append(line)
        
        return "\n\n".join(lines)
    
    def _format_candidates_for_cell(self, candidates, stage_type):
        """í›„ë³´êµ° í¬ë§·íŒ…"""
        if not candidates:
            return "í›„ë³´ ì—†ìŒ"
        
        lines = []
        max_candidates = 15 if stage_type in ['stage1', 'stage2'] else 10
        
        for i, candidate in enumerate(candidates[:max_candidates], 1):
            if stage_type == 'stage1':
                search_type = candidate.get('search_type', 'unknown')
                line = f"{i}. [{search_type}] {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                line += f"   ESì ìˆ˜: {candidate.get('elasticsearch_score', 0):.4f}, "
                line += f"Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Domain: {candidate.get('domain_id', 'N/A')}"
            elif stage_type == 'stage2':
                search_type = candidate.get('search_type', 'unknown')
                is_std = "âœ“" if candidate.get('is_original_standard', True) else "â†’"
                line = f"{i}. [{search_type}] {is_std} {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                line += f"   Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Domain: {candidate.get('domain_id', 'N/A')}"
                if not candidate.get('is_original_standard', True):
                    original_non_std = candidate.get('original_non_standard', {})
                    if original_non_std:
                        line += f"\n   ì›ë³¸ Non-std: {original_non_std.get('concept_name', 'N/A')} (ID: {original_non_std.get('concept_id', 'N/A')})"
            else:  # stage3
                search_type = candidate.get('search_type', 'unknown')
                line = f"{i}. [{search_type}] {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                line += f"   í…ìŠ¤íŠ¸: {candidate.get('text_similarity', 0):.4f}, "
                line += f"ì˜ë¯¸ì : {candidate.get('semantic_similarity', 0):.4f}, "
                line += f"ìµœì¢…: {candidate.get('final_score', 0):.4f}\n"
                line += f"   Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Domain: {candidate.get('domain_id', 'N/A')}"
            
            lines.append(line)
        
        return "\n\n".join(lines)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    tester = RealDataEntityMappingTester()
    
    # ì‹¤ì œ ë°ì´í„° ê²½ë¡œ
    csv_path = "/home/work/skku/hyo/omop-mapper/data/mapping_test_snomed_no_note.csv"
    
    # 1ë§Œê±´ ìƒ˜í”Œë§ í…ŒìŠ¤íŠ¸
    results = tester.run_test_with_real_data(csv_path, sample_size=10)
    
    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ê²°ê³¼ëŠ” {tester.log_dir} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()

