import pandas as pd
import logging
import os
from datetime import datetime
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append('/home/work/skku/hyo/omop-mapper/src')

from omop_mapper.entity_mapping_api import EntityMappingAPI, EntityInput, DomainID

class EntityMappingTester:
    def __init__(self, log_dir: str = "test_logs"):
        """í…ŒìŠ¤í„° ì´ˆê¸°í™”"""
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # ë¡œê·¸ ì„¤ì •
        self.setup_logging()
        
        # API ì´ˆê¸°í™”
        self.api = EntityMappingAPI()
        
        # ë„ë©”ì¸ ë§¤í•‘
        self.domain_mapping = {
            'Condition': DomainID.CONDITION,
            'Procedure': DomainID.PROCEDURE,
            'Drug': DomainID.DRUG,
            'Observation': DomainID.OBSERVATION,
            'Measurement': DomainID.MEASUREMENT,
            'Period': DomainID.PERIOD,
            'Provider': DomainID.PROVIDER
        }
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ë©”ì¸ ë¡œê·¸ íŒŒì¼
        log_file = self.log_dir / f"entity_mapping_test_{timestamp}.log"
        
        # ë¡œê±° ì„¤ì •
        self.logger = logging.getLogger('entity_mapping_test')
        self.logger.setLevel(logging.INFO)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # í¬ë§·í„°
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # í•¸ë“¤ëŸ¬ ì¶”ê°€
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
        # API ë¡œê±°ë„ ê°™ì€ í•¸ë“¤ëŸ¬ ì‚¬ìš©
        api_logger = logging.getLogger('omop_mapper.entity_mapping_api')
        api_logger.setLevel(logging.INFO)
        api_logger.addHandler(file_handler)
        
        self.logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file}")
    
    def load_test_data(self, excel_path: str) -> pd.DataFrame:
        """í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ"""
        self.logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ: {excel_path}")
        
        all_data = []
        
        for sheet in ['10', '11', '12']:
            df = pd.read_excel(excel_path, sheet_name=sheet)
            
            # NaNì´ ì•„ë‹Œ entity_plain_nameë§Œ í•„í„°ë§
            valid_entities = df.dropna(subset=['entity_plain_name'])
            
            self.logger.info(f"ì‹œíŠ¸ {sheet}: ì´ {len(df)}í–‰, ìœ íš¨í•œ ì—”í‹°í‹° {len(valid_entities)}ê°œ")
            
            # ì‹œíŠ¸ ì •ë³´ ì¶”ê°€
            valid_entities = valid_entities.copy()
            valid_entities['sheet'] = sheet
            
            all_data.append(valid_entities)
        
        combined_data = pd.concat(all_data, ignore_index=True)
        self.logger.info(f"ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(combined_data)}ê°œ ì—”í‹°í‹°")
        
        return combined_data
    
    def create_entity_input(self, row) -> EntityInput:
        """DataFrame í–‰ì—ì„œ EntityInput ìƒì„±"""
        entity_name = str(row['entity_plain_name']).strip()
        domain_str = str(row['entity_domain']).strip() if pd.notna(row['entity_domain']) else None
        
        # ë„ë©”ì¸ ë§¤í•‘
        domain_id = None
        if domain_str and domain_str in self.domain_mapping:
            domain_id = self.domain_mapping[domain_str]
        
        return EntityInput(
            entity_name=entity_name,
            domain_id=domain_id,
            vocabulary_id=None
        )
    
    def test_single_entity(self, entity_input: EntityInput, test_index: int, sheet: str) -> dict:
        """ë‹¨ì¼ ì—”í‹°í‹° í…ŒìŠ¤íŠ¸"""
        self.logger.info("=" * 100)
        self.logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ #{test_index} (ì‹œíŠ¸ {sheet}): {entity_input.entity_name}")
        self.logger.info(f"ë„ë©”ì¸: {entity_input.domain_id}")
        self.logger.info("=" * 100)
        
        try:
            # ë§¤í•‘ ìˆ˜í–‰
            result = self.api.map_entity(entity_input)
            
            # ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´ ë¡œê¹…
            if hasattr(self.api, '_last_rerank_candidates') and self.api._last_rerank_candidates:
                self.logger.info("ğŸ“Š 3ë‹¨ê³„ í›„ë³´êµ° ìƒì„¸ ì •ë³´:")
                for i, candidate in enumerate(self.api._last_rerank_candidates[:5], 1):  # ìƒìœ„ 5ê°œë§Œ
                    self.logger.info(f"   {i}. {candidate['concept_name']} (ID: {candidate['concept_id']})")
                    self.logger.info(f"      - í…ìŠ¤íŠ¸ ìœ ì‚¬ë„: {candidate['text_similarity']:.4f}")
                    self.logger.info(f"      - ì˜ë¯¸ì  ìœ ì‚¬ë„: {candidate['semantic_similarity']:.4f}")
                    self.logger.info(f"      - ìµœì¢… ì ìˆ˜: {candidate['final_score']:.4f}")
                    self.logger.info(f"      - Vocabulary: {candidate['vocabulary_id']}")
            
            # ê²°ê³¼ ì •ë¦¬
            test_result = {
                'test_index': test_index,
                'sheet': sheet,
                'entity_name': entity_input.entity_name,
                'domain_id': str(entity_input.domain_id) if entity_input.domain_id else None,
                'success': result is not None,
                'mapped_concept_id': result.mapped_concept_id if result else None,
                'mapped_concept_name': result.mapped_concept_name if result else None,
                'mapping_score': result.mapping_score if result else 0.0,
                'mapping_confidence': result.mapping_confidence if result else None,
                'mapping_method': result.mapping_method if result else None,
                'alternative_concepts_count': len(result.alternative_concepts) if result and result.alternative_concepts else 0
            }
            
            if result:
                self.logger.info(f"âœ… ë§¤í•‘ ì„±ê³µ!")
                self.logger.info(f"   - ë§¤í•‘ëœ ì»¨ì…‰: {result.mapped_concept_name} (ID: {result.mapped_concept_id})")
                self.logger.info(f"   - ë§¤í•‘ ì ìˆ˜: {result.mapping_score:.4f}")
                self.logger.info(f"   - ë§¤í•‘ ì‹ ë¢°ë„: {result.mapping_confidence}")
                self.logger.info(f"   - ë§¤í•‘ ë°©ë²•: {result.mapping_method}")
                self.logger.info(f"   - Vocabulary: {result.vocabulary_id}")
                if result.alternative_concepts:
                    self.logger.info(f"   - ëŒ€ì•ˆ ê°œìˆ˜: {len(result.alternative_concepts)}ê°œ")
                    for i, alt in enumerate(result.alternative_concepts[:3], 1):  # ìƒìœ„ 3ê°œ ëŒ€ì•ˆ
                        self.logger.info(f"     {i}. {alt['concept_name']} (ID: {alt['concept_id']}, ì ìˆ˜: {alt['score']:.4f})")
            else:
                self.logger.info(f"âŒ ë§¤í•‘ ì‹¤íŒ¨")
                
            return test_result
            
        except Exception as e:
            self.logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
            return {
                'test_index': test_index,
                'sheet': sheet,
                'entity_name': entity_input.entity_name,
                'domain_id': str(entity_input.domain_id) if entity_input.domain_id else None,
                'success': False,
                'error': str(e),
                'mapped_concept_id': None,
                'mapped_concept_name': None,
                'mapping_score': 0.0,
                'mapping_confidence': None,
                'mapping_method': None,
                'alternative_concepts_count': 0
            }
    
    def run_test(self, excel_path: str, max_entities: int = None):
        """ì „ì²´ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.logger.info("ğŸš€ Entity Mapping API í…ŒìŠ¤íŠ¸ ì‹œì‘")
        self.logger.info(f"í…ŒìŠ¤íŠ¸ íŒŒì¼: {excel_path}")
        
        # ë°ì´í„° ë¡œë“œ
        test_data = self.load_test_data(excel_path)
        
        if max_entities:
            test_data = test_data.head(max_entities)
            self.logger.info(f"í…ŒìŠ¤íŠ¸ ì œí•œ: ìµœëŒ€ {max_entities}ê°œ ì—”í‹°í‹°")
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        test_results = []
        successful_tests = 0
        
        for idx, row in test_data.iterrows():
            try:
                entity_input = self.create_entity_input(row)
                result = self.test_single_entity(entity_input, idx + 1, row['sheet'])
                test_results.append(result)
                
                if result['success']:
                    successful_tests += 1
                    
            except Exception as e:
                self.logger.error(f"í…ŒìŠ¤íŠ¸ #{idx + 1} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # ê²°ê³¼ ìš”ì•½
        total_tests = len(test_results)
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        self.logger.info("=" * 100)
        self.logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        self.logger.info("=" * 100)
        self.logger.info(f"ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
        self.logger.info(f"ì„±ê³µ: {successful_tests}ê°œ")
        self.logger.info(f"ì‹¤íŒ¨: {total_tests - successful_tests}ê°œ")
        self.logger.info(f"ì„±ê³µë¥ : {success_rate:.2f}%")
        
        # ì‹œíŠ¸ë³„ ìš”ì•½
        for sheet in ['10', '11', '12']:
            sheet_results = [r for r in test_results if r['sheet'] == sheet]
            sheet_success = len([r for r in sheet_results if r['success']])
            sheet_total = len(sheet_results)
            sheet_rate = (sheet_success / sheet_total * 100) if sheet_total > 0 else 0
            self.logger.info(f"ì‹œíŠ¸ {sheet}: {sheet_success}/{sheet_total} ({sheet_rate:.2f}%)")
        
        # ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥
        self.save_results_to_csv(test_results)
        
        return test_results
    
    def save_results_to_csv(self, test_results: list):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_file = self.log_dir / f"test_results_{timestamp}.csv"
        
        df_results = pd.DataFrame(test_results)
        df_results.to_csv(csv_file, index=False, encoding='utf-8')
        
        self.logger.info(f"ğŸ“„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ CSV ì €ì¥: {csv_file}")

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    tester = EntityMappingTester()
    excel_path = "/home/work/skku/hyo/omop-mapper/data/entity_sample.xlsx"
    results = tester.run_test(excel_path)
    
    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ë¡œê·¸ëŠ” {tester.log_dir} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
