import pandas as pd
import logging
import os
from datetime import datetime
from pathlib import Path
import sys
import openpyxl
from openpyxl.styles import Font, Alignment, PatternFill
from openpyxl.utils.dataframe import dataframe_to_rows

sys.path.append('/home/work/skku/hyo/omop-mapper/src')

from omop_mapper.entity_mapping_api import EntityMappingAPI, EntityInput, DomainID
from omop_mapper.elasticsearch_client import ElasticsearchClient

class EntityMappingTester:
    def __init__(self, log_dir: str = "test_logs"):
        """í…ŒìŠ¤í„° ì´ˆê¸°í™”"""
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        self.setup_logging()
        
        self.es_client = ElasticsearchClient()
        self.es_client.concept_index = "concept-small"
        self.es_client.concept_synonym_index = "concept-synonym"
        
        self.api = EntityMappingAPI(es_client=self.es_client)
        
        self.domain_mapping = {
            'Condition': DomainID.CONDITION,
            'Procedure': DomainID.PROCEDURE,
            'Drug': DomainID.DRUG,
            'Observation': DomainID.OBSERVATION,
            'Measurement': DomainID.MEASUREMENT,
            'Period': DomainID.PERIOD,
            'Provider': DomainID.PROVIDER,
            'Device': DomainID.DEVICE,
        }
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        log_file = self.log_dir / f"entity_mapping_test_{timestamp}.log"
        
        self.logger = logging.getLogger('entity_mapping_test')
        self.logger.setLevel(logging.INFO)
        
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
        api_logger = logging.getLogger('omop_mapper.entity_mapping_api')
        api_logger.setLevel(logging.INFO)
        api_logger.addHandler(file_handler)
        
        stage1_logger = logging.getLogger('omop_mapper.mapping_stages.stage1_candidate_retrieval')
        stage1_logger.setLevel(logging.INFO)
        stage1_logger.addHandler(file_handler)
        
        stage2_logger = logging.getLogger('omop_mapper.mapping_stages.stage2_standard_collection')
        stage2_logger.setLevel(logging.INFO)
        stage2_logger.addHandler(file_handler)
        
        stage3_logger = logging.getLogger('omop_mapper.mapping_stages.stage3_hybrid_scoring')
        stage3_logger.setLevel(logging.INFO)
        stage3_logger.addHandler(file_handler)
        
        self.logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file}")
    
    def load_test_data_from_list(self, entity_list: list) -> pd.DataFrame:
        """ë¦¬ìŠ¤íŠ¸ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±"""
        self.logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: {len(entity_list)}ê°œ ì—”í‹°í‹°")
        
        test_data = []
        for i, entity_name in enumerate(entity_list):
            test_data.append({
                'entity_plain_name': entity_name,
                'sheet': 'manual'  # ìˆ˜ë™ ì…ë ¥ í‘œì‹œ
            })
            self.logger.info(f"  {i+1}. {entity_name}")
        
        df = pd.DataFrame(test_data)
        self.logger.info(f"ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(df)}ê°œ ì—”í‹°í‹°")
        
        return df
    
    def create_entity_input(self, row) -> EntityInput:
        """DataFrame í–‰ì—ì„œ EntityInput ìƒì„±"""
        entity_name = str(row['entity_plain_name']).strip()
        
        # ë„ë©”ì¸ì€ ê¸°ë³¸ì ìœ¼ë¡œ None (ëª¨ë“  ë„ë©”ì¸ ê²€ìƒ‰)
        # ì‚¬ìš©ìê°€ entity_domainì„ ì§€ì •í•œ ê²½ìš°ì—ë§Œ ì‚¬ìš©
        domain_id = None
        if 'entity_domain' in row and pd.notna(row['entity_domain']):
            domain_str = str(row['entity_domain']).strip()
            if domain_str and domain_str in self.domain_mapping:
                domain_id = self.domain_mapping[domain_str]
        
        return EntityInput(
            entity_name=entity_name,
            domain_id=domain_id,
            vocabulary_id=None
        )
    
    def test_single_entity(self, entity_input: EntityInput, test_index: int, sheet: str) -> dict:
        """ë‹¨ì¼ ì—”í‹°í‹° í…ŒìŠ¤íŠ¸ (ë„ë©”ì¸ë³„ ê²°ê³¼)"""
        self.logger.info("=" * 100)
        self.logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ #{test_index} (ì‹œíŠ¸ {sheet}): {entity_input.entity_name}")
        self.logger.info("=" * 100)
        
        try:
            # ë§¤í•‘ ìˆ˜í–‰ (ë„ë©”ì¸ë³„ ê²°ê³¼ ë°˜í™˜)
            results = self.api.map_entity(entity_input)
            
            # ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´ ë¡œê¹… (ë§ˆì§€ë§‰ ë„ë©”ì¸)
            stage1_candidates = []
            stage2_candidates = []
            stage3_candidates = []
            
            if hasattr(self.api, '_last_stage1_candidates') and self.api._last_stage1_candidates:
                stage1_candidates = self.api._last_stage1_candidates
            
            if hasattr(self.api, '_last_stage2_candidates') and self.api._last_stage2_candidates:
                stage2_candidates = self.api._last_stage2_candidates
                self.logger.info("ğŸ“Š Stage 2 í›„ë³´êµ° ìƒì„¸ ì •ë³´:")
                for i, candidate in enumerate(stage2_candidates, 1):
                    search_type = candidate.get('search_type', 'unknown')
                    is_std = "âœ“" if candidate['is_original_standard'] else "â†’"
                    self.logger.info(f"   {i}. [{search_type}] {is_std} {candidate['concept_name']} (ID: {candidate['concept_id']})")
                    self.logger.info(f"      - Domain: {candidate.get('domain_id', 'N/A')}, Vocabulary: {candidate['vocabulary_id']}")
            
            if hasattr(self.api, '_last_rerank_candidates') and self.api._last_rerank_candidates:
                stage3_candidates = self.api._last_rerank_candidates
            
            # ë„ë©”ì¸ë³„ ê²°ê³¼ ì •ë¦¬
            domain_results = []
            if results:
                self.logger.info("\n" + "=" * 100)
                self.logger.info("ğŸ“Š ë„ë©”ì¸ë³„ ë§¤í•‘ ê²°ê³¼ ìš”ì•½")
                self.logger.info("=" * 100)
                
                for idx, result in enumerate(results, 1):
                    domain_info = {
                        'domain_id': result.domain_id,
                        'mapped_concept_id': result.mapped_concept_id,
                        'mapped_concept_name': result.mapped_concept_name,
                        'mapping_score': result.mapping_score,
                        'mapping_confidence': result.mapping_confidence,
                        'mapping_method': result.mapping_method,
                        'vocabulary_id': result.vocabulary_id
                    }
                    domain_results.append(domain_info)
                    
                    self.logger.info(f"\n{idx}. [{result.domain_id}] ë§¤í•‘ ì„±ê³µ!")
                    self.logger.info(f"   ê°œë…: {result.mapped_concept_name} (ID: {result.mapped_concept_id})")
                    self.logger.info(f"   ì ìˆ˜: {result.mapping_score:.4f} | ì‹ ë¢°ë„: {result.mapping_confidence}")
                    self.logger.info(f"   ë°©ë²•: {result.mapping_method} | Vocabulary: {result.vocabulary_id}")
            
            # ê²°ê³¼ ì •ë¦¬ (ìµœê³  ì ìˆ˜ ë„ë©”ì¸ ì„ íƒ)
            best_result = max(results, key=lambda x: x.mapping_score) if results else None
            
            # ë„ë©”ì¸ë³„ Stage ê²½ë¡œ ì •ë³´ ì¶”ì¶œ
            domain_stage_paths = {}
            best_search_domain = None
            if hasattr(self.api, '_all_domain_stage_results') and self.api._all_domain_stage_results:
                domain_stage_paths = self.api._all_domain_stage_results
                
                # Best resultì˜ ê²€ìƒ‰ ë„ë©”ì¸ ì°¾ê¸°
                if best_result:
                    for search_domain, stage_info in domain_stage_paths.items():
                        if stage_info.get('result_domain') == best_result.domain_id:
                            # ê°€ì¥ ë†’ì€ ì ìˆ˜ë¥¼ ê°€ì§„ ê²€ìƒ‰ ë„ë©”ì¸ ì°¾ê¸°
                            # (ê°™ì€ ê²°ê³¼ ë„ë©”ì¸ì´ ì—¬ëŸ¬ ê²€ìƒ‰ ë„ë©”ì¸ì—ì„œ ë‚˜ì˜¬ ìˆ˜ ìˆìŒ)
                            for domain_result in domain_results:
                                if domain_result['domain_id'] == best_result.domain_id and \
                                   domain_result['mapped_concept_id'] == best_result.mapped_concept_id and \
                                   domain_result['mapping_score'] == best_result.mapping_score:
                                    # ì´ ê²°ê³¼ë¥¼ ë‚³ì€ ê²€ìƒ‰ ë„ë©”ì¸ ì°¾ê¸°
                                    for sd, si in domain_stage_paths.items():
                                        if si.get('result_domain') == best_result.domain_id:
                                            best_search_domain = sd
                                            break
                                    break
                            if best_search_domain:
                                break
            
            test_result = {
                'test_index': test_index,
                'sheet': sheet,
                'entity_name': entity_input.entity_name,
                'success': results is not None and len(results) > 0,
                'domain_count': len(results) if results else 0,
                'domain_results': domain_results,
                'domain_stage_paths': domain_stage_paths,
                'best_search_domain': best_search_domain,
                'best_result_domain': best_result.domain_id if best_result else None,
                'best_concept_id': best_result.mapped_concept_id if best_result else None,
                'best_concept_name': best_result.mapped_concept_name if best_result else None,
                'best_score': best_result.mapping_score if best_result else 0.0,
                'best_confidence': best_result.mapping_confidence if best_result else None,
                'stage1_candidates': stage1_candidates,
                'stage2_candidates': stage2_candidates,
                'stage3_candidates': stage3_candidates
            }
            
            if not results:
                self.logger.info(f"âŒ ëª¨ë“  ë„ë©”ì¸ì—ì„œ ë§¤í•‘ ì‹¤íŒ¨")
            else:
                self.logger.info(f"\n" + "=" * 100)
                self.logger.info(f"ğŸ“Š ìµœì¢… ìš”ì•½: {len(results)}ê°œ ë„ë©”ì¸ì—ì„œ ë§¤í•‘ ì„±ê³µ")
                self.logger.info("=" * 100)
                self.logger.info(f"ğŸ† ìµœê³  ì ìˆ˜: [{best_result.domain_id}] {best_result.mapped_concept_name} ({best_result.mapping_score:.4f})")
                
                # ë„ë©”ì¸ë³„ Stage ê²½ë¡œ ì¶œë ¥
                if hasattr(self.api, '_all_domain_stage_results') and self.api._all_domain_stage_results:
                    self.logger.info(f"\nğŸ“ˆ ë„ë©”ì¸ë³„ Stage ê²½ë¡œ:")
                    for domain_name, stage_info in self.api._all_domain_stage_results.items():
                        self.logger.info(f"  [{domain_name}] Stage1: {stage_info.get('stage1_count', 0)}ê°œ â†’ "
                                       f"Stage2: {stage_info.get('stage2_count', 0)}ê°œ â†’ "
                                       f"Stage3: {stage_info.get('stage3_count', 0)}ê°œ")
                self.logger.info("=" * 100)
                
            return test_result
            
        except Exception as e:
            self.logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
            return {
                'test_index': test_index,
                'sheet': sheet,
                'entity_name': entity_input.entity_name,
                'success': False,
                'domain_count': 0,
                'domain_results': [],
                'best_search_domain': None,
                'best_result_domain': None,
                'best_concept_id': None,
                'best_concept_name': None,
                'best_score': 0.0,
                'best_confidence': None,
                'error': str(e),
                'stage1_candidates': [],
                'stage2_candidates': [],
                'stage3_candidates': []
            }
    
    def run_test_with_entities(self, entity_list: list, max_entities: int = None):
        """ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.logger.info("ğŸš€ Entity Mapping API í…ŒìŠ¤íŠ¸ ì‹œì‘")
        self.logger.info(f"í…ŒìŠ¤íŠ¸ ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸: {len(entity_list)}ê°œ")
        
        # ë°ì´í„° ìƒì„±
        test_data = self.load_test_data_from_list(entity_list)
        
        if max_entities:
            test_data = test_data.head(max_entities)
            self.logger.info(f"í…ŒìŠ¤íŠ¸ ì œí•œ: ìµœëŒ€ {max_entities}ê°œ ì—”í‹°í‹°")
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        test_results = []
        successful_tests = 0
        
        for idx, row in test_data.iterrows():
            try:
                entity_input = self.create_entity_input(row)
                result = self.test_single_entity(entity_input, idx + 1, row['sheet'])
                test_results.append(result)
                
                if result['success']:
                    successful_tests += 1
                    
            except Exception as e:
                self.logger.error(f"í…ŒìŠ¤íŠ¸ #{idx + 1} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # ê²°ê³¼ ìš”ì•½
        total_tests = len(test_results)
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        self.logger.info("=" * 100)
        self.logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        self.logger.info("=" * 100)
        self.logger.info(f"ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
        self.logger.info(f"ì„±ê³µ: {successful_tests}ê°œ")
        self.logger.info(f"ì‹¤íŒ¨: {total_tests - successful_tests}ê°œ")
        self.logger.info(f"ì„±ê³µë¥ : {success_rate:.2f}%")
        
        # ì—”í‹°í‹°ë³„ ìš”ì•½
        for i, result in enumerate(test_results, 1):
            status = "âœ… ì„±ê³µ" if result['success'] else "âŒ ì‹¤íŒ¨"
            self.logger.info(f"  {i}. {result['entity_name']}: {status}")
            if result['success']:
                search_domain = result.get('best_search_domain', 'N/A')
                result_domain = result.get('best_result_domain', 'N/A')
                if search_domain == result_domain:
                    domain_info = f"[{result_domain}]"
                else:
                    domain_info = f"[{search_domain} â†’ {result_domain}]"
                self.logger.info(f"     -> {domain_info} {result.get('best_concept_name', 'N/A')} (ì ìˆ˜: {result.get('best_score', 0.0):.4f})")
        
        # ê²°ê³¼ë¥¼ CSVì™€ XLSXë¡œ ì €ì¥
        self.save_results_to_csv(test_results)
        self.save_results_to_xlsx(test_results)
        
        return test_results
    
    def save_results_to_csv(self, test_results: list):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥ (ë„ë©”ì¸ë³„ ê²°ê³¼ í¬í•¨)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_file = self.log_dir / f"test_results_{timestamp}.csv"
        
        # CSVìš© ë°ì´í„° ì •ë¦¬ (ë„ë©”ì¸ë³„ ê²°ê³¼ í‰íƒ„í™”)
        csv_results = []
        for result in test_results:
            # ê¸°ë³¸ ì •ë³´
            base_info = {
                'test_index': result['test_index'],
                'entity_name': result['entity_name'],
                'success': result['success'],
                'domain_count': result.get('domain_count', 0),
                'best_search_domain': result.get('best_search_domain', 'N/A'),
                'best_result_domain': result.get('best_result_domain', 'N/A'),
                'best_concept_id': result.get('best_concept_id', 'N/A'),
                'best_concept_name': result.get('best_concept_name', 'N/A'),
                'best_score': result.get('best_score', 0.0),
                'best_confidence': result.get('best_confidence', 'N/A')
            }
            csv_results.append(base_info)
        
        df_results = pd.DataFrame(csv_results)
        df_results.to_csv(csv_file, index=False, encoding='utf-8')
        
        self.logger.info(f"ğŸ“„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ CSV ì €ì¥: {csv_file}")
    
    def save_results_to_xlsx(self, test_results: list):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ XLSX íŒŒì¼ë¡œ ì €ì¥ (stage1, stage3 í›„ë³´êµ°ì„ ì—´ë¡œ ë¶„ë¦¬)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        xlsx_file = self.log_dir / f"test_results_detailed_{timestamp}.xlsx"
        
        # ì—‘ì…€ ì›Œí¬ë¶ ìƒì„±
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "Detailed Results"
        
        # í†µí•© ìƒì„¸ ì‹œíŠ¸ ìƒì„±
        self._create_integrated_detail_sheet(ws, test_results)
        
        # íŒŒì¼ ì €ì¥
        wb.save(xlsx_file)
        self.logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ XLSX ì €ì¥: {xlsx_file}")
    
    def _create_integrated_detail_sheet(self, ws, test_results):
        """í†µí•© ìƒì„¸ ì‹œíŠ¸ ìƒì„± (ëª¨ë“  ì—”í‹°í‹°ë¥¼ í•˜ë‚˜ì˜ ì‹œíŠ¸ì—, ë„ë©”ì¸ë³„ ê²°ê³¼ í¬í•¨)"""
        
        # í—¤ë” ì„¤ì •
        headers = [
            "Test Index", "Entity Name", "Success", "Domain Count",
            "Best Search Domain", "Best Result Domain", "Best Concept ID", "Best Concept Name", 
            "Best Score", "Best Confidence",
            "All Domains", "Domain Stage Paths", "Stage1 Candidates", "Stage2 Candidates", "Stage3 Candidates"
        ]
        
        # í—¤ë” ìŠ¤íƒ€ì¼
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        header_alignment = Alignment(horizontal="center", vertical="center")
        
        # í—¤ë” ì‘ì„±
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col, value=header)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = header_alignment
        
        # ë°ì´í„° ì‘ì„±
        for row, result in enumerate(test_results, 2):
            ws.cell(row=row, column=1, value=result['test_index'])
            ws.cell(row=row, column=2, value=result['entity_name'])
            ws.cell(row=row, column=3, value="ì„±ê³µ" if result['success'] else "ì‹¤íŒ¨")
            ws.cell(row=row, column=4, value=result.get('domain_count', 0))
            ws.cell(row=row, column=5, value=result.get('best_search_domain', 'N/A'))
            ws.cell(row=row, column=6, value=result.get('best_result_domain', 'N/A'))
            ws.cell(row=row, column=7, value=result.get('best_concept_id', 'N/A'))
            ws.cell(row=row, column=8, value=result.get('best_concept_name', 'N/A'))
            ws.cell(row=row, column=9, value=result.get('best_score', 0.0))
            ws.cell(row=row, column=10, value=result.get('best_confidence', 'N/A'))
            
            # ëª¨ë“  ë„ë©”ì¸ ê²°ê³¼ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            domain_results_text = self._format_domain_results(result.get('domain_results', []))
            ws.cell(row=row, column=11, value=domain_results_text)
            
            # ë„ë©”ì¸ë³„ Stage ê²½ë¡œ ì •ë³´
            stage_paths_text = self._format_stage_paths(result.get('domain_stage_paths', {}))
            ws.cell(row=row, column=12, value=stage_paths_text)
            
            # Stage1 í›„ë³´êµ° ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            stage1_text = self._format_candidates_for_cell(result.get('stage1_candidates', []), 'stage1')
            ws.cell(row=row, column=13, value=stage1_text)
            
            # Stage2 í›„ë³´êµ° ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            stage2_text = self._format_candidates_for_cell(result.get('stage2_candidates', []), 'stage2')
            ws.cell(row=row, column=14, value=stage2_text)
            
            # Stage3 í›„ë³´êµ° ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            stage3_text = self._format_candidates_for_cell(result.get('stage3_candidates', []), 'stage3')
            ws.cell(row=row, column=15, value=stage3_text)
            
            # ì…€ ìŠ¤íƒ€ì¼ ì„¤ì • (í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ í—ˆìš©)
            for col in range(11, 16):  # All Domains, Stage Paths, Stage1, Stage2, Stage3 ì—´
                cell = ws.cell(row=row, column=col)
                cell.alignment = Alignment(wrap_text=True, vertical='top')
        
        # ì—´ ë„ˆë¹„ ì„¤ì •
        column_widths = {
            'A': 10,  # Test Index
            'B': 35,  # Entity Name
            'C': 10,  # Success
            'D': 12,  # Domain Count
            'E': 15,  # Best Search Domain
            'F': 15,  # Best Result Domain
            'G': 15,  # Best Concept ID
            'H': 45,  # Best Concept Name
            'I': 12,  # Best Score
            'J': 15,  # Best Confidence
            'K': 50,  # All Domains
            'L': 45,  # Domain Stage Paths
            'M': 70,  # Stage1 Candidates
            'N': 70,  # Stage2 Candidates
            'O': 85   # Stage3 Candidates
        }
        
        for col_letter, width in column_widths.items():
            ws.column_dimensions[col_letter].width = width
        
        # í–‰ ë†’ì´ ìë™ ì¡°ì • (í›„ë³´êµ° ì •ë³´ê°€ ë§ì€ ê²½ìš°)
        for row_num in range(2, len(test_results) + 2):
            ws.row_dimensions[row_num].height = 150  # ì¶©ë¶„í•œ ë†’ì´ ì„¤ì •
    
    def _format_domain_results(self, domain_results):
        """ë„ë©”ì¸ë³„ ê²°ê³¼ë¥¼ ì—‘ì…€ ì…€ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if not domain_results:
            return "ë„ë©”ì¸ ê²°ê³¼ ì—†ìŒ"
        
        lines = []
        for i, domain in enumerate(domain_results, 1):
            line = f"{i}. [{domain.get('domain_id', 'N/A')}] {domain.get('mapped_concept_name', 'N/A')}\n"
            line += f"   ID: {domain.get('mapped_concept_id', 'N/A')}, "
            line += f"Score: {domain.get('mapping_score', 0):.4f}, "
            line += f"Conf: {domain.get('mapping_confidence', 'N/A')}\n"
            line += f"   Vocab: {domain.get('vocabulary_id', 'N/A')}"
            lines.append(line)
        
        return "\n\n".join(lines)
    
    def _format_stage_paths(self, stage_paths):
        """ë„ë©”ì¸ë³„ Stage ê²½ë¡œë¥¼ ì—‘ì…€ ì…€ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if not stage_paths:
            return "ê²½ë¡œ ì •ë³´ ì—†ìŒ"
        
        lines = []
        for domain_name, stage_info in sorted(stage_paths.items()):
            search_domain = stage_info.get('search_domain', domain_name)
            result_domain = stage_info.get('result_domain', 'N/A')
            
            # ê²€ìƒ‰ ë„ë©”ì¸ê³¼ ê²°ê³¼ ë„ë©”ì¸ì´ ë‹¤ë¥¸ ê²½ìš° í‘œì‹œ
            if search_domain != result_domain:
                line = f"[{search_domain} â†’ {result_domain}]\n"
            else:
                line = f"[{search_domain}]\n"
            
            line += f"  Stage1: {stage_info.get('stage1_count', 0)}ê°œ\n"
            line += f"  Stage2: {stage_info.get('stage2_count', 0)}ê°œ\n"
            line += f"  Stage3: {stage_info.get('stage3_count', 0)}ê°œ"
            lines.append(line)
        
        return "\n\n".join(lines)
    
    def _format_candidates_for_cell(self, candidates, stage_type):
        """í›„ë³´êµ° ì •ë³´ë¥¼ ì—‘ì…€ ì…€ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if not candidates:
            return "í›„ë³´ ì—†ìŒ"
        
        lines = []
        max_candidates = 15 if stage_type == 'stage1' else (15 if stage_type == 'stage2' else 10)  # Stage1, Stage2ëŠ” 15ê°œ, Stage3ëŠ” 10ê°œ í‘œì‹œ
        
        for i, candidate in enumerate(candidates[:max_candidates], 1):
            if stage_type == 'stage1':
                search_type = candidate.get('search_type', 'unknown')
                line = f"{i}. [{search_type}] {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                line += f"   ESì ìˆ˜: {candidate.get('elasticsearch_score', 0):.4f}, "
                line += f"Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Domain: {candidate.get('domain_id', 'N/A')}"
            elif stage_type == 'stage2':
                search_type = candidate.get('search_type', 'unknown')
                is_std = "âœ“" if candidate.get('is_original_standard', True) else "â†’"
                line = f"{i}. [{search_type}] {is_std} {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                line += f"   Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Domain: {candidate.get('domain_id', 'N/A')}"
                if not candidate.get('is_original_standard', True):
                    original_non_std = candidate.get('original_non_standard', {})
                    if original_non_std:
                        line += f"\n   ì›ë³¸ Non-std: {original_non_std.get('concept_name', 'N/A')} (ID: {original_non_std.get('concept_id', 'N/A')})"
            else:  # stage3
                search_type = candidate.get('search_type', 'unknown')
                line = f"{i}. [{search_type}] {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                line += f"   í…ìŠ¤íŠ¸: {candidate.get('text_similarity', 0):.4f}, "
                line += f"ì˜ë¯¸ì : {candidate.get('semantic_similarity', 0):.4f}, "
                line += f"ìµœì¢…: {candidate.get('final_score', 0):.4f}\n"
                line += f"   Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Domain: {candidate.get('domain_id', 'N/A')}"
            
            lines.append(line)
        
        return "\n\n".join(lines)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    tester = EntityMappingTester()
    
    # í…ŒìŠ¤íŠ¸í•  ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸
    test_entities = test_entities = [
        'ST-segment elevation myocardial infarction',
        'acute coronary syndromes',
        'acute myocardial infarction',
        'adrenal incidentaloma',
        'adrenal vein sampling',
        'aldosterone-producing adenoma',
        'aldosterone-to-renin ratio',
        'angiotensin receptor blocker',
        'angiotensin-converting enzyme inhibitor',
        'atherosclerotic cardiovascular disease',
        'atrial fibrillation',
        'blood pressure',
        'cardiac rehabilitation',
        'cardiac troponin',
        'cardiovascular',
        'cardiovascular disease',
        'chronic coronary disease',
        'computed tomography',
        'coronary artery bypass grafting',
        'coronary artery disease',
        'diastolic blood pressure',
        'direct oral anticoagulant',
        'electrocardiogram',
        'fractional flow reserve',
        'glucagon-like peptide-1',
        'glucocorticoid-remediable aldosteronism',
        'heart failure',
        'high-sensitivity cardiac troponin',
        'hypertension',
        'idiopathic hyperaldosteronism',
        'implantable cardioverter-defibrillator',
        'intra-aortic balloon pump',
        'intravascular ultrasound',
        'left ventricular ejection fraction',
        'left ventricular hypertrophy',
        'low-density lipoprotein',
        'low-density lipoprotein cholesterol',
        'major adverse cardiovascular event',
        'mechanical circulatory support',
        'mineralocorticoid receptor antagonist',
        'multivessel disease',
        'nonâ€“ST-segment elevation ACS',
        'nonâ€“ST-segment elevation myocardial infarction',
        'optical coherence tomography',
        'percutaneous coronary intervention',
        'plasma aldosterone concentration',
        'plasma renin activity',
        'primary aldosteronism',
        'proprotein convertase subtilisin/kexin type 9',
        'primary percutaneous coronary intervention',
        'proton pump inhibitor',
        'randomized controlled trial',
        'return of spontaneous circulation',
        'sodium-glucose cotransporter-2',
        'systolic blood pressure',
        'unfractionated heparin',
        'venoarterial extracorporeal membrane oxygenation',
        'myocardial ischemia',
        'breast cancer',
        'type 2 diabetes',
        # --- ì¶”ê°€ (ì—¬ê¸°ì„œë¶€í„° í™•ì¥) ---
        'chronic kidney disease',
        'glomerular filtration rate',
        'end-stage renal disease',
        'atrial flutter',
        'ventricular tachycardia',
        'ventricular fibrillation',
        'sudden cardiac death',
        'ischemic stroke',
        'hemorrhagic stroke',
        'pulmonary embolism',
        'deep vein thrombosis',
        'chronic obstructive pulmonary disease',
        'obstructive sleep apnea',
        'acute respiratory distress syndrome',
        'body mass index',
        'fasting plasma glucose',
        'oral glucose tolerance test',
        'glycated hemoglobin',
        'insulin resistance',
        'metabolic syndrome',
        'nonalcoholic fatty liver disease',
        'nonalcoholic steatohepatitis',
        'hepatocellular carcinoma',
        'prostate cancer',
        'colorectal cancer',
    ]
    
    results = tester.run_test_with_entities(test_entities)
    
    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ë¡œê·¸ëŠ” {tester.log_dir} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()