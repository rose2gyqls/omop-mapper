import pandas as pd
import logging
import os
from datetime import datetime
from pathlib import Path
import sys
import openpyxl
from openpyxl.styles import Font, Alignment, PatternFill
from openpyxl.utils.dataframe import dataframe_to_rows

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì¶”ê°€
sys.path.append('/home/work/skku/hyo/omop-mapper/src')

from omop_mapper.entity_mapping_api import EntityMappingAPI, EntityInput, DomainID
from omop_mapper.elasticsearch_client import ElasticsearchClient

class EntityMappingTester:
    def __init__(self, log_dir: str = "test_logs"):
        """í…ŒìŠ¤í„° ì´ˆê¸°í™”"""
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        
        # ë¡œê·¸ ì„¤ì •
        self.setup_logging()
        
        # Elasticsearch í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (concept-small ì¸ë±ìŠ¤ ì‚¬ìš©)
        self.es_client = ElasticsearchClient()
        self.es_client.concept_index = "concept-small"
        self.es_client.concept_synonym_index = "concept-small"
        
        # API ì´ˆê¸°í™”
        self.api = EntityMappingAPI(es_client=self.es_client)
        
        # ë„ë©”ì¸ ë§¤í•‘
        self.domain_mapping = {
            'Condition': DomainID.CONDITION,
            'Procedure': DomainID.PROCEDURE,
            'Drug': DomainID.DRUG,
            'Observation': DomainID.OBSERVATION,
            'Measurement': DomainID.MEASUREMENT,
            'Period': DomainID.PERIOD,
            'Provider': DomainID.PROVIDER
        }
    
    def setup_logging(self):
        """ë¡œê¹… ì„¤ì •"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
        # ë©”ì¸ ë¡œê·¸ íŒŒì¼
        log_file = self.log_dir / f"entity_mapping_test_{timestamp}.log"
        
        # ë¡œê±° ì„¤ì •
        self.logger = logging.getLogger('entity_mapping_test')
        self.logger.setLevel(logging.INFO)
        
        # íŒŒì¼ í•¸ë“¤ëŸ¬
        file_handler = logging.FileHandler(log_file, encoding='utf-8')
        file_handler.setLevel(logging.INFO)
        
        # ì½˜ì†” í•¸ë“¤ëŸ¬
        console_handler = logging.StreamHandler()
        console_handler.setLevel(logging.INFO)
        
        # í¬ë§·í„°
        formatter = logging.Formatter(
            '%(asctime)s - %(name)s - %(levelname)s - %(message)s',
            datefmt='%Y-%m-%d %H:%M:%S'
        )
        file_handler.setFormatter(formatter)
        console_handler.setFormatter(formatter)
        
        # í•¸ë“¤ëŸ¬ ì¶”ê°€
        self.logger.addHandler(file_handler)
        self.logger.addHandler(console_handler)
        
        # API ë¡œê±°ë„ ê°™ì€ í•¸ë“¤ëŸ¬ ì‚¬ìš©
        api_logger = logging.getLogger('omop_mapper.entity_mapping_api')
        api_logger.setLevel(logging.INFO)
        api_logger.addHandler(file_handler)
        
        self.logger.info(f"ë¡œê·¸ íŒŒì¼: {log_file}")
    
    def load_test_data_from_list(self, entity_list: list) -> pd.DataFrame:
        """ë¦¬ìŠ¤íŠ¸ì—ì„œ í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±"""
        self.logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ìƒì„±: {len(entity_list)}ê°œ ì—”í‹°í‹°")
        
        # ì—”í‹°í‹°ë³„ ë„ë©”ì¸ ì¶”ì • (ê¸°ë³¸ì ìœ¼ë¡œ Conditionìœ¼ë¡œ ì„¤ì •)
        domain_mapping = {
            'Acute Coronary Syndromes': 'Condition',
            'myocardial ischemia': 'Condition', 
            'chronic coronary disease': 'Condition',
            'nonâ€“ST-segment elevation myocardial infarction': 'Condition',
            'breast cancer': 'Condition',
            'type 2 diabetes': 'Condition',
            'hypertension': 'Condition'
        }
        
        test_data = []
        for i, entity_name in enumerate(entity_list):
            domain = domain_mapping.get(entity_name, 'Condition')
            test_data.append({
                'entity_plain_name': entity_name,
                'entity_domain': domain,
                'sheet': 'manual'  # ìˆ˜ë™ ì…ë ¥ í‘œì‹œ
            })
            self.logger.info(f"  {i+1}. {entity_name} (ë„ë©”ì¸: {domain})")
        
        df = pd.DataFrame(test_data)
        self.logger.info(f"ì „ì²´ í…ŒìŠ¤íŠ¸ ë°ì´í„°: {len(df)}ê°œ ì—”í‹°í‹°")
        
        return df
    
    def create_entity_input(self, row) -> EntityInput:
        """DataFrame í–‰ì—ì„œ EntityInput ìƒì„±"""
        entity_name = str(row['entity_plain_name']).strip()
        domain_str = str(row['entity_domain']).strip() if pd.notna(row['entity_domain']) else None
        
        # ë„ë©”ì¸ ë§¤í•‘
        domain_id = None
        if domain_str and domain_str in self.domain_mapping:
            domain_id = self.domain_mapping[domain_str]
        
        return EntityInput(
            entity_name=entity_name,
            domain_id=domain_id,
            vocabulary_id=None
        )
    
    def test_single_entity(self, entity_input: EntityInput, test_index: int, sheet: str) -> dict:
        """ë‹¨ì¼ ì—”í‹°í‹° í…ŒìŠ¤íŠ¸"""
        self.logger.info("=" * 100)
        self.logger.info(f"ğŸ§ª í…ŒìŠ¤íŠ¸ #{test_index} (ì‹œíŠ¸ {sheet}): {entity_input.entity_name}")
        self.logger.info(f"ë„ë©”ì¸: {entity_input.domain_id}")
        self.logger.info("=" * 100)
        
        try:
            # ë§¤í•‘ ìˆ˜í–‰
            result = self.api.map_entity(entity_input)
            
            # ë‹¨ê³„ë³„ ìƒì„¸ ì •ë³´ ë¡œê¹…
            stage1_candidates = []
            stage3_candidates = []
            
            if hasattr(self.api, '_last_stage1_candidates') and self.api._last_stage1_candidates:
                stage1_candidates = self.api._last_stage1_candidates
                self.logger.info("ğŸ“Š 1ë‹¨ê³„ í›„ë³´êµ° ìƒì„¸ ì •ë³´:")
                for i, candidate in enumerate(stage1_candidates[:5], 1):  # ìƒìœ„ 5ê°œë§Œ
                    self.logger.info(f"   {i}. {candidate['concept_name']} (ID: {candidate['concept_id']})")
                    self.logger.info(f"      - Elasticsearch ì ìˆ˜: {candidate['elasticsearch_score']:.4f}")
                    self.logger.info(f"      - Standard: {candidate['standard_concept']}")
                    self.logger.info(f"      - Vocabulary: {candidate['vocabulary_id']}")
            
            if hasattr(self.api, '_last_rerank_candidates') and self.api._last_rerank_candidates:
                stage3_candidates = self.api._last_rerank_candidates
                self.logger.info("ğŸ“Š 3ë‹¨ê³„ í›„ë³´êµ° ìƒì„¸ ì •ë³´:")
                for i, candidate in enumerate(stage3_candidates[:5], 1):  # ìƒìœ„ 5ê°œë§Œ
                    self.logger.info(f"   {i}. {candidate['concept_name']} (ID: {candidate['concept_id']})")
                    self.logger.info(f"      - í…ìŠ¤íŠ¸ ìœ ì‚¬ë„: {candidate['text_similarity']:.4f}")
                    self.logger.info(f"      - ì˜ë¯¸ì  ìœ ì‚¬ë„: {candidate['semantic_similarity']:.4f}")
                    self.logger.info(f"      - ìµœì¢… ì ìˆ˜: {candidate['final_score']:.4f}")
                    self.logger.info(f"      - Vocabulary: {candidate['vocabulary_id']}")
            
            # ê²°ê³¼ ì •ë¦¬
            test_result = {
                'test_index': test_index,
                'sheet': sheet,
                'entity_name': entity_input.entity_name,
                'domain_id': str(entity_input.domain_id) if entity_input.domain_id else None,
                'success': result is not None,
                'mapped_concept_id': result.mapped_concept_id if result else None,
                'mapped_concept_name': result.mapped_concept_name if result else None,
                'mapping_score': result.mapping_score if result else 0.0,
                'mapping_confidence': result.mapping_confidence if result else None,
                'mapping_method': result.mapping_method if result else None,
                'alternative_concepts_count': len(result.alternative_concepts) if result and result.alternative_concepts else 0,
                'stage1_candidates': stage1_candidates,
                'stage3_candidates': stage3_candidates
            }
            
            if result:
                self.logger.info(f"âœ… ë§¤í•‘ ì„±ê³µ!")
                self.logger.info(f"   - ë§¤í•‘ëœ ì»¨ì…‰: {result.mapped_concept_name} (ID: {result.mapped_concept_id})")
                self.logger.info(f"   - ë§¤í•‘ ì ìˆ˜: {result.mapping_score:.4f}")
                self.logger.info(f"   - ë§¤í•‘ ì‹ ë¢°ë„: {result.mapping_confidence}")
                self.logger.info(f"   - ë§¤í•‘ ë°©ë²•: {result.mapping_method}")
                self.logger.info(f"   - Vocabulary: {result.vocabulary_id}")
                if result.alternative_concepts:
                    self.logger.info(f"   - ëŒ€ì•ˆ ê°œìˆ˜: {len(result.alternative_concepts)}ê°œ")
                    for i, alt in enumerate(result.alternative_concepts[:3], 1):  # ìƒìœ„ 3ê°œ ëŒ€ì•ˆ
                        self.logger.info(f"     {i}. {alt['concept_name']} (ID: {alt['concept_id']}, ì ìˆ˜: {alt['score']:.4f})")
            else:
                self.logger.info(f"âŒ ë§¤í•‘ ì‹¤íŒ¨")
                
            return test_result
            
        except Exception as e:
            self.logger.error(f"âŒ í…ŒìŠ¤íŠ¸ ì˜¤ë¥˜: {str(e)}")
            return {
                'test_index': test_index,
                'sheet': sheet,
                'entity_name': entity_input.entity_name,
                'domain_id': str(entity_input.domain_id) if entity_input.domain_id else None,
                'success': False,
                'error': str(e),
                'mapped_concept_id': None,
                'mapped_concept_name': None,
                'mapping_score': 0.0,
                'mapping_confidence': None,
                'mapping_method': None,
                'alternative_concepts_count': 0,
                'stage1_candidates': [],
                'stage3_candidates': []
            }
    
    def run_test_with_entities(self, entity_list: list, max_entities: int = None):
        """ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸ë¡œ í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.logger.info("ğŸš€ Entity Mapping API í…ŒìŠ¤íŠ¸ ì‹œì‘")
        self.logger.info(f"í…ŒìŠ¤íŠ¸ ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸: {len(entity_list)}ê°œ")
        
        # ë°ì´í„° ìƒì„±
        test_data = self.load_test_data_from_list(entity_list)
        
        if max_entities:
            test_data = test_data.head(max_entities)
            self.logger.info(f"í…ŒìŠ¤íŠ¸ ì œí•œ: ìµœëŒ€ {max_entities}ê°œ ì—”í‹°í‹°")
        
        # í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥
        test_results = []
        successful_tests = 0
        
        for idx, row in test_data.iterrows():
            try:
                entity_input = self.create_entity_input(row)
                result = self.test_single_entity(entity_input, idx + 1, row['sheet'])
                test_results.append(result)
                
                if result['success']:
                    successful_tests += 1
                    
            except Exception as e:
                self.logger.error(f"í…ŒìŠ¤íŠ¸ #{idx + 1} ì²˜ë¦¬ ì˜¤ë¥˜: {str(e)}")
                continue
        
        # ê²°ê³¼ ìš”ì•½
        total_tests = len(test_results)
        success_rate = (successful_tests / total_tests * 100) if total_tests > 0 else 0
        
        self.logger.info("=" * 100)
        self.logger.info("ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ ìš”ì•½")
        self.logger.info("=" * 100)
        self.logger.info(f"ì´ í…ŒìŠ¤íŠ¸: {total_tests}ê°œ")
        self.logger.info(f"ì„±ê³µ: {successful_tests}ê°œ")
        self.logger.info(f"ì‹¤íŒ¨: {total_tests - successful_tests}ê°œ")
        self.logger.info(f"ì„±ê³µë¥ : {success_rate:.2f}%")
        
        # ì—”í‹°í‹°ë³„ ìš”ì•½
        for i, result in enumerate(test_results, 1):
            status = "âœ… ì„±ê³µ" if result['success'] else "âŒ ì‹¤íŒ¨"
            self.logger.info(f"  {i}. {result['entity_name']}: {status}")
            if result['success']:
                self.logger.info(f"     -> {result['mapped_concept_name']} (ì ìˆ˜: {result['mapping_score']:.4f})")
        
        # ê²°ê³¼ë¥¼ CSVì™€ XLSXë¡œ ì €ì¥
        self.save_results_to_csv(test_results)
        self.save_results_to_xlsx(test_results)
        
        return test_results
    
    def save_results_to_csv(self, test_results: list):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        csv_file = self.log_dir / f"test_results_{timestamp}.csv"
        
        # CSVìš© ë°ì´í„° ì •ë¦¬ (ë³µì¡í•œ ê°ì²´ ì œê±°)
        csv_results = []
        for result in test_results:
            csv_result = {k: v for k, v in result.items() 
                         if k not in ['stage1_candidates', 'stage3_candidates']}
            csv_results.append(csv_result)
        
        df_results = pd.DataFrame(csv_results)
        df_results.to_csv(csv_file, index=False, encoding='utf-8')
        
        self.logger.info(f"ğŸ“„ í…ŒìŠ¤íŠ¸ ê²°ê³¼ CSV ì €ì¥: {csv_file}")
    
    def save_results_to_xlsx(self, test_results: list):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¥¼ XLSX íŒŒì¼ë¡œ ì €ì¥ (stage1, stage3 í›„ë³´êµ°ì„ ì—´ë¡œ ë¶„ë¦¬)"""
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        xlsx_file = self.log_dir / f"test_results_detailed_{timestamp}.xlsx"
        
        # ì—‘ì…€ ì›Œí¬ë¶ ìƒì„±
        wb = openpyxl.Workbook()
        ws = wb.active
        ws.title = "Detailed Results"
        
        # í†µí•© ìƒì„¸ ì‹œíŠ¸ ìƒì„±
        self._create_integrated_detail_sheet(ws, test_results)
        
        # íŒŒì¼ ì €ì¥
        wb.save(xlsx_file)
        self.logger.info(f"ğŸ“Š í…ŒìŠ¤íŠ¸ ê²°ê³¼ XLSX ì €ì¥: {xlsx_file}")
    
    def _create_integrated_detail_sheet(self, ws, test_results):
        """í†µí•© ìƒì„¸ ì‹œíŠ¸ ìƒì„± (ëª¨ë“  ì—”í‹°í‹°ë¥¼ í•˜ë‚˜ì˜ ì‹œíŠ¸ì—)"""
        
        # í—¤ë” ì„¤ì •
        headers = [
            "Test Index", "Entity Name", "Domain", "Success", 
            "Mapped Concept ID", "Mapped Concept Name", 
            "Mapping Score", "Mapping Confidence", "Mapping Method",
            "Stage1 Candidates", "Stage3 Candidates"
        ]
        
        # í—¤ë” ìŠ¤íƒ€ì¼
        header_font = Font(bold=True, color="FFFFFF")
        header_fill = PatternFill(start_color="366092", end_color="366092", fill_type="solid")
        header_alignment = Alignment(horizontal="center", vertical="center")
        
        # í—¤ë” ì‘ì„±
        for col, header in enumerate(headers, 1):
            cell = ws.cell(row=1, column=col, value=header)
            cell.font = header_font
            cell.fill = header_fill
            cell.alignment = header_alignment
        
        # ë°ì´í„° ì‘ì„±
        for row, result in enumerate(test_results, 2):
            ws.cell(row=row, column=1, value=result['test_index'])
            ws.cell(row=row, column=2, value=result['entity_name'])
            ws.cell(row=row, column=3, value=result['domain_id'])
            ws.cell(row=row, column=4, value="ì„±ê³µ" if result['success'] else "ì‹¤íŒ¨")
            ws.cell(row=row, column=5, value=result['mapped_concept_id'])
            ws.cell(row=row, column=6, value=result['mapped_concept_name'])
            ws.cell(row=row, column=7, value=result['mapping_score'])
            ws.cell(row=row, column=8, value=result['mapping_confidence'])
            ws.cell(row=row, column=9, value=result['mapping_method'])
            
            # Stage1 í›„ë³´êµ° ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            stage1_text = self._format_candidates_for_cell(result.get('stage1_candidates', []), 'stage1')
            ws.cell(row=row, column=10, value=stage1_text)
            
            # Stage3 í›„ë³´êµ° ì •ë³´ë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
            stage3_text = self._format_candidates_for_cell(result.get('stage3_candidates', []), 'stage3')
            ws.cell(row=row, column=11, value=stage3_text)
            
            # ì…€ ìŠ¤íƒ€ì¼ ì„¤ì • (í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ í—ˆìš©)
            for col in range(10, 12):  # Stage1, Stage3 ì—´
                cell = ws.cell(row=row, column=col)
                cell.alignment = Alignment(wrap_text=True, vertical='top')
        
        # ì—´ ë„ˆë¹„ ì„¤ì •
        column_widths = {
            'A': 10,  # Test Index
            'B': 30,  # Entity Name
            'C': 15,  # Domain
            'D': 10,  # Success
            'E': 15,  # Mapped Concept ID
            'F': 40,  # Mapped Concept Name
            'G': 15,  # Mapping Score
            'H': 15,  # Mapping Confidence
            'I': 20,  # Mapping Method
            'J': 60,  # Stage1 Candidates
            'K': 80   # Stage3 Candidates
        }
        
        for col_letter, width in column_widths.items():
            ws.column_dimensions[col_letter].width = width
        
        # í–‰ ë†’ì´ ìë™ ì¡°ì • (í›„ë³´êµ° ì •ë³´ê°€ ë§ì€ ê²½ìš°)
        for row_num in range(2, len(test_results) + 2):
            ws.row_dimensions[row_num].height = 120  # ì¶©ë¶„í•œ ë†’ì´ ì„¤ì •
    
    def _format_candidates_for_cell(self, candidates, stage_type):
        """í›„ë³´êµ° ì •ë³´ë¥¼ ì—‘ì…€ ì…€ìš© í…ìŠ¤íŠ¸ë¡œ í¬ë§·íŒ…"""
        if not candidates:
            return "í›„ë³´ ì—†ìŒ"
        
        lines = []
        for i, candidate in enumerate(candidates[:5], 1):  # ìƒìœ„ 5ê°œë§Œ í‘œì‹œ
            if stage_type == 'stage1':
                line = f"{i}. {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                line += f"   ESì ìˆ˜: {candidate.get('elasticsearch_score', 0):.4f}, "
                line += f"Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Vocab: {candidate.get('vocabulary_id', 'N/A')}"
            else:  # stage3
                line = f"{i}. {candidate.get('concept_name', 'N/A')} (ID: {candidate.get('concept_id', 'N/A')})\n"
                line += f"   í…ìŠ¤íŠ¸: {candidate.get('text_similarity', 0):.4f}, "
                line += f"ì˜ë¯¸ì : {candidate.get('semantic_similarity', 0):.4f}, "
                line += f"ìµœì¢…: {candidate.get('final_score', 0):.4f}\n"
                line += f"   Standard: {candidate.get('standard_concept', 'N/A')}, "
                line += f"Vocab: {candidate.get('vocabulary_id', 'N/A')}"
            
            lines.append(line)
        
        return "\n\n".join(lines)

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    tester = EntityMappingTester()
    
    # í…ŒìŠ¤íŠ¸í•  ì—”í‹°í‹° ë¦¬ìŠ¤íŠ¸
    test_entities = test_entities = [
        'MI with nonobstructive coronary artery disease',
        'ST-segment elevation myocardial infarction',
        'US Food and Drug Administration',
        'acute coronary syndromes',
        'acute myocardial infarction',
        'adrenal incidentaloma',
        'adrenal vein sampling',
        'aldosterone-producing adenoma',
        'aldosterone-to-renin ratio',
        'angiotensin receptor blocker',
        'angiotensin-converting enzyme inhibitor',
        'atherosclerotic cardiovascular disease',
        'atrial fibrillation',
        'blood pressure',
        'cardiac intensive care unit',
        'cardiac rehabilitation',
        'cardiac troponin',
        'cardiovascular',
        'cardiovascular disease',
        'chronic coronary disease',
        'clinical decision pathway',
        'computed tomography',
        'confidence interval',
        'coronary artery bypass grafting',
        'coronary artery disease',
        'diastolic blood pressure',
        'direct oral anticoagulant',
        'dual antiplatelet therapy',
        'electrocardiogram',
        'first medical contact',
        'fractional flow reserve',
        'glucagon-like peptide-1',
        'glucocorticoid-remediable aldosteronism',
        'hazard ratio',
        'heart failure',
        'high-sensitivity cardiac troponin',
        'hypertension',
        'idiopathic hyperaldosteronism',
        'implantable cardioverter-defibrillator',
        'intra-aortic balloon pump',
        'intravascular ultrasound',
        'left ventricular',
        'left ventricular ejection fraction',
        'left ventricular hypertrophy',
        'low-density lipoprotein',
        'low-density lipoprotein cholesterol',
        'major adverse cardiovascular event',
        'mechanical circulatory support',
        'mineralocorticoid receptor',
        'mineralocorticoid receptor antagonist',
        'multivessel disease',
        'nonâ€“ST-segment elevation ACS',
        'nonâ€“ST-segment elevation myocardial infarction',
        'odds ratio',
        'optical coherence tomography',
        'percutaneous coronary intervention',
        'plasma aldosterone concentration',
        'plasma renin activity',
        'primary aldosteronism',
        'proprotein convertase subtilisin/kexin type 9',
        'primary percutaneous coronary intervention',
        'proton pump inhibitor',
        'quality of life',
        'randomized controlled trial',
        'relative risk',
        'renin-angiotensin system',
        'return of spontaneous circulation',
        'sodium-glucose cotransporter-2',
        'subclinical hypercortisolism',
        'systolic blood pressure',
        'unfractionated heparin',
        'venoarterial extracorporeal membrane oxygenation',
        'myocardial ischemia',
        'breast cancer',
        'type 2 diabetes',
        # --- ì¶”ê°€ (ì—¬ê¸°ì„œë¶€í„° í™•ì¥) ---
        'chronic kidney disease',
        'glomerular filtration rate',
        'end-stage renal disease',
        'atrial flutter',
        'ventricular tachycardia',
        'ventricular fibrillation',
        'sudden cardiac death',
        'ischemic stroke',
        'hemorrhagic stroke',
        'pulmonary embolism',
        'deep vein thrombosis',
        'chronic obstructive pulmonary disease',
        'obstructive sleep apnea',
        'acute respiratory distress syndrome',
        'body mass index',
        'fasting plasma glucose',
        'oral glucose tolerance test',
        'glycated hemoglobin',
        'insulin resistance',
        'metabolic syndrome',
        'nonalcoholic fatty liver disease',
        'nonalcoholic steatohepatitis',
        'hepatocellular carcinoma',
        'prostate cancer',
        'colorectal cancer'
    ]
    
    results = tester.run_test_with_entities(test_entities)
    
    print(f"\nâœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ! ë¡œê·¸ëŠ” {tester.log_dir} ë””ë ‰í† ë¦¬ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

if __name__ == "__main__":
    main()
